<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>TensorFlow &#8211; Adventures in Machine Learning</title>
	<atom:link href="http://adventuresinmachinelearning.com/category/deep-learning/tensorflow/feed/" rel="self" type="application/rss+xml" />
	<link>http://adventuresinmachinelearning.com</link>
	<description>Learn and explore machine learning</description>
	<lastBuildDate>Sun, 09 Sep 2018 07:53:16 +0000</lastBuildDate>
	<language>en-AU</language>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.9.8</generator>
	<item>
		<title>TensorFlow Eager tutorial</title>
		<link>http://adventuresinmachinelearning.com/tensorflow-eager-tutorial/</link>
		<comments>http://adventuresinmachinelearning.com/tensorflow-eager-tutorial/#respond</comments>
		<pubDate>Sun, 05 Aug 2018 20:43:05 +0000</pubDate>
		<dc:creator><![CDATA[Andy]]></dc:creator>
				<category><![CDATA[Deep learning]]></category>
		<category><![CDATA[TensorFlow]]></category>

		<guid isPermaLink="false">http://adventuresinmachinelearning.com/?p=1013</guid>
		<description><![CDATA[<p>TensorFlow is a great deep learning framework. In fact, it is still the reigning monarch within the deep learning framework kingdom. However, it has some <a class="mh-excerpt-more" href="http://adventuresinmachinelearning.com/tensorflow-eager-tutorial/" title="TensorFlow Eager tutorial">[...]</a></p>
<p>The post <a rel="nofollow" href="http://adventuresinmachinelearning.com/tensorflow-eager-tutorial/">TensorFlow Eager tutorial</a> appeared first on <a rel="nofollow" href="http://adventuresinmachinelearning.com">Adventures in Machine Learning</a>.</p>
]]></description>
				<content:encoded><![CDATA[<p>TensorFlow is a great deep learning framework. In fact, it is still the reigning monarch within the deep learning framework kingdom. However, it has some frustrating limitations. One of these is the difficulties that arise during debugging. In TensorFlow, it&#8217;s difficult to diagnose what is happening in your model. This is due to its <em>static graph</em> structure (for details, see <a href="http://adventuresinmachinelearning.com/python-tensorflow-tutorial/">my TensorFlow tutorial</a>) &#8211; in TensorFlow the developer has to first create the full set of graph operations, and only then are these operations compiled with a TensorFlow session object and fed data. Wouldn&#8217;t it be great if you could define operations, then immediately run  data through them to observe what the output was? Or wouldn&#8217;t it be great to set standard Python debug breakpoints within your code, so you can step into your deep learning training loops wherever and whenever you like and examine the tensors and arrays in your models? This is now possible using the TensorFlow Eager API, available in the latest version of TensorFlow.</p>
<p>The TensorFlow Eager API allows you to dynamically create your model in an imperative programming framework. In other words, you can create tensors, operations and other TensorFlow objects by typing the command into Python, and run them straight way without the need to set up the usual session infrastructure. This is useful for debugging, as mentioned above, but also it allows dynamic adjustments of deep learning models as training progresses. In fact, in natural language processing, the ability to create dynamic graphs is useful, given that sentences and other utterances in natural language have varying lengths. In this TensorFlow Eager tutorial, I&#8217;ll show you the basics of the new API and also show how you can use it to create a fully fledged convolutional neural network.</p>
<hr />
<p><strong>Recommended video course &#8211; </strong>If you&#8217;d like to learn more about TensorFlow, and you&#8217;re more of a video learner, check out this cheap online course: <a href="https://click.linksynergy.com/link?id=Jbc0N5ZkDzk&amp;offerid=323058.1326292&amp;type=2&amp;murl=https%3A%2F%2Fwww.udemy.com%2Fcomplete-guide-to-tensorflow-for-deep-learning-with-python%2F">Complete Guide to TensorFlow for Deep Learning with Python</a><img src="https://ad.linksynergy.com/fs-bin/show?id=Jbc0N5ZkDzk&amp;bids=323058.1326292&amp;type=2&amp;subid=0" width="1" height="1" border="0" /></p>
<hr />
<h1>TensorFlow Eager basics</h1>
<p>The first thing you need to do to use TensorFlow Eager is to enable Eager execution. To do so, you can run the following (note, you can type this directly into your Python interpreter):</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">import tensorflow as tf
tf.enable_eager_execution()</code></pre> <div class="code-embed-infos"> </div> </div>
<p>Now you can define TensorFlow operations and run them on the fly. In the code below, a numpy range from 0 to 9 is multiplied by a scalar value of 10, using the TensorFlow <em>multiply</em> operation:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># simple example
z = tf.constant(np.arange(10))
z_tf = tf.multiply(z, np.array(10))
print(z_tf)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>This code snippet will output the following:</p>
<p>tf.Tensor([ 0 10 20 30 40 50 60 70 80 90], shape=(10,), dtype=int32)</p>
<p>Notice we can immediately access the results of the operation. If we ran the above without running the <em>tf.enable_eager_execution()</em> command, we would instead see the definition of the TensorFlow operation i.e.:</p>
<p>Tensor(&#8220;Mul:0&#8221;, shape=(10,), dtype=int32)</p>
<p>Notice also how easily TensorFlow Eager interacts with the numpy framework. So far, so good. Now, the main component of any deep learning API is how gradients are handled &#8211; this will be addressed in the next section.</p>
<h2>Gradients in TensorFlow Eager</h2>
<p>Gradient calculation is necessary in neural networks during the back-propagation stage (if you&#8217;d like to know more, check out <a href="http://adventuresinmachinelearning.com/neural-networks-tutorial/">my neural networks tutorial</a>). The gradient calculations in the TensorFlow Eager API work similarly to the <a href="https://github.com/HIPS/autograd" target="_blank" rel="noopener">autograd</a> package used in <a href="http://adventuresinmachinelearning.com/pytorch-tutorial-deep-learning/" target="_blank" rel="noopener">PyTorch</a>. To calculate the gradient of an operation using Eager, you can use the <em>gradients_function()</em> operation. The code below calculates the gradient for an $x^3$ function:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">import tensorflow.contrib.eager as tfe
def f_cubed(x):
    return x**3
grad = tfe.gradients_function(f_cubed)
grad(3.)[0].numpy()</code></pre> <div class="code-embed-infos"> </div> </div>
<p>Notice the use of <em>tfe.gradients_function(f_cubed</em>) &#8211; when called, this operation will return the gradient of <em>df/dx</em> for the <em>x</em> value. The code above returns the value 27 &#8211; this makes sense as the derivative of $x^3$ is $3x^2 = 3 * 3^2 = 27$. The final line shows the <em>grad</em> operation, and then the conversion of the output to a numpy scalar i.e. a float value.</p>
<p>We can show the use of this <em>gradients_function</em> in a more complicated example &#8211; polynomial line fitting. In this example, we will use TensorFlow Eager to discover the weights of a noisy 3rd order polynomial. This is what the line looks like:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">x = np.arange(0, 5, 0.1)
y = x**3 - 4*x**2 - 2*x + 2
y_noise = y + np.random.normal(0, 1.5, size=(len(x),))
plt.close(&quot;all&quot;)
plt.plot(x, y)
plt.scatter(x, y_noise)</code></pre> <div class="code-embed-infos"> </div> </div>
<figure id="attachment_1017" style="width: 380px" class="wp-caption aligncenter"><img class="size-full wp-image-1017" src="http://adventuresinmachinelearning.com/wp-content/uploads/2018/08/Noisy-polynomial.png" alt="TensorFlow Eager tutorial - noisy polynomial" width="380" height="252" srcset="http://adventuresinmachinelearning.com/wp-content/uploads/2018/08/Noisy-polynomial.png 380w, http://adventuresinmachinelearning.com/wp-content/uploads/2018/08/Noisy-polynomial-300x199.png 300w" sizes="(max-width: 380px) 100vw, 380px" /><figcaption class="wp-caption-text">A noisy polynomial to fit</figcaption></figure>
<p>As can be observed from the code, the polynomial is expressed as $x^3 &#8211; 4x^2 &#8211; 2x +2$ with some random noise added. Therefore, we want our code to find a &#8220;weight&#8221; vector of approximately [1, -4, -2, 2]. First, let&#8217;s define a few functions:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">def get_batch(x, y, batch_size=20):
    idxs = np.random.randint(0, len(x), (batch_size))
    return x[idxs], y[idxs]

class PolyModel(object):
    def __init__(self):
        self.w = tfe.Variable(tf.random_normal([4]))
        
    def f(self, x):
        return self.w[0] * x ** 3 + self.w[1] * x ** 2 + self.w[2] * x + self.w[3]

def loss(model, x, y):
    err = model.f(x) - y
    return tf.reduce_mean(tf.square(err))</code></pre> <div class="code-embed-infos"> </div> </div>
<p>The first function is a simple randomized batching function.  The second is a class definition for our polynomial model. Upon initialization, we create a weight variable <em>self.w</em> and set to a TensorFlow Eager variable type, randomly initialized as a 4 length vector. Next, we define a function <i>f</i> which returns the weight vector by the third order polynomial form. Finally, we have a loss function defined, which returns the mean squared error between the current model output and the noisy <em>y </em>vector.</p>
<p>To train the model, we can run the following:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">model = PolyModel()
grad = tfe.implicit_gradients(loss)
optimizer = tf.train.AdamOptimizer()
iters = 20000
for i in range(iters):
    x_batch, y_batch = get_batch(x, y)
    optimizer.apply_gradients(grad(model, x_batch, y_batch))
    if i % 1000 == 0:
        print(&quot;Iteration {}, loss: {}&quot;.format(i+1, loss(model, x_batch, y_batch).numpy()))</code></pre> <div class="code-embed-infos"> </div> </div>
<p>First, we create a model and then use a TensorFlow Eager function called <em>implicit_gradients</em>. This function will detect any upstream or parent gradients involved in calculating the loss, which is handy. We are using a standard Adam optimizer for this task. Finally a loop begins, which supplies the batch data and the model to the gradient function. Then the program applies the returned gradients to the optimizer to perform the optimizing step.</p>
<p>After running this code, we get the following output graph:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">plt.close(&quot;all&quot;)
plt.plot(x, y)
plt.plot(x, model.f(x).numpy())
plt.scatter(x, y_noise)</code></pre> <div class="code-embed-infos"> </div> </div>
<figure id="attachment_1019" style="width: 380px" class="wp-caption aligncenter"><img class="size-full wp-image-1019" src="http://adventuresinmachinelearning.com/wp-content/uploads/2018/08/Noisy-polynomial-fitted.png" alt="TensorFlow Eager - noisy polynomial fit" width="380" height="252" srcset="http://adventuresinmachinelearning.com/wp-content/uploads/2018/08/Noisy-polynomial-fitted.png 380w, http://adventuresinmachinelearning.com/wp-content/uploads/2018/08/Noisy-polynomial-fitted-300x199.png 300w" sizes="(max-width: 380px) 100vw, 380px" /><figcaption class="wp-caption-text">A noisy polynomial with a fitted function</figcaption></figure>
<p>The orange line is the fitted line, the blue is the &#8220;ground truth&#8221;. Not perfect, but not too bad.</p>
<p>Next, I&#8217;ll show you how to use TensorFlow Eager to create a proper neural network classifier trained on the MNIST dataset.</p>
<h1>A neural network with TensorFlow Eager</h1>
<p>In the code below, I&#8217;ll show you how to create a Convolutional Neural Network to classify MNIST images using TensorFlow Eager. If you&#8217;re not sure about Convolutional Neural Networks, you can check out <a href="http://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-tensorflow/">my tutorial here</a>. The first part of the code shows you how to extract the MNIST dataset:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">mnist = tf.keras.datasets.mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()</code></pre> <div class="code-embed-infos"> </div> </div>
<p>In the case above, we are making use of the Keras datasets now available in TensorFlow (by the way, the Keras deep learning framework is now heavily embedded within TensorFlow &#8211; to learn more about <a href="http://adventuresinmachinelearning.com/keras-tutorial-cnn-11-lines/">Keras see my tutorial</a>). The raw MNIST image dataset has values ranging from 0 to 255 which represent the grayscale values &#8211; these need to be scaled to between 0 and 1. The function below accomplishes this:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">def scale(x, min_val=0.0, max_val=255.0):
    x = tf.to_float(x)
    return tf.div(tf.subtract(x, min_val), tf.subtract(max_val, min_val))</code></pre> <div class="code-embed-infos"> </div> </div>
<p>Next, in order to setup the Keras image dataset into a TensorFlow Dataset object, we use the following code. This code creates a scaled training and testing dataset. This dataset is also randomly shuffled and ready for batch extraction. It also applies the <em>tf.one_hot </em>function to the labels to convert the integer label to a one hot vector of length 10 (one for each hand-written digit). If you&#8217;re not familiar with the TensorFlow Dataset API, check out <a href="http://adventuresinmachinelearning.com/tensorflow-dataset-tutorial/">my TensorFlow Dataset tutorial</a>.</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))
train_ds = train_ds.map(lambda x, y: (scale(x), tf.one_hot(y, 10))).shuffle(10000).batch(30)
test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))
test_ds = test_ds.map(lambda x, y: (scale(x), tf.one_hot(y, 10))).shuffle(10000).batch(30)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>The next section of code creates the MNIST model itself, which will be trained. The best practice at the moment for TensorFlow Eager is to create a class definition for the model which inherits from the tf.keras.Model class. This is useful for a number of reasons, but the main one for our purposes is the ability to call on the model.variables property when determining Eager gradients, and this &#8220;gathers together&#8221; all the trainable variables within the model. The code looks like:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">class MNISTModel(tf.keras.Model):
    def __init__(self, device=&#039;cpu:0&#039;):
        super(MNISTModel, self).__init__()
        self.device = device
        self._input_shape = [-1, 28, 28, 1]
        self.conv1 = tf.layers.Conv2D(32, 5,
                                  padding=&#039;same&#039;,
                                  activation=tf.nn.relu)
        self.max_pool2d = tf.layers.MaxPooling2D((2, 2), (2, 2), padding=&#039;same&#039;)
        self.conv2 = tf.layers.Conv2D(64, 5,
                                      padding=&#039;same&#039;,
                                      activation=tf.nn.relu)
        self.fc1 = tf.layers.Dense(750, activation=tf.nn.relu)
        self.dropout = tf.layers.Dropout(0.5)
        self.fc2 = tf.layers.Dense(10)
    
    def call(self, x):
        x = tf.reshape(x, self._input_shape)
        x = self.max_pool2d(self.conv1(x))
        x = self.max_pool2d(self.conv2(x))
        x = tf.layers.flatten(x)
        x = self.dropout(self.fc1(x))
        return self.fc2(x)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>In the model definition, we create layers to implement the following network structure:</p>
<ol>
<li>32 channel, 5&#215;5 convolutional layer with ReLU activation</li>
<li>2&#215;2 max pooling, with (2,2) strides</li>
<li>64 channel 5&#215;5 convolutional layer with ReLU activation</li>
<li>Flattening</li>
<li>Dense/Fully connected layer with 750 nodes, ReLU activation</li>
<li>Dropout layer</li>
<li>Dense/Fully connected layer with 10 nodes, no activation</li>
</ol>
<p>As stated above, if you&#8217;re not sure what these terms mean, see my <a href="http://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-tensorflow/">Convolutional Neural Network tutorial</a>. Note that the <em>call </em>method is a mandatory method for the tf.keras.Model superclass &#8211; it is where the forward pass through the model is defined.</p>
<p>The next function is the loss function for the optimization:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">def loss_fn(model, x, y):
    return tf.reduce_mean(
      tf.nn.softmax_cross_entropy_with_logits_v2(
          logits=model(x), labels=y))</code></pre> <div class="code-embed-infos"> </div> </div>
<p>Note that this function calls the forward pass through the model (which is an instance of our MNISTModel) and calculates the &#8220;raw&#8221; output. This raw output, along with the labels, passes through to the TensorFlow function <em>softmax_cross_entropy_with_logits_v2</em>. This applies the softmax activation to the &#8220;raw&#8221; output from the model, then creates a cross entropy loss.</p>
<p>Next, I define an accuracy function below, to keep track of how the training is progressing regarding training set accuracy, and also to check test set accuracy:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">def get_accuracy(model, x, y_true):
    logits = model(x)
    prediction = tf.argmax(logits, 1)
    equality = tf.equal(prediction, tf.argmax(y_true, 1))
    accuracy = tf.reduce_mean(tf.cast(equality, tf.float32))
    return accuracy</code></pre> <div class="code-embed-infos"> </div> </div>
<p>Finally, the full training code for the model is shown below:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">model = MNISTModel()
optimizer = tf.train.AdamOptimizer()
epochs = 1000
for (batch, (images, labels)) in enumerate(train_ds):
    with tfe.GradientTape() as tape:
        loss = loss_fn(model, images, labels)
    grads = tape.gradient(loss, model.variables)
    optimizer.apply_gradients(zip(grads, model.variables), global_step=tf.train.get_or_create_global_step())
    if batch % 10 == 0:
        acc = get_accuracy(model, images, labels).numpy()
        print(&quot;Iteration {}, loss: {:.3f}, train accuracy: {:.2f}%&quot;.format(batch, loss_fn(model, images, labels).numpy(), acc*100))
    if batch &gt; epochs:
        break</code></pre> <div class="code-embed-infos"> </div> </div>
<p>In the code above, we create the model along with an optimizer. The code then enters the training loop, by iterating over the training dataset <em>train_ds</em>. Then follows the definition of the gradients for the model. Here we are using the TensorFlow Eager object called <em>GradientTape()</em>. This is an efficient way of defining the gradients over all the variables involved in the forward pass. It will track all the operations during the forward pass and will efficiently &#8220;play back&#8221; these operations during back-propagation.</p>
<p>Using the Python <em>with </em>functionality, we can include the <em>loss</em><em>_fn</em> function, and all associated upstream variables and operations, within the tape to be recorded. Then, to extract the gradients of the relevant model variables, we call <em>tape.gradient. </em>The first argument is the &#8220;target&#8221; for the calculation, i.e. the loss, and the second argument is the &#8220;source&#8221; i.e. all the model variables.</p>
<p>We then pass the gradients and the variables zipped together to the Adam optimizer for a training step. Every 10 iterations some results are printed and the training loop exits if the iterations number exceeds the maximum number of epochs.</p>
<p>Running this code for 1000 iterations will give you a loss &lt; 0.05, and training set accuracy approaching 100%. The code below calculates the test set accuracy:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">avg_acc = 0
test_epochs = 20
for (batch, (images, labels)) in enumerate(test_ds):
    avg_acc += get_accuracy(model, images, labels).numpy()
    if batch % 100 == 0 and batch != 0:
        print(&quot;Iteration:{}, Average test accuracy: {:.2f}%&quot;.format(batch, (avg_acc/batch)*100))
print(&quot;Final test accuracy: {:.2f}%&quot;.format(avg_acc/batch * 100))</code></pre> <div class="code-embed-infos"> </div> </div>
<p>You should be able to get a test set accuracy, using the code defined above, on the order of 98% or greater for the trained model.</p>
<p>In this post, I&#8217;ve shown you the basics of using the TensorFlow Eager API for imperative deep learning. I&#8217;ve also shown you how to use the autograd-like functionality to perform a polynomial line fitting task and build a convolutional neural network which achieves relatively high test set accuracy for the MNIST classification task. Hopefully you can now use this new TensorFlow paradigm to reduce development time and enhance debugging for your future TensorFlow projects. All the best!</p>
<hr />
<p><strong>Recommended video course &#8211; </strong>If you&#8217;d like to learn more about TensorFlow, and you&#8217;re more of a video learner, check out this cheap online course: <a href="https://click.linksynergy.com/link?id=Jbc0N5ZkDzk&amp;offerid=323058.1326292&amp;type=2&amp;murl=https%3A%2F%2Fwww.udemy.com%2Fcomplete-guide-to-tensorflow-for-deep-learning-with-python%2F">Complete Guide to TensorFlow for Deep Learning with Python</a><img src="https://ad.linksynergy.com/fs-bin/show?id=Jbc0N5ZkDzk&amp;bids=323058.1326292&amp;type=2&amp;subid=0" width="1" height="1" border="0" /></p>
<hr />
<p>&nbsp;</p>
<p>The post <a rel="nofollow" href="http://adventuresinmachinelearning.com/tensorflow-eager-tutorial/">TensorFlow Eager tutorial</a> appeared first on <a rel="nofollow" href="http://adventuresinmachinelearning.com">Adventures in Machine Learning</a>.</p>
]]></content:encoded>
			<wfw:commentRss>http://adventuresinmachinelearning.com/tensorflow-eager-tutorial/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>Reinforcement learning tutorial with TensorFlow</title>
		<link>http://adventuresinmachinelearning.com/reinforcement-learning-tensorflow/</link>
		<comments>http://adventuresinmachinelearning.com/reinforcement-learning-tensorflow/#comments</comments>
		<pubDate>Fri, 06 Jul 2018 01:16:59 +0000</pubDate>
		<dc:creator><![CDATA[Andy]]></dc:creator>
				<category><![CDATA[Reinforcement learning]]></category>
		<category><![CDATA[TensorFlow]]></category>

		<guid isPermaLink="false">http://adventuresinmachinelearning.com/?p=959</guid>
		<description><![CDATA[<p>Reinforcement learning has gained significant attention with the relatively recent success of DeepMind&#8217;s AlphaGo system defeating the world champion Go player. The AlphaGo system was <a class="mh-excerpt-more" href="http://adventuresinmachinelearning.com/reinforcement-learning-tensorflow/" title="Reinforcement learning tutorial with TensorFlow">[...]</a></p>
<p>The post <a rel="nofollow" href="http://adventuresinmachinelearning.com/reinforcement-learning-tensorflow/">Reinforcement learning tutorial with TensorFlow</a> appeared first on <a rel="nofollow" href="http://adventuresinmachinelearning.com">Adventures in Machine Learning</a>.</p>
]]></description>
				<content:encoded><![CDATA[<p>Reinforcement learning has gained significant attention with the relatively recent success of DeepMind&#8217;s AlphaGo system defeating the world champion Go player. The AlphaGo system was trained in part by reinforcement learning on deep neural networks. This type of learning is a different aspect of machine learning from the classical supervised and unsupervised paradigms. In reinforcement learning using deep neural networks, the network reacts to environmental data (called the <em>state</em>) and controls the <em>actions</em> of an <em>agent</em> to attempt to maximize a <em>reward</em>. This process allows a network to learn to play <em>games, </em>such as Atari or other video games, or any other problem that can be recast as some form of game. In this tutorial, I&#8217;ll introduce the broad concepts of Q learning, a popular reinforcement learning paradigm, and I&#8217;ll show how to implement deep Q learning in TensorFlow. If you need to get up to speed in TensorFlow, check out <a href="http://adventuresinmachinelearning.com/python-tensorflow-tutorial/" target="_blank" rel="noopener">my introductory tutorial</a>.</p>
<hr />
<p><strong>Recommended online course &#8211; </strong>If you are more of a video learner, check out this inexpensive online course: <a href="https://click.linksynergy.com/link?id=Jbc0N5ZkDzk&amp;offerid=323058.1153742&amp;type=2&amp;murl=https%3A%2F%2Fwww.udemy.com%2Fdeep-reinforcement-learning-in-python%2F">Advanced AI: Deep Reinforcement Learning in Python</a><img src="https://ad.linksynergy.com/fs-bin/show?id=Jbc0N5ZkDzk&amp;bids=323058.1153742&amp;type=2&amp;subid=0" width="1" height="1" border="0" /></p>
<hr />
<h1>Introduction to reinforcement learning</h1>
<p>As stated above, reinforcement learning comprises of a few fundamental entities or concepts. They are: an <em>environment</em> which produces a <em>state</em> and <em>reward</em>, and an <em>agent </em>which performs <em>actions</em> in the given environment. This interaction can be seen in the diagram below:</p>
<figure id="attachment_768" style="width: 381px" class="wp-caption aligncenter"><img class="size-full wp-image-768" src="http://adventuresinmachinelearning.com/wp-content/uploads/2018/02/Reinforcement-learning-environment.png" alt="Reinforcement learning with Python and Keras - Reinforcement learning environment" width="381" height="211" srcset="http://adventuresinmachinelearning.com/wp-content/uploads/2018/02/Reinforcement-learning-environment.png 381w, http://adventuresinmachinelearning.com/wp-content/uploads/2018/02/Reinforcement-learning-environment-300x166.png 300w" sizes="(max-width: 381px) 100vw, 381px" /><figcaption class="wp-caption-text">Reinforcement learning environment</figcaption></figure>
<p>The goal of the agent in such an environment is to examine the state and the reward information it receives, and choose an action which maximizes the reward feedback it receives.  The agent learns by repeated interaction with the environment, or, in other words, repeated playing of the game.</p>
<p>To be successful, the agent needs to:</p>
<ol>
<li>Learn the interaction between states, actions and subsequent rewards</li>
<li>Determine which is the best action to choose given (1)</li>
</ol>
<p>The implementation of (1) involves determining some set of <em>values</em> which can be used to inform (2), and (2) is called the action <em>policy</em>. One of the most common ways of implementing (1) and (2) using deep learning is via the Deep Q network and the <em>epsilon-greedy </em>policy. I&#8217;ll cover both of these concepts in the next two sections.</p>
<h2>Q learning</h2>
<p>Q learning is a value based method of supplying information to inform which action an agent should take. An initially intuitive idea of creating values upon which to base actions is to create a table which sums up the rewards of taking action <em>a </em>in state <em>s</em> over multiple game plays. This could keep track of which moves are the most advantageous. For instance, let&#8217;s consider a simple game which has 3 states and two possible actions in each state &#8211; the rewards for this game can be represented in a table:</p>
<figure id="attachment_961" style="width: 246px" class="wp-caption aligncenter"><img class=" wp-image-961" src="http://adventuresinmachinelearning.com/wp-content/uploads/2018/06/Simple-value-table-reinforcement-learning.png" alt="Reinforcement learning - simple state-action-reward table" width="246" height="109" /><figcaption class="wp-caption-text">Simple state-action-reward table</figcaption></figure>
<p>In the table above, you can see that for this simple game, when the agent is State 1 and takes Action 2, it will receive a reward of 10 but zero reward if it takes Action 1. In State 2, the situation is reversed and finally State 3 resembles State 1. If an agent randomly explored this game, and summed up which actions received the most reward in each of the three states (storing this information in an array, say), then it would basically learn the functional form of the table above.</p>
<p>In other words, if the agent simply chooses the action which it learnt had yielded the highest reward in the past (effectively learning some form of the table above) it would have learnt how to play the game successfully. Why do we need fancy concepts such as Q learning and neural networks then, when simply creating tables by summation is sufficient?</p>
<h3>Deferred reward</h3>
<p>Well, the first obvious answer is that the game above is clearly very simple, with only 3 states and 2 actions per state. Real games are significantly more complex. The other significant concept that is missing in the example above is the idea of <em>deferred reward</em>. To adequately play most realistic games, an agent needs to learn to be able to take actions which may not immediately lead to a reward, but may result in a large reward further down the track.</p>
<p>Consider another game, defined by the table below:</p>
<figure id="attachment_965" style="width: 273px" class="wp-caption aligncenter"><img class=" wp-image-965" src="http://adventuresinmachinelearning.com/wp-content/uploads/2018/06/Simple-delayed-reward-value-table-reinforcement-learning.png" alt="Reinforcement learning with TensorFlow - simple delayed reward value table" width="273" height="138" srcset="http://adventuresinmachinelearning.com/wp-content/uploads/2018/06/Simple-delayed-reward-value-table-reinforcement-learning.png 313w, http://adventuresinmachinelearning.com/wp-content/uploads/2018/06/Simple-delayed-reward-value-table-reinforcement-learning-300x151.png 300w" sizes="(max-width: 273px) 100vw, 273px" /><figcaption class="wp-caption-text">Simple delayed reward value table</figcaption></figure>
<p>In the game defined above, in all states, if Action 2 is taken, the agent moves back to State 1 i.e. it goes back to the beginning. In States 1 to 3, it also receives a reward of 5 when it does so. However, in all States 1 &#8211; 3, if Action 1 is taken, the agent moves forward to the next state, but doesn&#8217;t receive a reward until it reaches State 4 &#8211; at which point it receives a reward of 20. In other words, an agent is better off if it doesn&#8217;t take Action 2 to get an instantaneous reward of 5, but rather it should choose Action 1 consistently to progress through the states to get the reward of 20. The agent needs to be able to select actions which result in a <em>delayed </em><em>reward, </em>if the delayed reward value is sufficiently large.</p>
<h3>The Q learning rule</h3>
<p>This allows us to define the Q learning rule. In deep Q learning, the neural network needs to take the current state, <em>s</em>, as a variable and return a Q value for each possible action, <em>a</em>, in that state &#8211; i.e. it needs to return $Q(s,a)$ for all <em>s</em> and <em>a</em>. This $Q(s,a)$ needs to be updated in training via the following rule:</p>
<p>$$Q(s,a) \leftarrow  Q(s,a) + \alpha [r + \gamma \max_{a&#8217;} Q(s&#8217;, a&#8217;) &#8211; Q(s,a)]$$</p>
<p>This updating rule needs a bit of unpacking. First, you can see that the new value of $Q(s,a)$ involves updating it&#8217;s current value by adding on some extra bits on the right hand side of the equation above. Moving left to right, ignore the $\alpha$ for a bit. We see inside the square brackets the first term is <em>r</em> which stands for the reward that is received for taking action <em>a</em> in state <em>s</em>. This is the immediate reward, no delayed gratification is involved yet.</p>
<p>The next term is the delayed reward calculation. First, we have the $\gamma$ value which discounts the delayed reward impact &#8211; it is always between 0 and 1. More on that in a second. The next term $\max_{a&#8217;} Q(s&#8217;, a&#8217;)$ is the maximum Q value possible in the next state. Let&#8217;s make that a bit clearer &#8211; the agent starts in state <em>s</em>, takes action <em>a, </em>ends up in state <em>s&#8217;</em> and then the code determines the maximum Q value in state <em>s&#8217;</em>  i.e. $\max_{a&#8217;} Q(s&#8217;, a&#8217;)$.</p>
<p>So why is the value $\max_{a&#8217;} Q(s&#8217;, a&#8217;)$ considered? It is considered because it represents the maximum future reward coming to the agent if it takes action <em>a </em>in state <em>s</em>. However, this value is discounted by $\gamma$ to take into account that it isn&#8217;t ideal for the agent to wait forever for a future reward &#8211; it is best for the agent to aim for the maximum award in the least period of time. Note that the value $Q(s&#8217;,a&#8217;)$ implicitly also holds the maximum discounted reward for the state after that, i.e. $Q(s&#8221;, a&#8221;)$ and likewise, it holds the discounted reward for the state $Q(s&#8221;&#8217;, a&#8221;&#8217;)$ and so on. This is how the agent can choose the action <em>a </em>based on not just the immediate reward <em>r</em>, but also based on possible future discounted rewards.</p>
<p>The final components in the formula above are the $\alpha$ value, which is the learning rate during the updating, and finally the current state, $Q(s,a)$, which is subtracted from the square bracket sum. This is done to normalize the updating. Both $\alpha$ and the $Q(s,a)$ subtraction are not required to be explicitly defined in deep Q learning, as the neural network will take care of that during its optimized learning process. This process will be discussed in the next section.</p>
<h3>Deep Q learning</h3>
<p>Deep Q learning applies the Q learning updating rule during the training process. In other words, a neural network is created which takes the state <em>s </em>as its input, and then the network is trained to output appropriate <em>Q(s,a)</em> values for each action in state <em>s</em>. The action <em>a </em>of the agent can then be chosen by taking the action with the greatest <em>Q(s,a)</em> value (by taking an <em>argmax</em> of the output of the neural network). This can be seen in the first step of the diagram below:</p>
<figure id="attachment_984" style="width: 1252px" class="wp-caption alignnone"><img class="size-full wp-image-984" src="http://adventuresinmachinelearning.com/wp-content/uploads/2018/06/Deep-Q-learning-environment.png" alt="Reinforcement learning TensorFlow - action and training steps" width="1252" height="675" srcset="http://adventuresinmachinelearning.com/wp-content/uploads/2018/06/Deep-Q-learning-environment.png 1252w, http://adventuresinmachinelearning.com/wp-content/uploads/2018/06/Deep-Q-learning-environment-300x162.png 300w, http://adventuresinmachinelearning.com/wp-content/uploads/2018/06/Deep-Q-learning-environment-768x414.png 768w, http://adventuresinmachinelearning.com/wp-content/uploads/2018/06/Deep-Q-learning-environment-1024x552.png 1024w" sizes="(max-width: 1252px) 100vw, 1252px" /><figcaption class="wp-caption-text">Action selecting and training steps &#8211; Deep Q learning</figcaption></figure>
<p>Once this step has been taken and an action has been selected, the agent can perform that action. The agent will then receive feedback on what reward is received by taking that action from that state. Now, the next step that we want to perform is to train the network according to the Q learning rule. This can be seen in the second part of the diagram above. The <em>x</em> input array for training the network is the state vector <em>s</em>, and the <em>y</em> output training sample is the <em>Q(s,a) </em>vector retrieved during the action selection step. However, one of the <em>Q(s,a)</em> values, corresponding to action <em>a</em>, is set to have a target of $r + \gamma Q(s&#8217;, a&#8217;)$ &#8211; this can be observed in the figure above.</p>
<p>By training the network in this way, the <em>Q(s,a)</em> output vector from the network will over time become better at informing the agent what action will be the best to select for its long term gain. There is a bit more to the story about action selection, however, which will be discussed in the next section.</p>
<h2>The epsilon-greedy policy</h2>
<p>In the explanation above, the action selection policy was simply the action which corresponded to the highest Q output from the neural network. However, this policy isn&#8217;t the most effective. Why is that? It is because, when the neural network is randomly initialized, it will be predisposed to select certain sub-optimal actions randomly. This may cause the agent to fall into sub-optimal behavior patterns without thoroughly exploring the game and action / reward space. As such, the agent won&#8217;t find the best strategies to play the game.</p>
<p>It is useful here to introduce two concepts &#8211; <em>exploration </em>and <em>exploitation. </em>At the beginning of an optimization problem, it is best to allow the problem space to be explored extensively in the hope of finding good local (or even global) minima. However, once the problem space has been adequately searched, it is now best for the optimization algorithm to focus on exploiting what it has found by converging on the best minima to arrive at a good solution.</p>
<p>Therefore, in reinforcement learning, it is best to allow some randomness in the action selection at the beginning of the training. This randomness is determined by the <em>epsilon</em> parameter. Essentially, a random number is drawn between 0 and 1, and if it is less than <em>epsilon, </em>then a random action is selection. If not, an action is selected based on the output of the neural network. The <em>epsilon </em>variable usually starts somewhere close to 1, and is slowly decayed to somewhere around 0 during training. This allows a large exploration of the game at the beginning, but then the decay of the <em>epsilon </em>value allows the network to zero in on a good solution.</p>
<p>We&#8217;re almost at the point where we can check out the game that will be used in this example, and begin to build our deep Q network. However, there is just one final important point to consider.</p>
<h2>Batching in reinforcement learning</h2>
<p>If a deep Q network is trained at each step in the game i.e. after each action is performed and the reward collected, there is a strong risk of over-fitting in the network. This is because game play is highly correlated i.e. if the game starts from the same place and the agent performs the same actions, there will likely be similar results each time (not exactly the same though, because of randomness in some games). Therefore, after each action it is a good idea to add all the data about the state, reward, action and the new state into some sort of <em>memory</em>. This memory can then be randomly sampled in batches to avoid the risk of over-fitting.</p>
<p>The network can therefore still be trained after each step if you desire (or less frequently, it&#8217;s up to the developer), but it is extracting the training data not from the agent&#8217;s ordered steps through the game, but rather a randomized memory of previous steps and outcomes that the agent has experienced. You&#8217;ll be able to see how this works in the code below.</p>
<p>We are now ready to examine the game/environment that we will develop our network to learn.</p>
<h1>The Mountain Car Environment and Open AI Gym</h1>
<p>In this reinforcement learning tutorial, the deep Q network that will be created will be trained on the Mountain Car environment/game. This can be accessed through the open source reinforcement learning library called <a href="https://gym.openai.com/" target="_blank" rel="noopener">Open AI Gym</a>. A screen capture from the rendered game can be observed below:</p>
<figure id="attachment_992" style="width: 383px" class="wp-caption aligncenter"><img class=" wp-image-992" src="http://adventuresinmachinelearning.com/wp-content/uploads/2018/06/MountainCarGame.png" alt="Reinforcement learning TensorFlow - Mountain Car game" width="383" height="258" srcset="http://adventuresinmachinelearning.com/wp-content/uploads/2018/06/MountainCarGame.png 895w, http://adventuresinmachinelearning.com/wp-content/uploads/2018/06/MountainCarGame-300x202.png 300w, http://adventuresinmachinelearning.com/wp-content/uploads/2018/06/MountainCarGame-768x517.png 768w" sizes="(max-width: 383px) 100vw, 383px" /><figcaption class="wp-caption-text">Mountain Car game</figcaption></figure>
<p>The object of this game is to get the car to go up the right-side hill to get to the flag. There&#8217;s one problem however, the car doesn&#8217;t have enough power to motor all the way up the hill. Instead, the car / agent needs to learn that it must motor up one hill for a bit, then accelerate down the hill and back up the other side, and repeat until it builds up enough momentum to make it to the top of the hill.</p>
<p>As stated above, Open AI Gym is an open source reinforcement learning package that allows developers to interact easily with games such as the Mountain Car environment. You can find details about the Mountain Car environment <a href="https://github.com/openai/gym/wiki/MountainCar-v0" target="_blank" rel="noopener">here</a>. Basically, the environment is represented by a two-element state vector, detailed below:</p>
<figure id="attachment_994" style="width: 302px" class="wp-caption aligncenter"><img class=" wp-image-994" src="http://adventuresinmachinelearning.com/wp-content/uploads/2018/06/MountainCareState.png" alt="Reinforcement learning - TensorFlow state vector" width="302" height="115" srcset="http://adventuresinmachinelearning.com/wp-content/uploads/2018/06/MountainCareState.png 462w, http://adventuresinmachinelearning.com/wp-content/uploads/2018/06/MountainCareState-300x114.png 300w" sizes="(max-width: 302px) 100vw, 302px" /><figcaption class="wp-caption-text">Mountain Car state vector</figcaption></figure>
<p>As can be observed, the agent&#8217;s state is represented by the car&#8217;s position and velocity. The goal/flag is sitting at a position = 0.5. The actions available to the agent are shown below:</p>
<figure id="attachment_995" style="width: 188px" class="wp-caption aligncenter"><img class=" wp-image-995" src="http://adventuresinmachinelearning.com/wp-content/uploads/2018/06/MountainCareActions.png" alt="Reinforcement learning TensorFlow - mountain car actions" width="188" height="154" /><figcaption class="wp-caption-text">Mountain Car actions</figcaption></figure>
<p>As can be observed, there are three actions available to the agent &#8211; accelerate to the left, right and no acceleration.</p>
<p>In the game&#8217;s default arrangement, for each time step where the car&#8217;s position is &lt;0.5, it receives a reward of -1, up to a maximum of 200 time steps. So the incentive for the agent is to get the car&#8217;s position to &gt;0.5 as soon as possible, after which the game ends. This will minimize the negative reward, which is the aim of the game.</p>
<p>However, in this default arrangement, it will take a significant period of time of random exploration before the car stumbles across the positive feedback of getting to the flag. As such, to speed things up a bit, in this example we&#8217;ll alter the reward structure to:</p>
<ul>
<li>Position &gt; 0.1, r += 10</li>
<li>Position &gt; 0.25 r += 20</li>
<li>Position &gt; 0.5 r += 100</li>
</ul>
<p>This new reward structure gives the agent better positive feedback when it starts learning how to ascend the hill on the right hand side toward the flag. The position of 0.1 is just over half way up the right-hand hill.</p>
<p>Ok, so now you know the environment, let&#8217;s write some code!</p>
<h1>Reinforcement learning in TensorFlow</h1>
<p>In this reinforcement learning implementation in TensorFlow, I&#8217;m going to split the code up into three main classes, these classes are:</p>
<ul>
<li>Model: This class holds the TensorFlow operations and model definitions</li>
<li>Memory: This class is where the memory of the actions, rewards and states are stored and retrieved from</li>
<li>GameRunner: This class is the main training and agent control class</li>
</ul>
<p>As stated before, I&#8217;ll be assuming some prior knowledge of TensorFlow here. If you&#8217;re not up to speed your welcome to wing it. Otherwise check out my <a href="http://adventuresinmachinelearning.com/python-tensorflow-tutorial/" target="_blank" rel="noopener">TensorFlow tutorial</a>. All the code for this tutorial can be found on <a href="https://github.com/adventuresinML/adventures-in-ml-code" target="_blank" rel="noopener">this site&#8217;s Github repository</a>.</p>
<p>I&#8217;ll go through each of the classes in turn in the sub-sections below.</p>
<h2>The Model class</h2>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">class Model:
    def __init__(self, num_states, num_actions, batch_size):
        self._num_states = num_states
        self._num_actions = num_actions
        self._batch_size = batch_size
        # define the placeholders
        self._states = None
        self._actions = None
        # the output operations
        self._logits = None
        self._optimizer = None
        self._var_init = None
        # now setup the model
        self._define_model()

    def _define_model(self):
        self._states = tf.placeholder(shape=[None, self._num_states], dtype=tf.float32)
        self._q_s_a = tf.placeholder(shape=[None, self._num_actions], dtype=tf.float32)
        # create a couple of fully connected hidden layers
        fc1 = tf.layers.dense(self._states, 50, activation=tf.nn.relu)
        fc2 = tf.layers.dense(fc1, 50, activation=tf.nn.relu)
        self._logits = tf.layers.dense(fc2, self._num_actions)
        loss = tf.losses.mean_squared_error(self._q_s_a, self._logits)
        self._optimizer = tf.train.AdamOptimizer().minimize(loss)
        self._var_init = tf.global_variables_initializer()</code></pre> <div class="code-embed-infos"> </div> </div>
<p>The first function within the class is of course the initialization function. All you need to pass into the Model definition is the number of states of the environment (2 in this game), the number of possible actions (3 in this game) and the batch size. The function simply sets up a few internal variables and operations, some of which are exposed as public properties later in the class definition. At the end of the initialization, the second method displayed above <em>_define_model() </em>is called. This method sets up the model structure and the main operations.</p>
<p>First, two placeholders are created <em>_states</em> and <em>_q_s_a</em> &#8211; these hold the state data and the $Q(s,a)$ training data respectively. The first dimension of these placeholders is set to <em>None, </em>so that it will automatically adapt when a batch of training data is fed into the model and also when single predictions from the model are required. The next lines create two fully connected layers <em>fc1 </em>and <em>fc2 </em>using the handy TensorFlow layers module. These hidden layers have 50 nodes each, and they are activated using the ReLU activation function (if you want to know more about the ReLU, check out my <a href="http://adventuresinmachinelearning.com/vanishing-gradient-problem-tensorflow/" target="_blank" rel="noopener">vanishing gradient and ReLU tutorial</a>).</p>
<p>The next layer is the output layer <em>_logits</em> &#8211; this is another fully connected or dense layer, but with no activation supplied. When no activation function is supplied to the dense layer API in TensorFlow, it defaults to a &#8216;linear&#8217; activation i.e. no activation. This is what we want, as we want the network to learn continuous $Q(s,a)$ values across all possible real numbers.</p>
<p>Next comes the <em>loss </em>&#8211; this isn&#8217;t a classification problem, so a good loss to use is simply a mean squared error loss. The next line specifies the optimizer &#8211; in this example, we&#8217;ll just use the generic Adam optimizer. Finally, the TensorFlow boiler plate global variable initializer operation is assigned to <em>_var_init</em>.</p>
<p>So far so good. Next, some methods of the Model class are created to perform prediction and training:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">    def predict_one(self, state, sess):
        return sess.run(self._logits, feed_dict={self._states:
                                                     state.reshape(1, self.num_states)})

    def predict_batch(self, states, sess):
        return sess.run(self._logits, feed_dict={self._states: states})

    def train_batch(self, sess, x_batch, y_batch):
        sess.run(self._optimizer, feed_dict={self._states: x_batch, self._q_s_a: y_batch})</code></pre> <div class="code-embed-infos"> </div> </div>
<p>The first method <em>predict_one</em> simply returns the output of the network (i.e. by calling the <em>_logits</em> operation) with an input of a single state. Note the reshaping operation that is used to ensure that the data has a size (1, num_states). This is called whenever action selection by the agent is required. The next method, <em>predict_batch</em> predicts a whole batch of outputs when given a whole bunch of input states &#8211; this is used to perform batch evaluation of $Q(s,a)$ and $Q(s&#8217;,a&#8217;)$ values for training. Finally, there is a method called <em>train_batch</em> which takes a batch training step of the network.</p>
<p>That&#8217;s the Model class, now it is time to consider the Memory class.</p>
<h2>The Memory class</h2>
<p>The next class to consider in the code is the Memory class &#8211; this class stores all the results of the action of the agent in the game, and also handles the retrieval. These can be used to batch train the network.</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">class Memory:
    def __init__(self, max_memory):
        self._max_memory = max_memory
        self._samples = []

    def add_sample(self, sample):
        self._samples.append(sample)
        if len(self._samples) &gt; self._max_memory:
            self._samples.pop(0)

    def sample(self, no_samples):
        if no_samples &gt; len(self._samples):
            return random.sample(self._samples, len(self._samples))
        else:
            return random.sample(self._samples, no_samples)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>First, when the Memory class is initialized, it is necessary to supply a maximum memory argument &#8211; this will control the maximum number of (state, action, reward, next_state) tuples the <em>_samples</em> list can hold. The bigger the better, as it ensures better random mixing of the samples, but you have to make sure you don&#8217;t run into memory errors.</p>
<p>The first method, <em>add_sample</em> takes an individual (state, action, reward, next_state) tuple and appends it to the <em>_samples </em>list. After this, a check is made &#8211; if the number of samples is now larger than the allowable memory size, the first element in <em>_samples</em> is removed using the Python .pop() list functionality.</p>
<p>The final method, <em>sample</em> returns a random selection of <em>no_samples</em> in length. However, if the <em>no_samples</em> argument is larger than the actual memory, whatever is available in the memory is returned.</p>
<p>The final class is called GameRunner.</p>
<h2>The GameRunner class</h2>
<p>The GameRunner class in this example is where all the model dynamics, agent action and training is organised.</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">class GameRunner:
    def __init__(self, sess, model, env, memory, max_eps, min_eps,
                 decay, render=True):
        self._sess = sess
        self._env = env
        self._model = model
        self._memory = memory
        self._render = render
        self._max_eps = max_eps
        self._min_eps = min_eps
        self._decay = decay
        self._eps = self._max_eps
        self._steps = 0
        self._reward_store = []
        self._max_x_store = []</code></pre> <div class="code-embed-infos"> </div> </div>
<p>In the GameRunner initialization, some internal variables are created. Note, it takes as first argument a TensorFlow session object, then a neural network Model, an Open AI gym environment and a Memory class instance. The next arguments <em>max_eps </em>and <em>min_eps</em> dictate the maximum and minimum epsilon values respectively &#8211; during training the actual $\epsilon$ will decay from the maximum to the minimum based on the following argument <em>decay</em>. Finally, <em>render </em>is a boolean which determines whether the game environment is rendered to the screen.</p>
<p>The next method is <em>run()</em>:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">    def run(self):
        state = self._env.reset()
        tot_reward = 0
        max_x = -100
        while True:
            if self._render:
                self._env.render()

            action = self._choose_action(state)
            next_state, reward, done, info = self._env.step(action)
            if next_state[0] &gt;= 0.1:
                reward += 10
            elif next_state[0] &gt;= 0.25:
                reward += 20
            elif next_state[0] &gt;= 0.5:
                reward += 100

            if next_state[0] &gt; max_x:
                max_x = next_state[0]
            # is the game complete? If so, set the next state to
            # None for storage sake
            if done:
                next_state = None

            self._memory.add_sample((state, action, reward, next_state))
            self._replay()

            # exponentially decay the eps value
            self._steps += 1
            self._eps = MIN_EPSILON + (MAX_EPSILON - MIN_EPSILON) \
                                      * math.exp(-LAMBDA * self._steps)

            # move the agent to the next state and accumulate the reward
            state = next_state
            tot_reward += reward

            # if the game is done, break the loop
            if done:
                self._reward_store.append(tot_reward)
                self._max_x_store.append(max_x)
                break

        print(&quot;Step {}, Total reward: {}, Eps: {}&quot;.format(self._steps, tot_reward, self._eps))</code></pre> <div class="code-embed-infos"> </div> </div>
<p>We&#8217;ll go through each step in the code above. First, the environment is reset by calling the Open AI Gym command .reset(). Then an infinite loop is entered into &#8211; this will be exited by calling a <em>break</em> command. If the boolean _<em>render</em> is True, then the output of the game will be shown on the screen. The <em>action</em> of the agent is determined by calling the internal method <em>_choose_action(state)</em> &#8211; this will discussed later. Next, the agent takes <em>action </em>by calling the Open AI Gym command <em>step(action)</em>. This command returns a tuple containing the new state of the agent, the reward received by taking <em>action</em>, a <em>done </em>boolean indicating whether the game has finished, and an information object (we won&#8217;t using <em>info </em>in this example).</p>
<p>The next step in the code is where there are some manual adjustments to the Mountain Car reward system. If you recall, earlier I mentioned that in order to speed up the training of the network, it was useful to add some more reward steps the closer the car got to the goal (rather than the default reward which was only received when the car reached the goal/flag). The maximum <em>x</em> value achieved in the given episode is also tracked and this will be stored once the game is complete.</p>
<p>The next step is a check to see if the game has completed i.e. <em>done == True</em> &#8211; this will occur after 200 turns. If it has completed, we want to set the <em>next_state</em> to None. This will be picked up during the training / replay step of the class, and the state will be set to an array of zeros whenever <em>next_state</em> is equal to None.</p>
<p>After this, the data about the agent is stored in the memory class &#8211; i.e.its original <em>state</em>, its chosen <em>action</em>, the <em>reward </em>it received for that action and finally the <em>next_state</em> of the agent. After this takes place, the training / replay step of the deep Q network is run &#8211; this step will be discussed more below. At this point the <em>epsilon </em>value is also exponentially decayed. Finally, the agent&#8217;s state is moved to <em>next_state</em>, the total reward during the game is accumulated, and there is some printing and breaking of the loop and storing of relevant variables if the game is complete.</p>
<p>The next part of the GameRunner class is the agent action selection method:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">    def _choose_action(self, state):
        if random.random() &lt; self._eps:
            return random.randint(0, self._model.num_actions - 1)
        else:
            return np.argmax(self._model.predict_one(state, self._sess))</code></pre> <div class="code-embed-infos"> </div> </div>
<p>This method executes our <em>epsilon </em>greedy + Q policy. In the first case, if a random number is less than the <em>_eps</em> value, then the returned action will simply be an action chosen at random from the set of possible actions. Otherwise, the action will be chosen based on an argmax of the output from the neural network. Recall that _<em>predict_one</em> from the model will take a single state as input, then output $Q(s,a)$ values for each of the possible actions available &#8211; the action with the highest $Q(s,a)$ value is that action with the highest expected current + future discounted reward.</p>
<p>The final method within the GameRunner class is the <em>_replay</em> method, where the batching and training takes place:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">    def _replay(self):
        batch = self._memory.sample(self._model.batch_size)
        states = np.array([val[0] for val in batch])
        next_states = np.array([(np.zeros(self._model.num_states)
                                 if val[3] is None else val[3]) for val in batch])
        # predict Q(s,a) given the batch of states
        q_s_a = self._model.predict_batch(states, self._sess)
        # predict Q(s&#039;,a&#039;) - so that we can do gamma * max(Q(s&#039;a&#039;)) below
        q_s_a_d = self._model.predict_batch(next_states, self._sess)
        # setup training arrays
        x = np.zeros((len(batch), self._model.num_states))
        y = np.zeros((len(batch), self._model.num_actions))
        for i, b in enumerate(batch):
            state, action, reward, next_state = b[0], b[1], b[2], b[3]
            # get the current q values for all actions in state
            current_q = q_s_a[i]
            # update the q value for action
            if next_state is None:
                # in this case, the game completed after action, so there is no max Q(s&#039;,a&#039;)
                # prediction possible
                current_q[action] = reward
            else:
                current_q[action] = reward + GAMMA * np.amax(q_s_a_d[i])
            x[i] = state
            y[i] = current_q
        self._model.train_batch(self._sess, x, y)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>The first step in the <em>_replay</em> method is to retrieve a randomized batch of data from memory. Next, we want to setup our batch state variables so that we can:</p>
<ol>
<li>For each state, produce baseline $Q(s,a)$ values &#8211; one of which will be given a target of $r + \gamma \max_{a&#8217;} Q(s&#8217;, a&#8217;)$</li>
<li> For each <em>next_state</em>, predict $Q(s&#8217;,a&#8217;)$ from the model, as required in (1)</li>
</ol>
<p>Now, if you recall, each sample in memory has the form of a tuple: <em>state, action, reward, next_state </em>which was extracted from the game play. To setup a batch of initial states, then, we simply use Python list comprehension to extract the first tuple value from each sample in the batch. Likewise, we do the same for the fourth value in the tuple to extract the <em>next_state</em> value for each sample in the batch. Note that whenever the <em>next_state</em> corresponds to a case where the game finished (i.e. <em>next_state </em>is None) the next state value is replaced by a vector of zeros corresponding in size to the number of states in the game.</p>
<p>Next, the batch of $Q(s, a)$ and $Q(s&#8217;,a&#8217;)$ values are extracted from the model from <em>states </em>and <em>next_states</em> respectively. The <em>x </em>and <em>y</em> training arrays are then created, but initially filled with zeros. After this, a loop is entered into to accumulate the <em>x </em>and <em>y</em> values on which to train the model. Within this loop, we extract the memory values from the batch, then set a variable designating the Q values for the current state. If the <em>next_state</em> value is actually zero, there is no discounted future rewards to add, so the <em>current_q</em> corresponding to <em>action</em> is set a target of the <em>reward</em> only. Alternatively, if there is a valid <em>next_state, </em>then the <em>current_q</em> corresponding to <em>action </em>is set a target of the <em>reward</em> plus the discounted future reward i.e. $max_{a&#8217;} Q(s&#8217;, a&#8217;)$.</p>
<p>The <em>state</em> and <em>current_q</em> are then loaded into the <em>x </em>and <em>y </em>values for the given batch, until the batch data is completely extracted. Then the network is trained by calling <em>_train_batch()</em> on the model.</p>
<p>That completes the review of the main classes within the TensorFlow reinforcement learning example. All that is left is to setup the classes and enter the training loop.</p>
<h2>The main function</h2>
<p>The code below sets up the environment and the classes, and runs multiple games to perform the learning:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">if __name__ == &quot;__main__&quot;:
    env_name = &#039;MountainCar-v0&#039;
    env = gym.make(env_name)

    num_states = env.env.observation_space.shape[0]
    num_actions = env.env.action_space.n

    model = Model(num_states, num_actions, BATCH_SIZE)
    mem = Memory(50000)

    with tf.Session() as sess:
        sess.run(model.var_init)
        gr = GameRunner(sess, model, env, mem, MAX_EPSILON, MIN_EPSILON,
                        LAMBDA)
        num_episodes = 300
        cnt = 0
        while cnt &lt; num_episodes:
            if cnt % 10 == 0:
                print(&#039;Episode {} of {}&#039;.format(cnt+1, num_episodes))
            gr.run()
            cnt += 1
        plt.plot(gr.reward_store)
        plt.show()
        plt.close(&quot;all&quot;)
        plt.plot(gr.max_x_store)
        plt.show()</code></pre> <div class="code-embed-infos"> </div> </div>
<p>In the first couple of lines, we create an Open AI Gym Mountain Car environment. Next, the number of states and actions are extracted from the environment object itself.</p>
<p>The network model and memory objects are then created &#8211; in this case, we&#8217;re using a batch size of 50 and a total number of samples in the memory of 50,000.</p>
<p>The TensorFlow session object is created, along with the variable initialization &#8211; then the GameRunner class is created. The number of episodes of the Mountain Car game which will be run in this training example is 300. For each of these episodes, we run the game by using the GameRunner <em>run()</em> method.</p>
<p>After all the episodes are run, some plotting is performed on the total reward for each episode, and the maximum x-axis value the cart reaches in the game (remembering that the goal is at x = 0.5). These plots can be observed below:</p>
<figure id="attachment_1006" style="width: 473px" class="wp-caption aligncenter"><img class=" wp-image-1006" src="http://adventuresinmachinelearning.com/wp-content/uploads/2018/07/MountainCarRewards.png" alt="Mountain Car rewards - from the TensorFlow reinforcement learning example" width="473" height="355" srcset="http://adventuresinmachinelearning.com/wp-content/uploads/2018/07/MountainCarRewards.png 640w, http://adventuresinmachinelearning.com/wp-content/uploads/2018/07/MountainCarRewards-300x225.png 300w, http://adventuresinmachinelearning.com/wp-content/uploads/2018/07/MountainCarRewards-326x245.png 326w, http://adventuresinmachinelearning.com/wp-content/uploads/2018/07/MountainCarRewards-80x60.png 80w" sizes="(max-width: 473px) 100vw, 473px" /><figcaption class="wp-caption-text">The Mountain Car rewards from the TensorFlow reinforcement learning example</figcaption></figure>
<p>As can be observed, the network starts out controlling the agent rather poorly, while it is exploring the environment and accumulating memory. However once it starts to receive positive rewards by ascending the right-hand hill, the rewards rapidly increase.</p>
<figure id="attachment_1007" style="width: 485px" class="wp-caption aligncenter"><img class=" wp-image-1007" src="http://adventuresinmachinelearning.com/wp-content/uploads/2018/07/MountainCarMaxX.png" alt="Mountain Car maximum X - from the TensorFlow reinforcement learning example" width="485" height="364" srcset="http://adventuresinmachinelearning.com/wp-content/uploads/2018/07/MountainCarMaxX.png 640w, http://adventuresinmachinelearning.com/wp-content/uploads/2018/07/MountainCarMaxX-300x225.png 300w, http://adventuresinmachinelearning.com/wp-content/uploads/2018/07/MountainCarMaxX-326x245.png 326w, http://adventuresinmachinelearning.com/wp-content/uploads/2018/07/MountainCarMaxX-80x60.png 80w" sizes="(max-width: 485px) 100vw, 485px" /><figcaption class="wp-caption-text">The Mountain Car maximum x values from the TensorFlow reinforcement learning example</figcaption></figure>
<p>As can be observed above, while there is some volatility, the network learns that the best rewards are achieved by reaching the top of the right-hand hill and, towards the end of the training, consistently controls the car/agent to reach there.</p>
<p>This reinforcement learning tutorial in TensorFlow has shown you:</p>
<ol>
<li>The basics of Q learning</li>
<li>The epsilon greed action selection policy</li>
<li> The importance of batching in training deep Q reinforcement learning networks, and</li>
<li>How to implement a deep Q reinforcement learning network in TensorFlow</li>
</ol>
<p>I hope it has been instructive &#8211; keep an eye out for future tutorials in reinforcement learning where more complicated games and techniques will be reviewed.</p>
<hr />
<p><strong>Recommended online course &#8211; </strong>If you are more of a video learner, check out this inexpensive online course: <a href="https://click.linksynergy.com/link?id=Jbc0N5ZkDzk&amp;offerid=323058.1153742&amp;type=2&amp;murl=https%3A%2F%2Fwww.udemy.com%2Fdeep-reinforcement-learning-in-python%2F">Advanced AI: Deep Reinforcement Learning in Python</a><img src="https://ad.linksynergy.com/fs-bin/show?id=Jbc0N5ZkDzk&amp;bids=323058.1153742&amp;type=2&amp;subid=0" width="1" height="1" border="0" /></p>
<hr />
<p>&nbsp;</p>
<p>The post <a rel="nofollow" href="http://adventuresinmachinelearning.com/reinforcement-learning-tensorflow/">Reinforcement learning tutorial with TensorFlow</a> appeared first on <a rel="nofollow" href="http://adventuresinmachinelearning.com">Adventures in Machine Learning</a>.</p>
]]></content:encoded>
			<wfw:commentRss>http://adventuresinmachinelearning.com/reinforcement-learning-tensorflow/feed/</wfw:commentRss>
		<slash:comments>1</slash:comments>
		</item>
		<item>
		<title>Weight initialization tutorial in TensorFlow</title>
		<link>http://adventuresinmachinelearning.com/weight-initialization-tutorial-tensorflow/</link>
		<comments>http://adventuresinmachinelearning.com/weight-initialization-tutorial-tensorflow/#respond</comments>
		<pubDate>Thu, 17 May 2018 10:28:56 +0000</pubDate>
		<dc:creator><![CDATA[Andy]]></dc:creator>
				<category><![CDATA[Deep learning]]></category>
		<category><![CDATA[TensorFlow]]></category>
		<category><![CDATA[Weight initialization]]></category>

		<guid isPermaLink="false">http://adventuresinmachinelearning.com/?p=879</guid>
		<description><![CDATA[<p>In the late 80&#8217;s and 90&#8217;s, neural network research stalled due to a lack of good performance. There were a number of reasons for this, <a class="mh-excerpt-more" href="http://adventuresinmachinelearning.com/weight-initialization-tutorial-tensorflow/" title="Weight initialization tutorial in TensorFlow">[...]</a></p>
<p>The post <a rel="nofollow" href="http://adventuresinmachinelearning.com/weight-initialization-tutorial-tensorflow/">Weight initialization tutorial in TensorFlow</a> appeared first on <a rel="nofollow" href="http://adventuresinmachinelearning.com">Adventures in Machine Learning</a>.</p>
]]></description>
				<content:encoded><![CDATA[<p>In the late 80&#8217;s and 90&#8217;s, neural network research stalled due to a lack of good performance. There were a number of reasons for this, outlined by the prominent AI researcher <a href="https://www.youtube.com/watch?v=MpLds0oohC8" target="_blank" rel="noopener">Geoffrey Hinton</a> &#8211; these reasons included poor computing speeds, lack of data, using the wrong type of non-linear activation functions and poor initialization of the weights in neural networks. <a href="http://adventuresinmachinelearning.com/vanishing-gradient-problem-tensorflow/" target="_blank" rel="noopener">My post on the vanishing gradient problem and ReLUs</a> addresses the problem of the wrong kind of non-linear activation functions, and this post will deal with proper weight initialization. In particular, in this post we&#8217;ll be examining the problem with a naive normal distribution when initializing weights, and examine Xavier and He initialization as a remedy to this problem. This will be empirically studied using TensorFlow and some associated TensorBoard visualizations. Note: to run the code in this tutorial, you&#8217;ll need TensorFlow 1.8 or greater installed.</p>
<hr />
<p><strong>Recommended</strong><strong> online course: </strong>If you&#8217;d like to learn more about TensorFlow I&#8217;d recommend the following inexpensive Udemy course: <a href="https://click.linksynergy.com/link?id=Jbc0N5ZkDzk&amp;offerid=323058.1326292&amp;type=2&amp;murl=https%3A%2F%2Fwww.udemy.com%2Fcomplete-guide-to-tensorflow-for-deep-learning-with-python%2F">Complete Guide to TensorFlow for Deep Learning with Python</a><img src="https://ad.linksynergy.com/fs-bin/show?id=Jbc0N5ZkDzk&amp;bids=323058.1326292&amp;type=2&amp;subid=0" width="1" height="1" border="0" /></p>
<hr />
<h2>The problem with a naive initialization of weights</h2>
<p>The random initialization of weights is critical to learning good mappings from input to output in neural networks. Because the search space involving many weights during training is very large, there are multiple local minimums within which the back-propagation may be trapped. Effective randomization of weights ensures that the search space is adequately explored during training, resulting in the best chances of a good minimum being found during back-propagation (for more on back-propagation, see <a href="http://adventuresinmachinelearning.com/neural-networks-tutorial/" target="_blank" rel="noopener">my neural networks tutorial</a>). However, the weight initialization randomization function needs to be carefully chosen and specified otherwise there is a large risk that the training progress will be slowed to the point of impracticality.</p>
<p>This is especially the case when using the historical &#8220;squashing&#8221; non-linear activation functions such as the sigmoid function and the tanh function, though it is still an issue with ReLU function, as will be seen later. The reason for this problem is that, if the weights are such that the activation functions of nodes are pushed into the &#8220;flat&#8221; regions of their curves, they are &#8220;saturated&#8221; and impede learning. Consider the plot below showing the tanh function and its first derivative:</p>
<figure id="attachment_881" style="width: 404px" class="wp-caption aligncenter"><img class="size-full wp-image-881" src="http://adventuresinmachinelearning.com/wp-content/uploads/2018/04/Tanh-gradient.png" alt="Tanh function - weight initialization TensorFlow" width="404" height="266" srcset="http://adventuresinmachinelearning.com/wp-content/uploads/2018/04/Tanh-gradient.png 404w, http://adventuresinmachinelearning.com/wp-content/uploads/2018/04/Tanh-gradient-300x198.png 300w" sizes="(max-width: 404px) 100vw, 404px" /><figcaption class="wp-caption-text">Tanh function and its first derivative</figcaption></figure>
<p>It can observed that when abs(x) &gt; 2, the derivative of the tanh function approaches zero. Now because the back-propagation method of updating the weight values in a neural network depends on the derivative of the activation functions, this means that when nodes are pushed into such &#8220;saturation&#8221; regions, slow or no learning will take place. Therefore, we don&#8217;t want to start with weight values that push some or all of the nodes into those saturation regions, as that network just won&#8217;t work very well. The sigmoid function operates similarly, as can be observed in <a href="http://adventuresinmachinelearning.com/vanishing-gradient-problem-tensorflow/" target="_blank" rel="noopener">my vanishing gradient</a> post.</p>
<p>A naive initialization of weights might be to simply use a normal distribution of mean zero and unit standard deviation (i.e. 1.0). Let&#8217;s consider how this might play out using a bit of simple statistical theory. Recall that the input to a neuron in the first layer of a neural network looks like:</p>
<p>$$in = X_1 W_1 + X_2 W_2 + X_3 W_3+ X_4 W_4 + \dots$$</p>
<p>The input, in other words, is a summation of the respective weights and their inputs. The variance (the square of the standard deviation) of each element in this sum can be explained by the <a href="https://en.wikipedia.org/wiki/Variance#Product_of_independent_variables" target="_blank" rel="noopener">product of independent variables</a> law:</p>
<p>$$Var(X_i W_i) = [E(X_i)]^2 Var(W_i) + [E(W_i)]^2 Var(X_i) + Var(X_i)Var(W_i)$$</p>
<p>If we assume that the input has been appropriately scaled with a mean of 0 and a unit variance, and likewise we initialize the weights for a mean 0 and unit variance, then this results in:</p>
<p>$$Var(X_i W_i) = 0 \times 1 + 0 \times 1 + 1 \times 1 = 1$$</p>
<p>So each product within the total sum of <em>in</em> has a variance of 1. What is the total variance of the node input variable <em>in</em>? We can make the assumption that each product (i.e. each $X_i W_i$) is statistically independent (not quite correct for things like images, but close enough for our purposes) and then apply the <a href="https://en.wikipedia.org/wiki/Variance#Sum_of_uncorrelated_variables_(Bienaym%C3%A9_formula)" target="_blank" rel="noopener">sum of uncorrelated independent variables</a> law:</p>
<p>$$Var(in) = \sum_{i=0}^n  Var(X_i W_i) = n \times 1 = n$$</p>
<p>Where <em>n</em> is the number of inputs. So here, we can observe that if there are, say, 784 inputs (equal to the input size of the MNIST problem), the variance will be large and the standard deviation will be $\sqrt{Var(in)} = \sqrt{784} = 28$. This will result in the vast majority of neurons in the first layer being saturated, as most values will be &gt;&gt; |2| (i.e. the saturation regions of the functions).</p>
<p>Clearly this is not ideal, and so another way of initializing our weight variables is desirable.</p>
<h2>Xavier or variance scaling for weight initialization</h2>
<p>The <a href="http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf" target="_blank" rel="noopener">Xavier method of weight initialization</a> is a big improvement on the naive way of weight scaling shown in the section above. This method has helped accelerate the field of deep learning in a big way. It takes into account the problems shown above and bases the standard deviation or the variance of the weight initialization on the number of variables involved. It thereby adjusts itself based on the number of weight values. It works on the idea that if you can keep the variance constant from layer to layer in both the feed forward direction and back-propagation direction, your network will learn optimally. This makes sense, as if the variance increases or decreases as you go through the layers, your weights will eventually saturate your non-linear neurons in either the positive or negative direction.</p>
<p>So, how do we use this idea to work out what variance should be used to best initialize the weights? First, because the network will be learning effectively when it is operating in the linear regions of the <em>tanh</em> and <em>sigmoid</em> functions, the activation function can be approximated by a linear activation, i.e.:</p>
<p>$$ Y = W_{1} X_{1} + W_{2} X_{2} + W_{3} X_{3} + \dots $$</p>
<p>Therefore, with this linear activation function, we can use the same result that was arrived at above using the product of independent variables and sum of uncorrelated independent variables, namely:</p>
<p>$$ Var(Y) = n_{in} Var(W_i)Var(X_i)$$</p>
<p>Where $n_{in}$ is the number of inputs to each node. If we want the variance of the input ($Var(X_i)$) to be equal to the variance of the output ($Var(Y)$) this reduces to:</p>
<p>$$ Var(W_i) = \frac{1}{n_{in}} $$</p>
<p>Which is a preliminary result for a good initialization variance for the weights in your network. However, this is really just keeping the variance constant during the forward pass. What about trying to keep the variance constant also during back-propagation? It turns out that during back-propagation, to try to do this you need:</p>
<p>$$ n_{i+1} Var(W_i) = 1 $$</p>
<p>Or:</p>
<p>$$ Var(W_i) = \frac{1}{n_{out}} $$</p>
<p>Now there are two different ways of calculating the variance, one depending on the value of the number of inputs and the other on the number of outputs. The authors of the <a href="http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf" target="_blank" rel="noopener">original paper on Xavier initialization</a> take the average of the two:</p>
<p>$$ n_{avg} = \frac{n_{in}  + n_{out}}{2} $$</p>
<p>$$ Var(W_i) = \frac{1}{n_{avg}} = \frac {2}{n_{in} + n_{out}} $$</p>
<p>That is the final result in the Xavier initialization of weights for <em>squashing </em>activation functions i.e. <em>tanh </em>and <em>sigmoid</em>. However, it turns out this isn&#8217;t quite as optimal for <a href="http://adventuresinmachinelearning.com/vanishing-gradient-problem-tensorflow/" target="_blank" rel="noopener">ReLU functions</a>.</p>
<h2>ReLU activations and the He initialization</h2>
<p>Consider the ReLU function &#8211; for all values less than zero, the output of the activation function is also zero. For values greater than zero, the ReLU function simply returns it&#8217;s input. In other words, half of the output is linear, like the assumption made in the analysis above &#8211; so that&#8217;s easy. However, for the other half of the inputs, for input values &lt; 0, the output is zero. If we assume that the inputs to the ReLU neurons are approximately centered about 0, then, roughly speaking, half the variance will be in line with the Xavier initialization result, and the other half will be 0.</p>
<p>This is basically equivalent to halving the number of input nodes. So if we return to our Xavier calculations, but with half the number of input nodes, we have:</p>
<p>$$ Var(Y) = \frac{n_{in}}{2} Var(W_i)Var(X_i) $$</p>
<p>Again, if we want the variance of the input ($Var(X_i)$) to be equal to the variance of the output ($Var(Y)$) this reduces to:</p>
<p>$$ Var(W_i) = \frac{2}{n_{in}} $$</p>
<p>This is He initialization, and this initialization has been found to generally work better with ReLU activation functions.</p>
<p>Now that we&#8217;ve reviewed the theory, let&#8217;s get to the code.</p>
<h2>Weight initialization in TensorFlow</h2>
<p>This section will show you how to initialize weights easily in TensorFlow. The full code can be found on <a href="https://github.com/adventuresinML/adventures-in-ml-code" target="_blank" rel="noopener">this site&#8217;s Github page</a>. Performing Xavier and He initialization in TensorFlow is now really straight-forward using the <em>tf.contrib.layers.variance_scaling_initializer</em>. By adjusting the available parameters, we can create either Xavier, He or other types of modern weight initializations. In this TensorFlow example, I&#8217;ll be creating a simple MNIST classifier using TensorFlow&#8217;s packaged MNIST dataset, with a simple three layer fully connected neural network architecture. I&#8217;ll also be logging various quantities so that we can visualize the variance, activations and so on in TensorBoard.</p>
<p>First, we define a Model class to hold the neural network model:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">class Model(object):
    def __init__(self, input_size, label_size, initialization, activation, num_layers=3,
                 hidden_size=100):
        self._input_size = input_size
        self._label_size = label_size
        self._init = initialization
        self._activation = activation
        # num layers does not include the input layer
        self._num_layers = num_layers
        self._hidden_size = hidden_size
        self._model_def()</code></pre> <div class="code-embed-infos"> </div> </div>
<p>The above code is the class initialization function &#8211; notice that various initialization and activation functions can be passed to the model. Later on, we&#8217;ll cycle through different weight initialization and activation functions and see how they perform.</p>
<p>In the next section, I define the model creation function inside the Model class:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">    def _model_def(self):
        # create placeholder variables
        self.input_images = tf.placeholder(tf.float32, shape=[None, self._input_size])
        self.labels = tf.placeholder(tf.float32, shape=[None, self._label_size])
        # create self._num_layers dense layers as the model
        input = self.input_images
        tf.summary.scalar(&quot;input_var&quot;, self._calculate_variance(input))
        for i in range(self._num_layers - 1):
            input = tf.layers.dense(input, self._hidden_size, kernel_initializer=self._init,
                                    activation=self._activation, name=&#039;layer{}&#039;.format(i+1))
            # get the input to the nodes (sans bias)
            mat_mul_in = tf.get_default_graph().get_tensor_by_name(&quot;layer{}/MatMul:0&quot;.format(i + 1))
            # log pre and post activation function histograms
            tf.summary.histogram(&quot;mat_mul_hist_{}&quot;.format(i + 1), mat_mul_in)
            tf.summary.histogram(&quot;fc_out_{}&quot;.format(i + 1), input)
            # also log the variance of mat mul
            tf.summary.scalar(&quot;mat_mul_var_{}&quot;.format(i + 1), self._calculate_variance(mat_mul_in))
        # don&#039;t supply an activation for the final layer - the loss definition will
        # supply softmax activation. This defaults to a linear activation i.e. f(x) = x
        logits = tf.layers.dense(input, 10, name=&#039;layer{}&#039;.format(self._num_layers))
        mat_mul_in = tf.get_default_graph().get_tensor_by_name(&quot;layer{}/MatMul:0&quot;.format(self._num_layers))
        tf.summary.histogram(&quot;mat_mul_hist_{}&quot;.format(self._num_layers), mat_mul_in)
        tf.summary.histogram(&quot;fc_out_{}&quot;.format(self._num_layers), input)
        # use softmax cross entropy with logits - no need to apply softmax activation to
        # logits
        self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,
                                                                             labels=self.labels))
        # add the loss to the summary
        tf.summary.scalar(&#039;loss&#039;, self.loss)
        self.optimizer = tf.train.AdamOptimizer().minimize(self.loss)
        self.accuracy = self._compute_accuracy(logits, self.labels)
        tf.summary.scalar(&#039;acc&#039;, self.accuracy)
        self.merged = tf.summary.merge_all()
        self.init_op = tf.global_variables_initializer()</code></pre> <div class="code-embed-infos"> </div> </div>
<p>I&#8217;ll step through the major points in this function. First, there is the usual placeholders to hold the training input and output data &#8211; if you&#8217;re unfamiliar with the basics of TensorFlow, check out my introductory tutorial <a href="http://adventuresinmachinelearning.com/python-tensorflow-tutorial/" target="_blank" rel="noopener">here</a>. Then, a scalar variable is logged called &#8220;input_var&#8221; which logs the variance of the input images, calculated via the _calculate_variance function &#8211; this will be presented later. The next step involves a loop through the layers, and here I have used the TensorFlow layers API which allows us to create densely connected layers easily. Notice that the <em>kernel_initializer</em> argument is what will initialize the weights of the layer, and <em>activation</em> is the activation function which the layer neurons will use.</p>
<p>Next, I access the values of the matrix multiplication between the weights and inputs for each layer, and log the values. This way we can observe what the values of the inputs to each neuron is, and the variance of these inputs. We log these values as histograms. Finally, within the layer loop, the variance of the matrix multiplication input is also logged as a scalar.</p>
<p>The remainder of this model construction function is all the standard TensorFlow operations which define the loss, the optimizer and variable initialization, and also some additional logging of variables. The next function to take notice of within the Model class is the _calculate_variance function &#8211; it looks like:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">    def _calculate_variance(self, x):
        mean = tf.reduce_mean(x)
        sqr = tf.square(x - mean)
        return tf.reduce_mean(sqr)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>The function above is just a simple calculation of the <a href="https://en.wikipedia.org/wiki/Variance" target="_blank" rel="noopener">variance</a> of <em>x</em>.</p>
<p>The main code block creates a list of various scenarios to run through, each with a different folder name in which to store the results, a different weight initialization function and finally a different activation function to supply to the neurons. The main training / analysis loop first runs a single batch of data through the network to examine initial variances. Thereafter it performs a full training run of the network so that performance indicators can be analysed.</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">if __name__ == &quot;__main__&quot;:
    sub_folders = [&#039;first_pass_normal&#039;, &#039;first_pass_variance&#039;,
                   &#039;full_train_normal&#039;, &#039;full_train_variance&#039;,
                   &#039;full_train_normal_relu&#039;, &#039;full_train_variance_relu&#039;,
                   &#039;full_train_he_relu&#039;]
    initializers = [tf.random_normal_initializer,
                    tf.contrib.layers.variance_scaling_initializer(factor=1.0, mode=&#039;FAN_AVG&#039;, uniform=False),
                    tf.random_normal_initializer,
                    tf.contrib.layers.variance_scaling_initializer(factor=1.0, mode=&#039;FAN_AVG&#039;, uniform=False),
                    tf.random_normal_initializer,
                    tf.contrib.layers.variance_scaling_initializer(factor=1.0, mode=&#039;FAN_AVG&#039;, uniform=False),
                    tf.contrib.layers.variance_scaling_initializer(factor=2.0, mode=&#039;FAN_IN&#039;, uniform=False)]
    activations = [tf.sigmoid, tf.sigmoid, tf.sigmoid, tf.sigmoid, tf.nn.relu, tf.nn.relu, tf.nn.relu]
    assert len(sub_folders) == len(initializers) == len(activations)
    maybe_create_folder_structure(sub_folders)
    for i in range(len(sub_folders)):
        tf.reset_default_graph()
        model = Model(784, 10, initializers[i], activations[i])
        if &quot;first_pass&quot; in sub_folders[i]:
            init_pass_through(model, sub_folders[i])
        else:
            train_model(model, sub_folders[i], 30, 1000)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>The most important thing to consider in the code above is the Xavier and He weight initialization<em> </em>definitions. The function used to create these is the <em>tf.contrib.layers.variance_scaling_initializer</em> which allows us to create weight initializers which are based on the number of input and output connections in order to execute the Xavier and He initialization discussed previously.</p>
<p>The three arguments used in this function are:</p>
<ul>
<li>The <em>factor </em>argument, which is a multiplicative factor that is applied to the scaling. This is 1.0 for Xavier weight initialization, and 2.0 for He weight initialization</li>
<li>The <em>mode</em> argument: this defines which is on the denominator of the variance calculation. If &#8216;FAN_IN&#8217;, the variance scaling is based solely on the number of inputs to the node. If &#8216;FAN_OUT&#8217; it is based solely on the number of outputs. If it is &#8216;FAN_AVG&#8217;, it is based on an averaging calculation, i.e. Xavier initialization. For He initialization, use &#8216;FAN_IN&#8217;</li>
<li>The <em>uniform</em> argument: this defines whether to use a uniform distribution or a normal distribution to sample the weights from during initialization. For both Xavier and He weight initialization, you can use a normal distribution, so set this argument to False</li>
</ul>
<p>The other weight initialization function used in the scenarios is the <em>tf.random_normal_initializer</em> with default parameters. The default parameters for this initializer are a mean of zero, and a unit (i.e. 1.0) standard deviation / variance.</p>
<p>After running this code, a number of interesting results are obtained.</p>
<h2>Visualizing the TensorFlow model variables</h2>
<p>The first thing that we want to look at is the &#8220;first pass&#8221; model results, where only one batch is passed through the model. If we look at the distribution of inputs into the first layer in TensorBoard, with our naive normally distributed weight values with a unit variance, we can see the following:</p>
<figure id="attachment_911" style="width: 322px" class="wp-caption aligncenter"><img class=" wp-image-911" src="http://adventuresinmachinelearning.com/wp-content/uploads/2018/05/Weight-initialization-Mat-Mul-1.png" alt="Weight initialization - First pass distribution of inputs to the first layer" width="322" height="201" srcset="http://adventuresinmachinelearning.com/wp-content/uploads/2018/05/Weight-initialization-Mat-Mul-1.png 505w, http://adventuresinmachinelearning.com/wp-content/uploads/2018/05/Weight-initialization-Mat-Mul-1-300x187.png 300w" sizes="(max-width: 322px) 100vw, 322px" /><figcaption class="wp-caption-text">First pass distribution of inputs to the first layer</figcaption></figure>
<p>As can be observed the matrix multiplication input into the first layer is approximately normally distributed, with a standard deviation around 10. If you recall, the variance scalar of the matrix multiplication input was also been logged, and it gives a value of approximately 88. Does this make sense? I mentioned earlier that with 784 inputs (i.e. the input size of the MNIST dataset), we should expect a variance of approximately 784. What&#8217;s the explanation of this discrepancy? Well, remember I also logged the variance of the input data &#8211; it turns out that the MNIST TensorFlow dataset has a variance of 0.094. You&#8217;ll recall that we assumed a unit variance in the calculations previously shown. In this case, though, we should expect a variance of (remember that $Var(W_i)$, for the normal distribution initializer we are currently considering, is equal to 1.0):</p>
<p>$$Var(in) = \sum_{i=0}^n Var(X_i)Var(W_i) = n Var(X_i)Var(W_i) = 784 * 0.094 * 1 = 74$$</p>
<p>This is roughly in line with the observed variance &#8211; so we can be happy that we are on the right track. The distribution shown above is the distribution into the first layer neurons. In the first set of scenarios, we&#8217;re using a sigmoid activation function &#8211; so what does the first layer output distribution look like for this type of input distribution?</p>
<figure id="attachment_912" style="width: 319px" class="wp-caption aligncenter"><img class=" wp-image-912" src="http://adventuresinmachinelearning.com/wp-content/uploads/2018/05/Weight-initialization-first-layer-output-distribution.png" alt="Weight initialization - Distribution of outputs from first layer - sigmoid activations and normal weight initialization" width="319" height="210" srcset="http://adventuresinmachinelearning.com/wp-content/uploads/2018/05/Weight-initialization-first-layer-output-distribution.png 498w, http://adventuresinmachinelearning.com/wp-content/uploads/2018/05/Weight-initialization-first-layer-output-distribution-300x198.png 300w" sizes="(max-width: 319px) 100vw, 319px" /><figcaption class="wp-caption-text">Distribution of outputs from first layer &#8211; sigmoid activations and normal weight initialization</figcaption></figure>
<p>As can be observed, the input distribution with such a relatively large variance completely saturates the first layer &#8211; with the output distribution being squeezed to the saturated regions of the sigmoid<em> </em>curve i.e. outputs close to 0 and 1 (we&#8217;d observe the same thing with a <em>tanh</em> activation). This confirms our previous analysis of the problems with a naive normally distributed weight initialization.</p>
<p>What happens when we use the Xavier initialization configuration of the variance scaler initializer? The plot below shows the same distribution of outputs:</p>
<figure id="attachment_913" style="width: 302px" class="wp-caption aligncenter"><img class=" wp-image-913" src="http://adventuresinmachinelearning.com/wp-content/uploads/2018/05/Weight-initialization-first-layer-output-Xavier-distribution.png" alt="Weight initialization - Distribution of outputs from first layer - sigmoid activations and Xavier weight initialization" width="302" height="213" srcset="http://adventuresinmachinelearning.com/wp-content/uploads/2018/05/Weight-initialization-first-layer-output-Xavier-distribution.png 463w, http://adventuresinmachinelearning.com/wp-content/uploads/2018/05/Weight-initialization-first-layer-output-Xavier-distribution-300x212.png 300w" sizes="(max-width: 302px) 100vw, 302px" /><figcaption class="wp-caption-text">Distribution of outputs from first layer &#8211; sigmoid activations and Xavier weight initialization</figcaption></figure>
<p>As can be observed, this is a very satisfactory distribution &#8211; with the output values centered around the linear region of the sigmoid function (i.e. 0.5), with no saturation occurring. This more optimal initialization results in better training outcomes also. The figure below shows the accuracy comparison between the normally initialized weight distribution and the Xavier initialized weight distribution, for the full training run scenario:</p>
<figure id="attachment_914" style="width: 379px" class="wp-caption aligncenter"><img class=" wp-image-914" src="http://adventuresinmachinelearning.com/wp-content/uploads/2018/05/Weight-initialization-accuracy-comparison.png" alt="Weight initialization - Accuracy comparison between normal and Xavier initialization - sigmoid activation" width="379" height="248" srcset="http://adventuresinmachinelearning.com/wp-content/uploads/2018/05/Weight-initialization-accuracy-comparison.png 527w, http://adventuresinmachinelearning.com/wp-content/uploads/2018/05/Weight-initialization-accuracy-comparison-300x196.png 300w" sizes="(max-width: 379px) 100vw, 379px" /><figcaption class="wp-caption-text">Accuracy comparison between normal (red) and Xavier initialization (light blue) &#8211; sigmoid activation</figcaption></figure>
<p>As can be observed, Xavier initialization results in better training performance, as we should expect.</p>
<p>The next thing to compare is the performance of normal weight initialization, Xavier initialization and He initialization for a ReLU activation function. The plot below shows the accuracy comparison during training between the three initialization techniques:</p>
<figure id="attachment_917" style="width: 380px" class="wp-caption aligncenter"><img class=" wp-image-917" src="http://adventuresinmachinelearning.com/wp-content/uploads/2018/05/Weight-initialization-ReLU-accuracy-comparison.png" alt="Weight initialization - He, Xavier and normal comparison with ReLU activations" width="380" height="253" srcset="http://adventuresinmachinelearning.com/wp-content/uploads/2018/05/Weight-initialization-ReLU-accuracy-comparison.png 525w, http://adventuresinmachinelearning.com/wp-content/uploads/2018/05/Weight-initialization-ReLU-accuracy-comparison-300x200.png 300w" sizes="(max-width: 380px) 100vw, 380px" /><figcaption class="wp-caption-text">Accuracy comparison for ReLU activation functions and normal (red), Xavier (green) and He (grey) weight initialization</figcaption></figure>
<p>As can be observed, the model performance is significantly greater for Xavier and He weight initialization than for the normal initialization on a ReLU network. There is little clear difference between the Xavier and He initialization, but a better average performance should be expected from He initialization for more complicated networks and problems that use a ReLU activation function.</p>
<p>There you have it &#8211; you should now hopefully understand the drawbacks of naive, normally distributed weight initialization, and you should also understand the basics of how Xavier and He initialization work, and their performance benefits. You should also understand how to easily use such initialization methods in TensorFlow. I hope this helps you build better performing models for both sigmoid/tanh and ReLU networks.</p>
<hr />
<p><strong>Recommended</strong><strong> online course: </strong>If you&#8217;d like to learn more about TensorFlow I&#8217;d recommend the following inexpensive Udemy course: <a href="https://click.linksynergy.com/link?id=Jbc0N5ZkDzk&amp;offerid=323058.1326292&amp;type=2&amp;murl=https%3A%2F%2Fwww.udemy.com%2Fcomplete-guide-to-tensorflow-for-deep-learning-with-python%2F">Complete Guide to TensorFlow for Deep Learning with Python</a><img src="https://ad.linksynergy.com/fs-bin/show?id=Jbc0N5ZkDzk&amp;bids=323058.1326292&amp;type=2&amp;subid=0" width="1" height="1" border="0" /></p>
<hr />
<p>&nbsp;</p>
<p>The post <a rel="nofollow" href="http://adventuresinmachinelearning.com/weight-initialization-tutorial-tensorflow/">Weight initialization tutorial in TensorFlow</a> appeared first on <a rel="nofollow" href="http://adventuresinmachinelearning.com">Adventures in Machine Learning</a>.</p>
]]></content:encoded>
			<wfw:commentRss>http://adventuresinmachinelearning.com/weight-initialization-tutorial-tensorflow/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>The vanishing gradient problem and ReLUs &#8211; a TensorFlow investigation</title>
		<link>http://adventuresinmachinelearning.com/vanishing-gradient-problem-tensorflow/</link>
		<comments>http://adventuresinmachinelearning.com/vanishing-gradient-problem-tensorflow/#comments</comments>
		<pubDate>Tue, 03 Apr 2018 01:50:19 +0000</pubDate>
		<dc:creator><![CDATA[Andy]]></dc:creator>
				<category><![CDATA[Deep learning]]></category>
		<category><![CDATA[TensorFlow]]></category>

		<guid isPermaLink="false">http://adventuresinmachinelearning.com/?p=839</guid>
		<description><![CDATA[<p>Deep learning is huge in machine learning at the moment, and no wonder &#8211; it is making large and important strides in solving problems in computer <a class="mh-excerpt-more" href="http://adventuresinmachinelearning.com/vanishing-gradient-problem-tensorflow/" title="The vanishing gradient problem and ReLUs &#8211; a TensorFlow investigation">[...]</a></p>
<p>The post <a rel="nofollow" href="http://adventuresinmachinelearning.com/vanishing-gradient-problem-tensorflow/">The vanishing gradient problem and ReLUs &#8211; a TensorFlow investigation</a> appeared first on <a rel="nofollow" href="http://adventuresinmachinelearning.com">Adventures in Machine Learning</a>.</p>
]]></description>
				<content:encoded><![CDATA[<p>Deep learning is huge in machine learning at the moment, and no wonder &#8211; it is making large and important strides in solving problems in <a href="http://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-tensorflow/">computer vision</a>, <a href="http://adventuresinmachinelearning.com/recurrent-neural-networks-lstm-tutorial-tensorflow/">natural language</a> and <a href="http://adventuresinmachinelearning.com/reinforcement-learning-tutorial-python-keras/">reinforcement learning</a> and problems in many other areas. Deep learning neural networks are neural networks which are characterized by <em>many </em><em>layers</em> &#8211; making them <em>deep </em>instead of <em>wide</em>. Deep networks <a href="https://arxiv.org/pdf/1512.03965v4.pdf" target="_blank" rel="noopener">have been demonstrated</a> to be more practically capable of solving problems than simple, wide two layer networks. Neural networks have been around for a long time, but initial success using these networks was elusive. One of the issues that had to be overcome in making them more useful and transitioning to modern deep learning networks was the <em>vanishing gradient</em> problem. This problem manifests in the early layers of deep neural networks not learning (or learning very slowly), resulting in difficulties in solving practical problems.</p>
<p>This post will examine the vanishing gradient problem, and demonstrate an improvement to the problem through the use of the rectified linear unit activation function, or ReLUs. The examination will take place using TensorFlow and visualizing with the TensorBoard utility. The TensorFlow code used in this tutorial can be found on <a href="https://github.com/adventuresinML/adventures-in-ml-code">this site&#8217;s Github repository</a>.</p>
<hr />
<p><strong>Recommended</strong><strong> online course: </strong>If you&#8217;d like to learn more about TensorFlow I&#8217;d recommend the following inexpensive Udemy course: <a href="https://click.linksynergy.com/link?id=Jbc0N5ZkDzk&#038;offerid=323058.1326292&#038;type=2&#038;murl=https%3A%2F%2Fwww.udemy.com%2Fcomplete-guide-to-tensorflow-for-deep-learning-with-python%2F">Complete Guide to TensorFlow for Deep Learning with Python</a><IMG border=0 width=1 height=1 src="https://ad.linksynergy.com/fs-bin/show?id=Jbc0N5ZkDzk&#038;bids=323058.1326292&#038;type=2&#038;subid=0" ></p>
<hr />
<h2>The vanishing gradient problem</h2>
<p>The vanishing gradient problem arises due to the nature of the back-propagation optimization which occurs in neural network training (for a comprehensive introduction to back-propagation, see <a href="http://adventuresinmachinelearning.com/ebook-newsletter-sign/">my free ebook</a>). The weight and bias values in the various layers within a neural network are updated each optimization iteration by stepping in the direction of the <em>gradient </em>of the weight/bias values with respect to the loss function. In other words, the weight values change in proportion to the following gradient:</p>
<p>$$ \partial C/ \partial W_l $$</p>
<p>Where <i>$W_l$</i> represents the weights of layer <em>l</em> and <em>C  </em>is the cost or loss function at the output layer (again, if these terms are gibberish to you, check out <a href="http://adventuresinmachinelearning.com/ebook-newsletter-sign/">my free ebook</a> which will get you up to speed). In the final layer, this calculation is straight-forward, however in earlier layers, the back-propagation of errors method needs to be utilized. At the final layer, the error term $\delta$ looks like:</p>
<p>$$\delta_i^{(n_l)} = -(y_i &#8211; h_i^{(n_l)})\cdot f^\prime(z_i^{(n_l)})$$</p>
<p>Don&#8217;t worry too much about the notation, but basically the equation above shows first that the error is related to the difference between the output of the network $h_i^{(n_l)}$ and the training labels $y_i$ (i.e. $(y_i &#8211; h_i^{(n_l)})$). It is also, more importantly for the vanishing gradient problem, proportional to the derivative of the activation function $f^\prime(z_i^{(n_l)})$. The weights in the final layer change in direct proportion to this $\delta$ value. For earlier layers, the error from the latter layers is back-propagated via the following rule:</p>
<p>$$\delta^{(l)} = \left((W^{(l)})^T \delta^{(l+1)}\right) \bullet f'(z^{(l)})$$</p>
<p>Again, in the second part of this equation, there is the derivative of the activation function f'(z^{(l)}). Notice that $\delta^{(l)}$ is also proportional to the error propagated from the downstream layer $\delta^{(l+1)}$. These downstream $\delta$ values also include their own f'(z^{(l)}) values. So, basically, the gradient of the weights of a given layer with respect to the loss function, which controls how these weight values are updated, is proportional to chained multiplications of the derivative of the activation function i.e.:</p>
<p>$$ \frac{\partial C} {\partial W_l} \propto  f'(z^{(l)}) f'(z^{(l+1)}) f'(z^{(l+2)}) \dots$$</p>
<p>The vanishing gradient problem comes about in deep neural networks when the <em>f&#8217;</em> terms are all outputting values &lt;&lt; 1. When we multiply lots of numbers &lt;&lt; 1 together, we end up with a vanishing product, which leads to a very small $\frac{\partial C} {\partial W_l}$ value and hence practically no learning of the weight values &#8211; the predictive power of the neural network then platueus.</p>
<h3>The sigmoid activation function</h3>
<p>The vanishing gradient problem is particularly problematic with sigmoid activation functions. The plot below shows the sigmoid activation function and its first derivative:</p>
<figure id="attachment_559" style="width: 389px" class="wp-caption aligncenter"><img class="size-full wp-image-559" src="http://adventuresinmachinelearning.com/wp-content/uploads/2017/09/Sigmoid-gradient.png" alt="Recurrent neural network and LSTM tutorial - sigmoid gradient" width="389" height="266" srcset="http://adventuresinmachinelearning.com/wp-content/uploads/2017/09/Sigmoid-gradient.png 389w, http://adventuresinmachinelearning.com/wp-content/uploads/2017/09/Sigmoid-gradient-300x205.png 300w" sizes="(max-width: 389px) 100vw, 389px" /><figcaption class="wp-caption-text">Sigmoid gradient</figcaption></figure>
<p>As can be observed, when the sigmoid function value is either too high or too low, the derivative (orange line) becomes very small i.e. &lt;&lt; 1. This causes vanishing gradients and poor learning for deep networks. This can occur when the weights of our networks are initialized poorly &#8211; with too-large negative and positive values. These too-large values <em>saturate</em> the input to the sigmoid and pushes the derivatives into the small valued regions. However, even if the weights are initialized nicely, and the derivatives are sitting around the maximum i.e. ~0.2, with many layers there will still be a vanishing gradient problem. With only 4 layers of 0.2 valued derivatives we have a product of $0.2^{4} = 0.0016$ &#8211; not very large! Consider how the ResNet architecture, generally with 10&#8217;s or 100&#8217;s of layers, would train using sigmoid activation functions with even the best initialized weights. Most of the layers would be static or dead and impervious to training.</p>
<p>So what&#8217;s the solution to this problem? It&#8217;s called a rectified linear unit activation function, or ReLU.</p>
<h3>The ReLU activation function</h3>
<p>The ReLU activation function is defined as:</p>
<p>$$f(x) = \max(0, x)$$</p>
<p>This function and it&#8217;s first derivative look like:</p>
<figure id="attachment_849" style="width: 380px" class="wp-caption aligncenter"><img class="size-full wp-image-849" src="http://adventuresinmachinelearning.com/wp-content/uploads/2018/03/ReLU-activation-and-derivative.png" alt="ReLU activation - vanishing gradient problem and TensorFlow" width="380" height="266" srcset="http://adventuresinmachinelearning.com/wp-content/uploads/2018/03/ReLU-activation-and-derivative.png 380w, http://adventuresinmachinelearning.com/wp-content/uploads/2018/03/ReLU-activation-and-derivative-300x210.png 300w" sizes="(max-width: 380px) 100vw, 380px" /><figcaption class="wp-caption-text">ReLU activation and first derivative</figcaption></figure>
<p>As can be observed, the ReLU activation simply returns its argument <em>x</em> whenever it is greater than zero, and returns 0 otherwise. The first derivative of ReLU is also very simple &#8211; it is equal to 1 when <em>x </em>is greater than zero, but otherwise it is 0. You can probably see the advantages of ReLU at this point &#8211; when it&#8217;s derivative is back-propagated there will be no degradation of the error signal as 1 x 1 x 1 x 1&#8230; = 1. However, the ReLU activation still maintains a non-linearity or &#8220;switch on&#8221; characteristic which enables it to behave analogously to a biological neuron.</p>
<p>There is only one problem with the ReLU activation &#8211; sometimes, because the derivative is zero when <em>x </em>&lt; 0, certain weights can be &#8220;killed off&#8221; or become &#8220;dead&#8221;. This is because the back-propagated error can be cancelled out whenever there is a negative input into a given neuron and therefore the gradient $\frac{\partial C} {\partial W_l}$ will also fall to zero. This means there is no way for the associated weights to update in the right direction. This can obviously impact learning.</p>
<p>What&#8217;s the solution? A variant of ReLU which is called a Leaky ReLU activation.</p>
<h3>The Leaky ReLU activation</h3>
<p>The Leaky ReLU activation is defined as:</p>
<p>$$f(x) = \max(0.01x, x)$$</p>
<p>As you can observe, when <em>x </em>is below zero, the output will switch from <em>x </em>to 0.01<em>x</em>. I won&#8217;t plot the activation for this function, as it is too difficult to see the difference between 0.01<em>x</em> and 0 and therefore in plots it looks just like a normal ReLU. However, the good thing about the Leaky ReLU activation function is that the derivative when <em>x</em> is below zero is 0.01 &#8211; i.e. it is a small but no longer 0. This gives the neuron and associated weights the <em>chance </em>to reactivate, and therefore this should improve the overall learning performance.</p>
<p>Now it&#8217;s time to test out these ideas in a real example using TensorFlow.</p>
<h2>Demonstrating the vanishing gradient problem in TensorFlow</h2>
<h3>Creating the model</h3>
<p>In the TensorFlow code I am about to show you, we&#8217;ll be creating a 7 layer densely connected network (including the input and output layers) and using the TensorFlow summary operations and TensorBoard visualization to see what is going on with the gradients. The code uses the TensorFlow layers (tf.layers) framework which allows quick and easy building of networks. The data we will be training the network on is the MNIST hand-written digit recognition dataset that comes packaged up with the TensorFlow installation.</p>
<p>To create the dataset, we can run the following:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">mnist = input_data.read_data_sets(&quot;MNIST_data/&quot;, one_hot=True)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>The MNIST data can be extracted from this mnist data set by calling mnist.train.next_batch(batch_size). In this case, we&#8217;ll just be looking at the training data, but you can also extract a test dataset from the same data. In this example, I&#8217;ll be using the feed_dict methodology and placeholder variables to feed in the training data, which isn&#8217;t the optimal method (see my <a href="http://adventuresinmachinelearning.com/tensorflow-dataset-tutorial/">Dataset tutorial</a> for the most efficient data consumption methodology) but it will do for these purposes. First, I&#8217;ll setup the data placeholders:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">self.input_images = tf.placeholder(tf.float32, shape=[None, self._input_size])
self.labels = tf.placeholder(tf.float32, shape=[None, self._label_size])</code></pre> <div class="code-embed-infos"> </div> </div>
<p>Note, I have created these variables in an overarching class called Model, hence all the <em>self</em> references. The MNIST data input size (<em>self._input_size</em>) is equal to the 28 x 28 image pixels i.e. 784 pixels. The number of associated labels, <em>self._label_size</em> is equal to the 10 possible hand-written digit classes in the MNIST dataset.</p>
<p>In this tutorial, we&#8217;ll be creating a slightly deep fully connected network &#8211; a network with 7 total layers including input and output layers. To create these densely connected layers easily, we&#8217;ll be using TensorFlow&#8217;s handy tf.layers API and a simple Python loop like follows:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># create self._num_layers dense layers as the model
input = self.input_images
for i in range(self._num_layers - 1):
    input = tf.layers.dense(input, self._hidden_size, activation=self._activation,
                                    name=&#039;layer{}&#039;.format(i+1))</code></pre> <div class="code-embed-infos"> </div> </div>
<p>First, the generic <em>input </em>variable is initialized to be equal to the input images (fed via the placeholder). Next, the code runs through a loop where multiple dense layers are created, each named &#8216;layerX&#8217; where X is the layer number. The number of nodes in the layer is set equal to the class property <em>self._hidden_size</em> and the activation function is also supplied via the property <em>self._activation</em>.</p>
<p>Next we create the final, output layer (you&#8217;ll note that the loop above terminates before it gets to creating the final layer), and we don&#8217;t supply an activation to this layer. In the tf.layers API, a linear activation (i.e. <em>f(x) = x</em>) is applied by default if no activation argument is supplied.</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># don&#039;t supply an activation for the final layer - the loss definition will
# supply softmax activation. This defaults to a linear activation i.e. f(x) = x
logits = tf.layers.dense(input, 10, name=&#039;layer{}&#039;.format(self._num_layers))</code></pre> <div class="code-embed-infos"> </div> </div>
<p>Next, the loss operation is setup and logged:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># use softmax cross entropy with logits - no need to apply softmax activation to
# logits
self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,
                                                                             labels=self.labels))
# add the loss to the summary
tf.summary.scalar(&#039;loss&#039;, self.loss)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>The loss used in this instance is the handy TensorFlow softmax_cross_entropy_with_logits_v2 (the original version is soon to be deprecated). This loss function will apply the <a href="https://en.wikipedia.org/wiki/Softmax_function" target="_blank" rel="noopener">softmax</a> operation to the un-activated output of the network, then apply the <a href="https://en.wikipedia.org/wiki/Cross_entropy" target="_blank" rel="noopener">cross entropy loss</a> to this outcome. After this loss operation is created, it&#8217;s output value is added to the tf.summary framework. This framework allows scalar values to be logged and subsequently visualized in the TensorBoard web-based visualization page. It can also log histogram information, along with audio and images &#8211; all of these can be observed through the aforementioned TensorBoard visualization.</p>
<p>Next, the program calls a method to log the gradients, which we will visualize to examine the vanishing gradient problem:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">self._log_gradients(self._num_layers)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>This method looks like the following:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">def _log_gradients(self, num_layers):
    gr = tf.get_default_graph()
    for i in range(num_layers):
        weight = gr.get_tensor_by_name(&#039;layer{}/kernel:0&#039;.format(i + 1))
        grad = tf.gradients(self.loss, weight)[0]
        mean = tf.reduce_mean(tf.abs(grad))
        tf.summary.scalar(&#039;mean_{}&#039;.format(i + 1), mean)
        tf.summary.histogram(&#039;histogram_{}&#039;.format(i + 1), grad)
        tf.summary.histogram(&#039;hist_weights_{}&#039;.format(i + 1), grad)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>In this method, first the TensorFlow computational graph is extracted so that weight variables can be called out of it. Then a loop is entered into, to cycle through all the layers. For each layer, first the weight tensor for the given layer is grabbed by the handy function get_tensor_by_name. You will recall that each layer was named &#8220;layerX&#8221; where X is the layer number. This is supplied to the function, along with &#8220;/kernel:0&#8221; &#8211; this tells the function that we are trying to access the weight variable (also called a kernel) as opposed to the bias value, which would be &#8220;/bias:0&#8221;.</p>
<p>On the next line, the tf.gradients() function is used. This will calculate gradients of the form $\partial y / \partial x$ where the first argument supplied to the function is <em>y</em> and the second is <em>x</em>. In the gradient descent step, the weight update is made in proportion to $\partial loss / \partial W$, so in this case the first argument supplied to tf.gradients() is the loss, and the second is the weight tensor.</p>
<p>Next, the mean absolute value of the gradient is calculated, and then this is logged as a scalar in the summary. Next, histograms of the gradients and the weight values are also logged in the summary. The flow now returns back to the main method in the class.</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">self.optimizer = tf.train.AdamOptimizer().minimize(self.loss)
self.accuracy = self._compute_accuracy(logits, self.labels)
tf.summary.scalar(&#039;acc&#039;, self.accuracy)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>The code above is fairly standard TensorFlow usage &#8211; defining an optimizer, in this case the flexible and powerful AdamOptimizer(), and also a generic accuracy operation, the outcome of which is also added to the summary (see the<a href="https://github.com/adventuresinML/adventures-in-ml-code" target="_blank" rel="noopener"> Github code</a> for the accuracy method called).</p>
<p>Finally a summary merge operation is created, which will gather up all the summary data ready for export to the TensorBoard file whenever it is executed:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">self.merged = tf.summary.merge_all()</code></pre> <div class="code-embed-infos"> </div> </div>
<p>An initialization operation is also created. Now all that is left is to run the main training loop.</p>
<h3>Training the model</h3>
<p>The main training loop of this experimental model is shown in the code below:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">def run_training(model, mnist, sub_folder, iterations=2500, batch_size=30):
    with tf.Session() as sess:
        sess.run(model.init_op)
        train_writer = tf.summary.FileWriter(base_path + sub_folder,
                                             sess.graph)
        for i in range(iterations):
            image_batch, label_batch = mnist.train.next_batch(batch_size)
            l, _, acc = sess.run([model.loss, model.optimizer, model.accuracy],
                                 feed_dict={model.input_images: image_batch, model.labels: label_batch})
            if i % 200 == 0:
                summary = sess.run(model.merged, feed_dict={model.input_images: image_batch,
                                                            model.labels: label_batch})
                train_writer.add_summary(summary, i)
                print(&quot;Iteration {} of {}, loss: {:.3f}, train accuracy: &quot;
                      &quot;{:.2f}%&quot;.format(i, iterations, l, acc * 100))</code></pre> <div class="code-embed-infos"> </div> </div>
<p>This is a pretty standard TensorFlow training loop (if you&#8217;re unfamiliar with this, see my <a href="http://adventuresinmachinelearning.com/python-tensorflow-tutorial/" target="_blank" rel="noopener">TensorFlow tutorial</a>) &#8211; however, one non-standard addition is the tf.summary.FileWriter() operation and its associated uses. This operation generally takes two arguments &#8211; the location to store the files and the session graph. Note that it is a good idea to setup a different sub folder for each of your TensorFlow runs when using summaries, as this allows for better visualization and comparison of the various runs within TensorBoard.</p>
<p>Every 200 iterations, we run the <em>merged</em> operation, which is defined in the class instance model &#8211; as mentioned previously, this gathers up all the logged summary data ready for writing. The train_writer.add_summary() operation is then run on this output, which writes the data into the chosen location (optionally along with the iteration/epoch number).</p>
<p>The summary data can then be visualized using TensorBoard. To run TensorBoard, using command prompt, navigate to the base directory where all the sub folders are stored, and run the following command:</p>
<blockquote><p>tensorboard &#8211;log_dir=whatever_your_folder_path_is</p></blockquote>
<p>Upon running this command, you will see startup information in the prompt which will tell you the address to type into your browser which will bring up the TensorBoard interface. Note that the TensorBoard page will update itself dynamically during training, so you can visually monitor the progress.</p>
<p>Now, to run this whole experiment, we can run the following code which cycles through each of the activation functions:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">scenarios = [&quot;sigmoid&quot;, &quot;relu&quot;, &quot;leaky_relu&quot;]
act_funcs = [tf.sigmoid, tf.nn.relu, tf.nn.leaky_relu]
assert len(scenarios) == len(act_funcs)
# collect the training data
mnist = input_data.read_data_sets(&quot;MNIST_data/&quot;, one_hot=True)
for i in range(len(scenarios)):
    tf.reset_default_graph()
    print(&quot;Running scenario: {}&quot;.format(scenarios[i]))
    model = Model(784, 10, act_funcs[i], 6, 10)
    run_training(model, mnist, scenarios[i])</code></pre> <div class="code-embed-infos"> </div> </div>
<p>This should be pretty self-explanatory. Three scenarios are investigated &#8211; a scenario for each type of activation reviewed: sigmoid, ReLU and Leaky ReLU. Note that, in this experiment, I&#8217;ve setup a densely connected model with 6 layers (including the output layer but excluding the input layer), with each having a layer size of 10 nodes.</p>
<h3>Analyzing the results</h3>
<p>The first figure below shows the training accuracy of the network, for each of the activations:</p>
<figure id="attachment_859" style="width: 355px" class="wp-caption aligncenter"><img class=" wp-image-859" src="http://adventuresinmachinelearning.com/wp-content/uploads/2018/03/Vanishing-gradient-accuracy-three-scenarios.png" alt="Vanishing gradient TensorFlow - accuracy scenarios" width="355" height="230" srcset="http://adventuresinmachinelearning.com/wp-content/uploads/2018/03/Vanishing-gradient-accuracy-three-scenarios.png 484w, http://adventuresinmachinelearning.com/wp-content/uploads/2018/03/Vanishing-gradient-accuracy-three-scenarios-300x195.png 300w" sizes="(max-width: 355px) 100vw, 355px" /><figcaption class="wp-caption-text">Accuracy of the three activation scenarios &#8211; sigmoid (blue), ReLU (red), Leaky ReLU (green)</figcaption></figure>
<p>As can be observed, the sigmoid (blue) significantly under performs the ReLU and Leaky ReLU activation functions. Is this due to the vanishing gradient problem? The plots below show the mean absolute gradient logs during training, again for the three scenarios:</p>
<figure id="attachment_862" style="width: 314px" class="wp-caption aligncenter"><img class=" wp-image-862" src="http://adventuresinmachinelearning.com/wp-content/uploads/2018/04/Vanishing-gradient-output-layer-gradients.png" alt="Vanishing gradients - TensorFlow - output layer mean gradients" width="314" height="210" srcset="http://adventuresinmachinelearning.com/wp-content/uploads/2018/04/Vanishing-gradient-output-layer-gradients.png 484w, http://adventuresinmachinelearning.com/wp-content/uploads/2018/04/Vanishing-gradient-output-layer-gradients-300x201.png 300w" sizes="(max-width: 314px) 100vw, 314px" /><figcaption class="wp-caption-text">Three scenario mean absolute gradients &#8211; output layer (6th layer) &#8211; sigmoid (blue), ReLU (red), Leaky ReLU (green)</figcaption></figure>
<figure id="attachment_863" style="width: 330px" class="wp-caption aligncenter"><img class=" wp-image-863" src="http://adventuresinmachinelearning.com/wp-content/uploads/2018/04/Vanishing-gradient-1st-layer-gradients.png" alt="Vanishing gradient TensorFlow - 1st layer mean gradients" width="330" height="227" srcset="http://adventuresinmachinelearning.com/wp-content/uploads/2018/04/Vanishing-gradient-1st-layer-gradients.png 469w, http://adventuresinmachinelearning.com/wp-content/uploads/2018/04/Vanishing-gradient-1st-layer-gradients-300x207.png 300w" sizes="(max-width: 330px) 100vw, 330px" /><figcaption class="wp-caption-text">Three scenario mean absolute gradients &#8211; 1st layer &#8211; sigmoid (blue), ReLU (red), Leaky ReLU (green)</figcaption></figure>
<p>The first graph shows the mean absolute gradients of the loss with respect to the weights for the output layer, and the second graph shows the same gradients for the first layer, for all three activation scenarios. First, it is clear that the overall magnitudes of the gradients for the ReLU activated networks are significantly greater than those in the sigmoid activated network. It can also be observed that there is a significant reduction in the gradient magnitudes between the output layer (layer 6) and the first layer (layer 1). This is the vanishing gradient problem.</p>
<p>You may be wondering why the ReLU activated networks still experience a significant reduction in the gradient values from the output layer to the first layer &#8211; weren&#8217;t these activation functions, with their gradients of 1 for activated regions, supposed to stop vanishing gradients? Yes and no. The gradient of the ReLU functions where <em>x &gt; 0</em> is 1, so there is no degradation in multiplying 1&#8217;s together. However, the &#8220;chaining&#8221; expression I showed previously describing the vanishing gradient problem, i.e.:</p>
<p>$$ \frac{\partial C} {\partial W_l} \propto  f'(z^{(l)}) f'(z^{(l+1)}) f'(z^{(l+2)}) \dots$$</p>
<p>isn&#8217;t quite the full picture. Rather, the back-propagation product is also in some sense proportional to the values of the weights in each layer, so more completely, it looks something like this:</p>
<p>$$ \frac{\partial C} {\partial W_l} \propto  f'(z^{(l)}) \cdot W_{l} \cdot f'(z^{(l+1)}) \cdot W_{l+1} \cdot f'(z^{(l+2)}) \cdot W_{l+2} \dots$$</p>
<p>So if the weight values are consistently &lt; 0, then we will also see a vanishing of gradients, as the chained expression will reduce through the layers as the weight values &lt; 0 are multiplied together. We can confirm that the weight values in this case are &lt; 0 by checking the histogram that was logged for the weight values in each layer:</p>
<figure id="attachment_866" style="width: 308px" class="wp-caption aligncenter"><img class=" wp-image-866" src="http://adventuresinmachinelearning.com/wp-content/uploads/2018/04/Vanishing-gradient-leaky-ReLU-weights-layer-4.png" alt="Vanishing gradients TensorFlow - layer 4 weights leaky ReLU" width="308" height="204" srcset="http://adventuresinmachinelearning.com/wp-content/uploads/2018/04/Vanishing-gradient-leaky-ReLU-weights-layer-4.png 435w, http://adventuresinmachinelearning.com/wp-content/uploads/2018/04/Vanishing-gradient-leaky-ReLU-weights-layer-4-300x199.png 300w" sizes="(max-width: 308px) 100vw, 308px" /><figcaption class="wp-caption-text">Distribution of layer 4 weights &#8211; leaky ReLU scenario</figcaption></figure>
<p>The diagram above shows the histogram of layer 4 weights in the leaky ReLU scenario as they evolve through the epochs (y axis) &#8211; this is a handy visualization available in the TensorBoard panel. Note that the weights are consistently &lt; 0, and therefore we should expect the gradients to reduce even under the ReLU scenarios.</p>
<p>In saying all this, we can observe that the degradation of the gradients is <em>significantly worse </em>in the sigmoid scenario than the ReLU scenarios. The mean absolute weight reduces by a factor of 30 between layer 6 and layer 1 for the sigmoid scenario, compared to a factor of 6 for the leaky ReLU scenario (the standard ReLU scenario is pretty much the same). Therefore, while there is still a vanishing gradient problem in the network presented, it is <em>greatly reduced</em> by using the ReLU activation functions. This benefit can be observed in the significantly better performance of the ReLU activation scenarios compared to the sigmoid scenario. Note that, at least in this example, there is not an observable benefit of the leaky ReLU activation function over the standard ReLU activation function.</p>
<p>In summary then, this post has shown you how the vanishing gradient problem comes about, particularly when using the old canonical sigmoid activation function. However, the problem can be greatly reduced using the ReLU family of activation functions. You will also have seen how to log summary information in TensorFlow and plot it in TensorBoard to understand more about your networks. Hope it helps.</p>
<hr />
<p><strong>Recommended</strong><strong> online course: </strong>If you&#8217;d like to learn more about TensorFlow I&#8217;d recommend the following inexpensive Udemy course: <a href="https://click.linksynergy.com/link?id=Jbc0N5ZkDzk&#038;offerid=323058.1326292&#038;type=2&#038;murl=https%3A%2F%2Fwww.udemy.com%2Fcomplete-guide-to-tensorflow-for-deep-learning-with-python%2F">Complete Guide to TensorFlow for Deep Learning with Python</a><IMG border=0 width=1 height=1 src="https://ad.linksynergy.com/fs-bin/show?id=Jbc0N5ZkDzk&#038;bids=323058.1326292&#038;type=2&#038;subid=0" ></p>
<hr />
<p>&nbsp;</p>
<p>The post <a rel="nofollow" href="http://adventuresinmachinelearning.com/vanishing-gradient-problem-tensorflow/">The vanishing gradient problem and ReLUs &#8211; a TensorFlow investigation</a> appeared first on <a rel="nofollow" href="http://adventuresinmachinelearning.com">Adventures in Machine Learning</a>.</p>
]]></content:encoded>
			<wfw:commentRss>http://adventuresinmachinelearning.com/vanishing-gradient-problem-tensorflow/feed/</wfw:commentRss>
		<slash:comments>2</slash:comments>
		</item>
		<item>
		<title>TensorFlow Dataset API tutorial &#8211; build high performance data pipelines</title>
		<link>http://adventuresinmachinelearning.com/tensorflow-dataset-tutorial/</link>
		<comments>http://adventuresinmachinelearning.com/tensorflow-dataset-tutorial/#comments</comments>
		<pubDate>Sat, 17 Mar 2018 01:55:31 +0000</pubDate>
		<dc:creator><![CDATA[Andy]]></dc:creator>
				<category><![CDATA[TensorFlow]]></category>

		<guid isPermaLink="false">http://adventuresinmachinelearning.com/?p=817</guid>
		<description><![CDATA[<p>Consuming data efficiently becomes really paramount to training performance in deep learning. In a previous post I discussed the TensorFlow data queuing framework. However, TensorFlow <a class="mh-excerpt-more" href="http://adventuresinmachinelearning.com/tensorflow-dataset-tutorial/" title="TensorFlow Dataset API tutorial &#8211; build high performance data pipelines">[...]</a></p>
<p>The post <a rel="nofollow" href="http://adventuresinmachinelearning.com/tensorflow-dataset-tutorial/">TensorFlow Dataset API tutorial &#8211; build high performance data pipelines</a> appeared first on <a rel="nofollow" href="http://adventuresinmachinelearning.com">Adventures in Machine Learning</a>.</p>
]]></description>
				<content:encoded><![CDATA[<p>Consuming data efficiently becomes really paramount to training performance in deep learning. In a previous post I discussed the <a href="http://adventuresinmachinelearning.com/introduction-tensorflow-queuing/" target="_blank" rel="noopener">TensorFlow data queuing framework</a>. However, TensorFlow development is always on the move and they have now created a more streamlined and efficient way of setting up data input pipelines. This TensorFlow Dataset tutorial will show you how to use this Dataset framework to enable you to produce highly efficient input data pipelines. This is an important topic which isn&#8217;t covered very well in most TensorFlow tutorials &#8211; rather, these tutorials will often use the <em>feed_dict</em> and placeholder method of feeding data into the model. This method of feeding data into your network in TensorFlow is <em>inefficient</em> and will likely slow down your training for large, realistic datasets &#8211; see a discussion about this on the <a href="https://www.tensorflow.org/performance/performance_guide" target="_blank" rel="noopener">TensorFlow website. </a>Why is this framework better than the feed_dict method that is so commonly used? Simply, all of the operations to transform data and feed it into the model which can be performed with the Dataset API i.e. reading the data from arrays and files, transforming it, shuffling it etc. can all be automatically optimized and paralleled to provide efficient consumption of data.</p>
<p>In this TensorFlow Dataset tutorial, I will show you how to use the framework with some simple examples, and finally show you how to consume the scikit-learn MNIST dataset to create an MNIST classifier. As always, the code for this tutorial can be found on this site&#8217;s <a href="https://github.com/adventuresinML/adventures-in-ml-code" target="_blank" rel="noopener">Github repository</a>.</p>
<p>&nbsp;</p>
<hr />
<p><strong>Recommended</strong><strong> online course: </strong>If you&#8217;d like to learn more about TensorFlow I&#8217;d recommend the following inexpensive Udemy course: <a href="https://click.linksynergy.com/link?id=Jbc0N5ZkDzk&#038;offerid=323058.1326292&#038;type=2&#038;murl=https%3A%2F%2Fwww.udemy.com%2Fcomplete-guide-to-tensorflow-for-deep-learning-with-python%2F">Complete Guide to TensorFlow for Deep Learning with Python</a><IMG border=0 width=1 height=1 src="https://ad.linksynergy.com/fs-bin/show?id=Jbc0N5ZkDzk&#038;bids=323058.1326292&#038;type=2&#038;subid=0" ></p>
<hr />
<h2>The TensorFlow Dataset framework &#8211; main components</h2>
<p>The TensorFlow Dataset framework has two main components:</p>
<ul>
<li>The Dataset</li>
<li>An associated Iterator</li>
</ul>
<p>The Dataset is basically where the data resides. This data can be loaded in from a number of sources &#8211; existing tensors, numpy arrays and numpy files, the TFRecord format and direct from text files. Once you&#8217;ve loaded the data into the Dataset object, you can string together various operations to apply to the data, these include operations such as:</p>
<ul>
<li>batch() &#8211; this allows you to consume the data from your TensorFlow Dataset in batches</li>
<li>map() &#8211; this allows you to transform the data using lambda statements applied to each element</li>
<li>zip() &#8211; this allows you to zip together different Dataset objects into a new Dataset, in a similar way to the Python zip function</li>
<li>filter() &#8211; this allows you to remove problematic data-points in your data-set, again based on some lambda function</li>
<li>repeat() &#8211; this operation restricts the number of times data is consumed from the Dataset before a tf.errors.OutOfRangeError error is thrown</li>
<li>shuffle() &#8211; this operation shuffles the data in the Dataset</li>
</ul>
<p>There are many other methods that the Dataset API includes &#8211; see <a href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset#repeat" target="_blank" rel="noopener">here</a> for more details.  The next component in the TensorFlow Dataset framework is the Iterator. This creates operations which can be called during the training, validation and/or testing of your model in TensorFlow. I&#8217;ll introduce more of both components in some examples below.</p>
<h2>Simple TensorFlow Dataset examples</h2>
<p>In the first simple example, we&#8217;ll create a dataset out of numpy ranges:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">x = np.arange(0, 10)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>We can create a TensorFlow Dataset object straight from a numpy array using <em>from_tensor_slices()</em>:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># create dataset object from numpy array
dx = tf.data.Dataset.from_tensor_slices(x)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>The object <em>dx</em> is now a TensorFlow Dataset object. The next step is to create an Iterator that will extract data from this dataset. In the code below, the iterator is created using the method <em>make_one_shot_iterator()</em>.  The iterator arising from this method can only be initialized and run once &#8211; it can&#8217;t be re-initialized. The importance of being able to re-initialize an iterator will be explained more later.</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># create a one-shot iterator
iterator = dx.make_one_shot_iterator()
# extract an element
next_element = iterator.get_next()</code></pre> <div class="code-embed-infos"> </div> </div>
<p>After the iterator is created, the next step is to setup a TensorFlow operation which can be called from the training code to extract the next element from the dataset. Finally, the dataset operation can be examined by running the following code:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">with tf.Session() as sess:
    for i in range(11):
        val = sess.run(next_element)
        print(val)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>This code will print out integers from 0 to 9 but then throw an OutOfRangeError. This is because the code extracted all the data slices from the dataset and it is now out of range or &#8220;empty&#8221;.</p>
<p>If we want to repeatedly extract data from a dataset, one way we can do it is to make the dataset re-initializable. We can do that by first adjusting the <em>make_one_shot_iterator()</em> line to the following:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">iterator = dx.make_initializable_iterator()</code></pre> <div class="code-embed-infos"> </div> </div>
<p>Then, within the TensorFlow session, the code looks like this:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">with tf.Session() as sess:
    sess.run(iterator.initializer)
    for i in range(15):
        val = sess.run(next_element)
        print(val)
        if i % 9 == 0 and i &gt; 0:
            sess.run(iterator.initializer)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>Note that the first operation run is the iterator.initializer operation. This is required to get your iterator ready for action and if you don&#8217;t do this before running the next_element operation it will throw an error. The final change is the last two lines: this <em>if </em>statement ensures that when we know that the iterator has run out of data (i.e. i == 9), the iterator is re-initialized by the iterator.initializer operation. Running this new code will produce: 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4. No error this time!</p>
<p>There are also other things that can be done to manipulate the dataset and how it can be used. First, the batch function:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">dx = tf.data.Dataset.from_tensor_slices(x).batch(3)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>After this change, when the next_element operation is run, a batch of length 3 will be extracted from the data. Running the code below:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">with tf.Session() as sess:
    sess.run(iterator.initializer)
    for i in range(15):
        val = sess.run(next_element)
        print(val)
        if (i + 1) % (10 // 3) == 0 and i &gt; 0:
            sess.run(iterator.initializer)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>Will produce an output like:</p>
[0 1 2]
[3 4 5]
[6 7 8]
[0 1 2]
[3 4 5]
[6 7 8]
<p>and so on.</p>
<p>Next, we can zip together datasets. This is useful when pairing up input-output training/validation pairs of data (i.e. input images and matching labels for each image). The code below does this:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">def simple_zip_example():
    x = np.arange(0, 10)
    y = np.arange(1, 11)
    # create dataset objects from the arrays
    dx = tf.data.Dataset.from_tensor_slices(x)
    dy = tf.data.Dataset.from_tensor_slices(y)
    # zip the two datasets together
    dcomb = tf.data.Dataset.zip((dx, dy)).batch(3)
    iterator = dcomb.make_initializable_iterator()
    # extract an element
    next_element = iterator.get_next()
    with tf.Session() as sess:
        sess.run(iterator.initializer)
        for i in range(15):
            val = sess.run(next_element)
            print(val)
            if (i + 1) % (10 // 3) == 0 and i &gt; 0:
                sess.run(iterator.initializer)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>The zip combination of the two datasets (<em>dx, dy</em>) can be seen in the line where <em>dcomb</em> is created. Note the chaining together of multiple operations &#8211; first the zip method, then the batching operation. The rest of the code is the same. This code will produce an output like the following:</p>
<p>(array([0, 1, 2]), array([1, 2, 3]))<br />
(array([3, 4, 5]), array([4, 5, 6]))<br />
(array([6, 7, 8]), array([7, 8, 9]))<br />
(array([0, 1, 2]), array([1, 2, 3]))</p>
<p>and so on. As you can observe, the batching takes place appropriately within the zipped together datasets i.e. 3 items from dx, 3 items from dy. As stated above, this is handy for combining input data and matching labels.</p>
<p>Note, the re-initialization <em>if </em>statement on the last two lines is a bit unwieldy, we can actually get rid of it by replacing the <em>dcomb</em> dataset creation line with the following:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">dcomb = tf.data.Dataset.zip((dx, dy)).repeat().batch(3)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>Note the addition of the <em>repeat()</em> method to the operation list. When this method is applied to the dataset with no argument, it means that the dataset can be repeated indefinitely without throwing an OutOfRangeError. This will be shown in the next more detailed example &#8211; using the sci-kit learn MNIST dataset to create a hand-written digits classifier.</p>
<h2>TensorFlow Dataset MNIST example</h2>
<p>In this section, I&#8217;ll show how to create an MNIST hand-written digit classifier which will consume the MNIST image and label data from the simplified MNIST dataset supplied from the Python <a href="http://scikit-learn.org/stable/index.html" target="_blank" rel="noopener">scikit-learn</a> package (a must-have package for practical machine learning enthusiasts). I&#8217;ll step through the code slowly below.</p>
<p>First, we have to load the data from the package and split it into train and validation datasets. This can be performed with the following code:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># load the data
digits = load_digits(return_X_y=True)
# split into train and validation sets
train_images = digits[0][:int(len(digits[0]) * 0.8)]
train_labels = digits[1][:int(len(digits[0]) * 0.8)]
valid_images = digits[0][int(len(digits[0]) * 0.8):]
valid_labels = digits[1][int(len(digits[0]) * 0.8):]</code></pre> <div class="code-embed-infos"> </div> </div>
<p>The load_digits method will extract the data from the relevant location in the scikit-learn package, and the code above splits the first 80% of the data into the training arrays, and the remaining 20% into the validation arrays.</p>
<p>Next, the TensorFlow Datasets of the training data are created:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># create the training datasets
dx_train = tf.data.Dataset.from_tensor_slices(train_images)
# apply a one-hot transformation to each label for use in the neural network
dy_train = tf.data.Dataset.from_tensor_slices(train_labels).map(lambda z: tf.one_hot(z, 10))
# zip the x and y training data together and shuffle, batch etc.
train_dataset = tf.data.Dataset.zip((dx_train, dy_train)).shuffle(500).repeat().batch(30)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>The <em>dx_train </em>statement is straightforward, however there is an extra element that has been added in the <em>dy_train</em> statement. Note the use of the <em>map()</em> method. The labels in the MNIST dataset are integers between 0 and 9 corresponding to the hand-written digit in the image. This integer data must be transformed into one-hot format, i.e. the integer label 4 transformed into the vector [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]. To do this, the lambda statement is used, where every row (expressed as <em>z</em> in the above) in the label dataset is transformed into one-hot data format using the TensorFlow one_hot function. If you&#8217;d like to learn more about one hot data structures and neural networks, see <a href="http://adventuresinmachinelearning.com/neural-networks-tutorial/" target="_blank" rel="noopener">my neural network tutorial</a>.</p>
<p>Finally, the training <em>x</em> and <em>y</em> data is zipped together in the full <em>train_dataset</em>. Chained along together with this zip method is first the <em>shuffle()</em> dataset method. This method randomly shuffles the data, using a buffer of data specified in the argument &#8211; 500 in this case. Next, the <em>repeat() </em>method is used, to allow the iterator to continuously extract data from this dataset, finally the data is batched with a batch size of 30.</p>
<p>The same steps are used to create the validation dataset:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># do the same operations for the validation set
dx_valid = tf.data.Dataset.from_tensor_slices(valid_images)
dy_valid = tf.data.Dataset.from_tensor_slices(valid_labels).map(lambda z: tf.one_hot(z, 10))
valid_dataset = tf.data.Dataset.zip((dx_valid, dy_valid)).shuffle(500).repeat().batch(30)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>Now, we want to be able to extract data from either the train_dataset or the valid_dataset seamlessly. This is important, as we don&#8217;t want to have to change how data flows through the neural network structure when all we want to do is just change the dataset the model is consuming. To do this, we can use another way of creating the Iterator object &#8211; the <em>from_structure() </em>method. This method creates a <em>generic</em> iterator object &#8211; all it needs is the data types of the data it will be outputting and the output data size/shape in order to be created. The code below uses this methodology:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># create general iterator
iterator = tf.data.Iterator.from_structure(train_dataset.output_types,
                                               train_dataset.output_shapes)
next_element = iterator.get_next()</code></pre> <div class="code-embed-infos"> </div> </div>
<p>The second line of the above creates a standard <em>get_next() </em>iterator operation which can be called to extract data from this generic iterator structure. Next, we need some operations which can be called during training or validating to initialize this generic iterator and &#8220;point it&#8221; to the desired dataset. These are as follows:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># make datasets that we can initialize separately, but using the same structure via the common iterator
training_init_op = iterator.make_initializer(train_dataset)
validation_init_op = iterator.make_initializer(valid_dataset)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>These operations can be run to &#8220;switch over&#8221; the iterator from one dataset to another. This &#8220;switching over&#8221; will be demonstrated in code below.</p>
<p>Next, the neural network model is created &#8211; this is standard TensorFlow usage and in this case I will be utilizing the TensorFlow layers API to create a simple fully connected or dense neural network, with dropout and a first layer of batch normalization to effectively scale the input data. If you&#8217;d like to learn some of the basics of TensorFlow, check out my <a href="http://adventuresinmachinelearning.com/python-tensorflow-tutorial/" target="_blank" rel="noopener">Python TensorFlow tutorial</a>. The TensorFlow model is defined as follows:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">def nn_model(in_data):
    bn = tf.layers.batch_normalization(in_data)
    fc1 = tf.layers.dense(bn, 50)
    fc2 = tf.layers.dense(fc1, 50)
    fc2 = tf.layers.dropout(fc2)
    fc3 = tf.layers.dense(fc2, 10)
    return fc3</code></pre> <div class="code-embed-infos"> </div> </div>
<p>To call this model creation function, the code below can be used:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># create the neural network model
logits = nn_model(next_element[0])</code></pre> <div class="code-embed-infos"> </div> </div>
<p>Note that the next_element operation is handled directly in the model &#8211; in other words, it doesn&#8217;t need to be called explicitly during the training loop as will be seen below. Rather, whenever any of the operations following this point in the graph are called (i.e. the loss operation, the optimization operation etc.) the TensorFlow graph structure will know to run the next_element operation and extract the data from whichever dataset has been initialized into the iterator. The next_element operation, because it is operating on the generic iterator which is defined by the shape of the train_dataset, is a tuple &#8211; the first element ([0]) will contain the MNIST images, while the second element ([1]) will contain the corresponding labels. Therefore, next_element[0] will extract the image data batch and send it into the neural network model (nn_model) as the input data.</p>
<p>Next are some standard TensorFlow operations to calculate the loss function, the optimization step and prediction accuracy (again, for more details see <a href="http://adventuresinmachinelearning.com/python-tensorflow-tutorial/" target="_blank" rel="noopener">this tutorial</a> or <a href="http://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-tensorflow/" target="_blank" rel="noopener">this one</a>):</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># add the optimizer and loss
loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits_v2(labels=next_element[1], logits=logits))
optimizer = tf.train.AdamOptimizer().minimize(loss)
# get accuracy
prediction = tf.argmax(logits, 1)
equality = tf.equal(prediction, tf.argmax(next_element[1], 1))
accuracy = tf.reduce_mean(tf.cast(equality, tf.float32))
init_op = tf.global_variables_initializer()</code></pre> <div class="code-embed-infos"> </div> </div>
<p>Now we can run the training loop:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># run the training
epochs = 600
with tf.Session() as sess:
    sess.run(init_op)
    sess.run(training_init_op)
    for i in range(epochs):
        l, _, acc = sess.run([loss, optimizer, accuracy])
        if i % 50 == 0:
            print(&quot;Epoch: {}, loss: {:.3f}, training accuracy: {:.2f}%&quot;.format(i, l, acc * 100))
    # now setup the validation run
    valid_iters = 100
    # re-initialize the iterator, but this time with validation data
    sess.run(validation_init_op)
    avg_acc = 0
    for i in range(valid_iters):
        acc = sess.run([accuracy])
        avg_acc += acc[0]
    print(&quot;Average validation set accuracy over {} iterations is {:.2f}%&quot;.format(valid_iters,                                                                              (avg_acc / valid_iters) * 100))</code></pre> <div class="code-embed-infos"> </div> </div>
<p>As can be observed, before the main training loop is entered into, the session executes the training_init_op operation, which initializes the generic iterator to extract data from train_dataset. After running <em>epochs</em> iterations to train the model, we then want to check how the trained model performs on the validation dataset (valid_dataset). To do this, we can simply run the validation_init_op operation in the session to point the generic iterator to valid_dataset. Then we run the accuracy operation as per normal, knowing that the operation will be calculating the model accuracy based on the validation data, rather than the training data. Running this code will produce an output that will look something like:</p>
<figure id="attachment_828" style="width: 490px" class="wp-caption alignnone"><img class=" wp-image-828" src="http://adventuresinmachinelearning.com/wp-content/uploads/2018/03/Dataset-tutorial-MNIST-output.png" alt="TensorFlow Dataset tutorial - MNIST example output" width="490" height="235" srcset="http://adventuresinmachinelearning.com/wp-content/uploads/2018/03/Dataset-tutorial-MNIST-output.png 687w, http://adventuresinmachinelearning.com/wp-content/uploads/2018/03/Dataset-tutorial-MNIST-output-300x144.png 300w" sizes="(max-width: 490px) 100vw, 490px" /><figcaption class="wp-caption-text">TensorFlow Dataset tutorial &#8211; MNIST example output</figcaption></figure>
<p>Obviously not a create validation set accuracy for MNIST &#8211; but this is just an example model to demonstrate how to use the TensorFlow Dataset framework. For more accurate ways of performing image classification, check out my <a href="http://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-tensorflow/" target="_blank" rel="noopener">Convolutional Neural Network Tutorial in TensorFlow</a>.</p>
<p>So there you have it &#8211; hopefully you are now in a position to use this new, streamlined data input pipeline API in TensorFlow. Enjoy your newly optimized TensorFlow code.</p>
<hr />
<p><strong>Recommended</strong><strong> online course: </strong>If you&#8217;d like to learn more about TensorFlow I&#8217;d recommend the following inexpensive Udemy course: <a href="https://click.linksynergy.com/link?id=Jbc0N5ZkDzk&#038;offerid=323058.1326292&#038;type=2&#038;murl=https%3A%2F%2Fwww.udemy.com%2Fcomplete-guide-to-tensorflow-for-deep-learning-with-python%2F">Complete Guide to TensorFlow for Deep Learning with Python</a><IMG border=0 width=1 height=1 src="https://ad.linksynergy.com/fs-bin/show?id=Jbc0N5ZkDzk&#038;bids=323058.1326292&#038;type=2&#038;subid=0" ></p>
<hr />
<p>&nbsp;</p>
<p>The post <a rel="nofollow" href="http://adventuresinmachinelearning.com/tensorflow-dataset-tutorial/">TensorFlow Dataset API tutorial &#8211; build high performance data pipelines</a> appeared first on <a rel="nofollow" href="http://adventuresinmachinelearning.com">Adventures in Machine Learning</a>.</p>
]]></content:encoded>
			<wfw:commentRss>http://adventuresinmachinelearning.com/tensorflow-dataset-tutorial/feed/</wfw:commentRss>
		<slash:comments>5</slash:comments>
		</item>
		<item>
		<title>How to create a TensorFlow deep learning powerhouse on Amazon AWS</title>
		<link>http://adventuresinmachinelearning.com/tensorflow-amazon-aws/</link>
		<comments>http://adventuresinmachinelearning.com/tensorflow-amazon-aws/#respond</comments>
		<pubDate>Sat, 18 Nov 2017 09:53:10 +0000</pubDate>
		<dc:creator><![CDATA[Andy]]></dc:creator>
				<category><![CDATA[Amazon AWS]]></category>
		<category><![CDATA[Deep learning]]></category>
		<category><![CDATA[GPUs]]></category>
		<category><![CDATA[Recurrent neural networks]]></category>
		<category><![CDATA[TensorFlow]]></category>

		<guid isPermaLink="false">http://adventuresinmachinelearning.com/?p=703</guid>
		<description><![CDATA[<p>In my previous tutorial on recurrent neural networks and LSTM networks in TensorFlow, we weren&#8217;t able to get fantastic results. This is because I was <a class="mh-excerpt-more" href="http://adventuresinmachinelearning.com/tensorflow-amazon-aws/" title="How to create a TensorFlow deep learning powerhouse on Amazon AWS">[...]</a></p>
<p>The post <a rel="nofollow" href="http://adventuresinmachinelearning.com/tensorflow-amazon-aws/">How to create a TensorFlow deep learning powerhouse on Amazon AWS</a> appeared first on <a rel="nofollow" href="http://adventuresinmachinelearning.com">Adventures in Machine Learning</a>.</p>
]]></description>
				<content:encoded><![CDATA[<p>In my previous tutorial on recurrent neural networks and LSTM networks in TensorFlow, we weren&#8217;t able to get fantastic results. This is because I was running the code on my little ol&#8217; laptop CPU &#8211; not exactly the ideal setup for big deep learning networks. So what to do? I could fork out thousands on a specced up desktop with <a href="https://www.nvidia.com/en-us/deep-learning-ai/developer/" target="_blank" rel="noopener">NVIDIA GPUs</a>, but, you know, I have a family and bills to pay. So the best option, I think, is to hire out some GPUs on Amazon AWS. That&#8217;s just what I did, and I&#8217;m going to give you a how-to guide below on how to do it. Then I&#8217;m going to run the <a href="https://github.com/adventuresinML/adventures-in-ml-code" target="_blank" rel="noopener">sequence-to-sequence LSTM model</a> that I created in TensorFlow, and show you the improvements. So let&#8217;s get to it.</p>
<hr />
<p><strong>Recommended online course: </strong>If you are more of a video course learner, checkout the following highly rated and inexpensive Udemy course, which covers deep learning concepts and how to deploy on Amazon AWS too: <a href="https://click.linksynergy.com/link?id=Jbc0N5ZkDzk&amp;offerid=323058.772462&amp;type=2&amp;murl=https%3A%2F%2Fwww.udemy.com%2Fdata-science-deep-learning-in-theano-tensorflow%2F" target="new">Modern Deep Learning in Python</a><img src="https://ad.linksynergy.com/fs-bin/show?id=Jbc0N5ZkDzk&amp;bids=323058.772462&amp;type=2&amp;subid=0" width="1" height="1" border="0" /></p>
<hr />
<h1>Step 1 &#8211; Setup an Amazon AWS account and load up an instance</h1>
<p>The first thing to do is to head over to <a href="https://aws.amazon.com/" target="_blank" rel="noopener">Amazon AWS</a> and create an account. You&#8217;ll need to supply some credit card details, as the computing power isn&#8217;t free &#8211; but we&#8217;ll be using a cheap option here, so it shouldn&#8217;t cost you too much if you want to follow along (a few dollars). At this stage, you may have to request, via Amazon AWS support, for them to free up an EC2 instance for you in your region. To do this, log into your Amazon AWS account and go to the dashboard. At the top of the window you&#8217;ll see a &#8220;Services&#8221; drop down &#8211; click this and select the Support link on the left hand side. Once you&#8217;ve clicked this, on the next page click &#8220;Create Case&#8221;, again on the left hand side menu.</p>
<p>On this page, next to the heading &#8220;Regarding&#8221;, select &#8220;Service Limit Increase&#8221;. Then, under &#8220;Limit Type&#8221; select &#8220;EC2 Instances&#8221;. Select your closest region, and under &#8220;Primary Instance Type&#8221; select &#8220;p2.xlarge&#8221;. Leave the &#8220;Limit&#8221; field as &#8220;Instance Limit&#8221;, and put a &#8220;1&#8221; in the field &#8220;New limit value&#8221;. Put in a use case description i.e. &#8220;Deep learning computing&#8221; then submit the case. Amazon AWS will then free up an instance for you to use, which might take a little while for them to do. If the terms above like &#8220;EC2 instance&#8221; and &#8220;p2.xlarge&#8221; don&#8217;t make sense at this stage, don&#8217;t worry &#8211; they are explained more fully later.</p>
<p>Once you&#8217;re done that, head over to <a href="https://aws.amazon.com/marketplace/pp/B01M0AXXQB?qid=1510042228622&amp;sr=0-3&amp;ref_=srh_res_product_title" target="_blank" rel="noopener">this link</a>. This page (see below) details a specifically setup Amazon Machine Instance (AMI) with all your favorite deep learning packages already loaded up &#8211; TensorFlow, Keras, PyTorch, CNTK, MXNet and more.</p>
<figure id="attachment_704" style="width: 1526px" class="wp-caption alignnone"><img class="size-full wp-image-704" src="http://adventuresinmachinelearning.com/wp-content/uploads/2017/11/Amazon-AWS-Step-1.png" alt="Amazon AWS TensorFlow how-to: AMI selection" width="1526" height="798" srcset="http://adventuresinmachinelearning.com/wp-content/uploads/2017/11/Amazon-AWS-Step-1.png 1526w, http://adventuresinmachinelearning.com/wp-content/uploads/2017/11/Amazon-AWS-Step-1-300x157.png 300w, http://adventuresinmachinelearning.com/wp-content/uploads/2017/11/Amazon-AWS-Step-1-768x402.png 768w, http://adventuresinmachinelearning.com/wp-content/uploads/2017/11/Amazon-AWS-Step-1-1024x535.png 1024w" sizes="(max-width: 1526px) 100vw, 1526px" /><figcaption class="wp-caption-text">Amazon AWS &#8211; deep learning AMI selection</figcaption></figure>
<p>Scroll down and check out the EC2 instances available and the hourly prices on the right hand side. The EC2 instances are scale-able cloud computing services offered by Amazon AWS, and there are lots of different machine arrangements to choose from. In this case, we want to choose an AMI with at least 1 NVIDIA GPU. To do that, select your appropriate region on the right hand side and then hit the continue button.</p>
<p>You&#8217;ll then be taken to a launch page that looks like:</p>
<figure id="attachment_705" style="width: 1411px" class="wp-caption alignnone"><img class="size-full wp-image-705" src="http://adventuresinmachinelearning.com/wp-content/uploads/2017/11/Amazon-AWS-Step-1-instance-selection.png" alt="Amazon AWS TensorFlow - AMI instance selection" width="1411" height="805" srcset="http://adventuresinmachinelearning.com/wp-content/uploads/2017/11/Amazon-AWS-Step-1-instance-selection.png 1411w, http://adventuresinmachinelearning.com/wp-content/uploads/2017/11/Amazon-AWS-Step-1-instance-selection-300x171.png 300w, http://adventuresinmachinelearning.com/wp-content/uploads/2017/11/Amazon-AWS-Step-1-instance-selection-768x438.png 768w, http://adventuresinmachinelearning.com/wp-content/uploads/2017/11/Amazon-AWS-Step-1-instance-selection-1024x584.png 1024w" sizes="(max-width: 1411px) 100vw, 1411px" /><figcaption class="wp-caption-text">AMI instance selection</figcaption></figure>
<p>Let&#8217;s go with the &#8220;1-Click Launch&#8221; option to make things nice and easy. Then, I&#8217;d suggest selecting the p2.xlarge EC2 instance under the &#8220;EC2 Instance Type&#8221; pane. This gives us 1 NVIDIA K80 GPU to play with. At the time of writing, this instance costs $1.54 / hour for an Asia Pacific (Sydney) deploy. Not too bad.</p>
<p>If you&#8217;re like me and haven&#8217;t done this before, scroll down to the bottom of the page and you&#8217;ll find this box:</p>
<figure id="attachment_706" style="width: 509px" class="wp-caption aligncenter"><img class=" wp-image-706" src="http://adventuresinmachinelearning.com/wp-content/uploads/2017/11/Amazon-AWS-Step-1-key-pair.png" alt="Amazon AWS TensorFlow - key pair creation" width="509" height="188" srcset="http://adventuresinmachinelearning.com/wp-content/uploads/2017/11/Amazon-AWS-Step-1-key-pair.png 850w, http://adventuresinmachinelearning.com/wp-content/uploads/2017/11/Amazon-AWS-Step-1-key-pair-300x111.png 300w, http://adventuresinmachinelearning.com/wp-content/uploads/2017/11/Amazon-AWS-Step-1-key-pair-768x284.png 768w" sizes="(max-width: 509px) 100vw, 509px" /><figcaption class="wp-caption-text">Key pair creation</figcaption></figure>
<p>Expand the Key Pair pane and follow the instructions &#8211; this Key Pair is a security measure that is required to perform the necessary secure encryption when you logon to your instance. Once you&#8217;ve done that, refresh the page again, and make sure that your region matches if you had to change it. Once you match the region correctly with your Key Pair, the &#8220;Launch with 1-click&#8221; button will become enabled, as shown below. Click this, and your instance will be created after a few minutes.</p>
<figure id="attachment_707" style="width: 327px" class="wp-caption aligncenter"><img class=" wp-image-707" src="http://adventuresinmachinelearning.com/wp-content/uploads/2017/11/Amazon-AWS-Step-1-launch-button-enabled.png" alt="Amazon AWS TensorFlow - launch button enabled" width="327" height="245" srcset="http://adventuresinmachinelearning.com/wp-content/uploads/2017/11/Amazon-AWS-Step-1-launch-button-enabled.png 586w, http://adventuresinmachinelearning.com/wp-content/uploads/2017/11/Amazon-AWS-Step-1-launch-button-enabled-300x225.png 300w, http://adventuresinmachinelearning.com/wp-content/uploads/2017/11/Amazon-AWS-Step-1-launch-button-enabled-326x245.png 326w, http://adventuresinmachinelearning.com/wp-content/uploads/2017/11/Amazon-AWS-Step-1-launch-button-enabled-80x60.png 80w" sizes="(max-width: 327px) 100vw, 327px" /><figcaption class="wp-caption-text">Launch button enabled</figcaption></figure>
<p>Once you&#8217;ve hit the button above, you can go back to your <a href="http://console.aws.amazon.com/" target="_blank" rel="noopener">Amazon AWS dashboard</a>. Search or select the &#8220;EC2&#8221; service (under the &#8220;Compute&#8221; heading) in the AWS Services. This will take you to your EC2 dashboard, it should look something like this:</p>
<figure id="attachment_710" style="width: 670px" class="wp-caption aligncenter"><img class=" wp-image-710" src="http://adventuresinmachinelearning.com/wp-content/uploads/2017/11/Amazon-AWS-Step-1-EC2-console.png" alt="Amazon AWS TensorFlow - EC2 console" width="670" height="319" srcset="http://adventuresinmachinelearning.com/wp-content/uploads/2017/11/Amazon-AWS-Step-1-EC2-console.png 1469w, http://adventuresinmachinelearning.com/wp-content/uploads/2017/11/Amazon-AWS-Step-1-EC2-console-300x143.png 300w, http://adventuresinmachinelearning.com/wp-content/uploads/2017/11/Amazon-AWS-Step-1-EC2-console-768x366.png 768w, http://adventuresinmachinelearning.com/wp-content/uploads/2017/11/Amazon-AWS-Step-1-EC2-console-1024x488.png 1024w" sizes="(max-width: 670px) 100vw, 670px" /><figcaption class="wp-caption-text">Amazon AWS EC2 console</figcaption></figure>
<p>Note that under the Resources heading, there should be &#8220;1 Running Instances&#8221; showing &#8211; this is your instance. To access your running AMI, on the left hand side select &#8220;Instances&#8221;. You&#8217;ll then see your p2.xlarge instance up and running on the main pane. Select the button &#8220;Connect&#8221;. You&#8217;ll be presented with a pop-up window &#8220;Connect To Your Instance&#8221; &#8211; select either option. I&#8217;m using &#8220;A standalone SSH client&#8221; (PuTTY on Windows) &#8211; but you can choose whichever method you like to connect. Just follow the instruction Amazon AWS gives you to setup.</p>
<p>If you&#8217;re using PuTTY, there is one final step to allow you to properly use a Linux text manager and terminal multiplexer called Byobu. In your PuTTY program, before you connect, go to the settings menu on the left hand side. Under Connections &#8211; Data, in the field &#8220;Terminal-type string&#8221; enter &#8220;putty-256color&#8221;. This allows you to hit Ctrl-F2 in Windows to create multiple screens in Linux, which will let us monitor our GPU performance while training &#8211; this will be discussed later.</p>
<p>Once you&#8217;ve done that &#8211; you&#8217;re all connected! You should see a command prompt that looks like:</p>
<figure id="attachment_712" style="width: 966px" class="wp-caption alignnone"><img class="size-full wp-image-712" src="http://adventuresinmachinelearning.com/wp-content/uploads/2017/11/Amazon-AWS-Remote-console.png" alt="Amazon AWS TensorFlow - remote Linux console" width="966" height="356" srcset="http://adventuresinmachinelearning.com/wp-content/uploads/2017/11/Amazon-AWS-Remote-console.png 966w, http://adventuresinmachinelearning.com/wp-content/uploads/2017/11/Amazon-AWS-Remote-console-300x111.png 300w, http://adventuresinmachinelearning.com/wp-content/uploads/2017/11/Amazon-AWS-Remote-console-768x283.png 768w" sizes="(max-width: 966px) 100vw, 966px" /><figcaption class="wp-caption-text">AMI remote Linux console</figcaption></figure>
<h1>Step 2 &#8211; Exploring the instance and loading up the code</h1>
<p>The first thing you want to do when you have your instance running is update all the packages &#8211; you do this by running:</p>
<blockquote><p>sudo yum upgrade</p></blockquote>
<p>Next, let&#8217;s clone the Adventures in Machine Learning <a href="https://github.com/adventuresinML/adventures-in-ml-code" target="_blank" rel="noopener">github repo</a> by executing the following:</p>
<blockquote><p>git clone https://github.com/adventuresinML/adventures-in-ml-code</p></blockquote>
<p>Let&#8217;s also install a Python package called <em>gpustat </em>that we will use to monitor how our Nvidia GPU on the Amazon AWS instance is going as we train our recurrent neural network. Run:</p>
<blockquote><p>pip install gpustat</p></blockquote>
<p>Ok, so we&#8217;re not too far off being able to run the code using the GPU. However, first we&#8217;ll want to be able to monitor the GPU as we train. To do this on a Linux machine we need two screens, and we can use the package mentioned earlier called byobu to do this. To install it, we first need to go back to the root or administration privilege of our instance. Run this:</p>
<blockquote><p><span class="pln">sudo su </span><span class="pun">&#8211; </span></p></blockquote>
<p>Then to install byobu run this:</p>
<blockquote><p>yum install byobu</p></blockquote>
<p>Ok &#8211; now you can run byobu by simply typing &#8220;byobu&#8221; at the command prompt. To open up a new window, press Ctrl-F2. You&#8217;ll see this opens a new screen in your Linux session. To switch between the screens, press Ctrl-F3 and Ctrl-F4. Now, on one screen, we want to run the following to start a background monitoring process (which speeds up our gpustat package):</p>
<blockquote><p>sudo nvidia-smi daemon</p></blockquote>
<p>Then, on the same screen let&#8217;s setup our gpustat watch function, which will give us data about the GPU usage:</p>
<blockquote><p>watch -n1.0 gpustat -cp</p></blockquote>
<p>You should now see a utility printout with the GPU temperature, percentage usage and memory stats (see below for an example when we are actually running the code).</p>
<p>Now switch back to the other screen, using either Ctrl-F3 or Ctrl-F4.</p>
<h1>Step 3 &#8211; Download the data and run</h1>
<p>One final thing remains before we run the code &#8211; we first have to download the training data onto our instance. In the <a href="http://adventuresinmachinelearning.com/recurrent-neural-networks-lstm-tutorial-tensorflow/" target="_blank" rel="noopener">TensorFlow recurrent neural network tutorial</a> we used a text data-set from the following link: http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz. You&#8217;ll need to download and extract this tarfile &#8211; to do this run the following:</p>
<blockquote><p>curl http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz | tar xvz</p></blockquote>
<p>You can navigate around this extracted file / folder by using the Linux commands ls (to list the contents of the current path) and cd (for change directory). You need to find the path to simple-examples/data/ &#8211; this is where our training data files are located. Once you&#8217;ve done this, we can finally run the following command to start training the LSTM network created in the aforementioned tutorial:</p>
<blockquote><p>python lstm_tutorial.py 1 &#8211;data_path /home/ec2-user/data/simple-examples/data/</p></blockquote>
<p>Once you run the above command, the program will start and, after it prints out some text data it will begin to train the network (note the dash before &#8220;data_path&#8221; is actually a double dash: &#8220;&#8211;&#8220;). After every 50 iterations, you can observe the loss, the accuracy on the training set and the average time it took to execute each iteration. You&#8217;ll see something like this:</p>
<figure id="attachment_722" style="width: 663px" class="wp-caption aligncenter"><img class=" wp-image-722" src="http://adventuresinmachinelearning.com/wp-content/uploads/2017/11/Example-output-with-step-timing-Amazon-AWS-GPU.png" alt="Amazon AWS TensorFlow - GPU training times" width="663" height="149" srcset="http://adventuresinmachinelearning.com/wp-content/uploads/2017/11/Example-output-with-step-timing-Amazon-AWS-GPU.png 909w, http://adventuresinmachinelearning.com/wp-content/uploads/2017/11/Example-output-with-step-timing-Amazon-AWS-GPU-300x67.png 300w, http://adventuresinmachinelearning.com/wp-content/uploads/2017/11/Example-output-with-step-timing-Amazon-AWS-GPU-768x172.png 768w" sizes="(max-width: 663px) 100vw, 663px" /><figcaption class="wp-caption-text">Example output with GPU training times</figcaption></figure>
<p>As you can observe, each iteration takes an average of 0.14 seconds to execute. I&#8217;ve also run this oj my own Intel i5 CPUs and the average iteration time is around 3 seconds &#8211; so we get a greater than 20 times increase in performance with a single Amazon AWS Nvidia GPU. Not bad!</p>
<p>While it&#8217;s training, let&#8217;s take a look at what our GPU doing &#8211; hit Ctrl-F3 or Ctrl-F4 and you&#8217;ll return to your gpustat watch print-out. It should look something like this:</p>
<figure id="attachment_724" style="width: 608px" class="wp-caption aligncenter"><img class=" wp-image-724" src="http://adventuresinmachinelearning.com/wp-content/uploads/2017/11/GPU_status_during_run.png" alt="Amazon AWS TensorFlow - GPU status" width="608" height="51" srcset="http://adventuresinmachinelearning.com/wp-content/uploads/2017/11/GPU_status_during_run.png 926w, http://adventuresinmachinelearning.com/wp-content/uploads/2017/11/GPU_status_during_run-300x25.png 300w, http://adventuresinmachinelearning.com/wp-content/uploads/2017/11/GPU_status_during_run-768x65.png 768w" sizes="(max-width: 608px) 100vw, 608px" /><figcaption class="wp-caption-text">GPU status while training the LSTM network</figcaption></figure>
<p>So here we can see that the GPU is running close to maximum capacity &#8211; 81%. Good to see</p>
<p>WARNING: Remember, you have to shut down your instance on your EC2 console on Amazon AWS when you are complete. It&#8217;s not enough to shut down your PuTTY session or similar &#8211; you have to go an shut down your instance on the AWS dashboard. If you don&#8217;t you&#8217;ll be getting charged per hour with the instance sitting there doing nothing!</p>
<p>I hope that&#8217;s been helpful and will let you get your own Amazon AWS deep learning instance up and running. Enjoy your faster model training!</p>
<hr />
<p><strong>Recommended online course: </strong>If you are more of a video course learner, checkout the following highly rated and inexpensive Udemy course, which covers deep learning concepts and how to deploy on Amazon AWS too: <a href="https://click.linksynergy.com/link?id=Jbc0N5ZkDzk&amp;offerid=323058.772462&amp;type=2&amp;murl=https%3A%2F%2Fwww.udemy.com%2Fdata-science-deep-learning-in-theano-tensorflow%2F" target="new">Modern Deep Learning in Python</a><img src="https://ad.linksynergy.com/fs-bin/show?id=Jbc0N5ZkDzk&amp;bids=323058.772462&amp;type=2&amp;subid=0" width="1" height="1" border="0" /></p>
<hr />
<p>&nbsp;</p>
<p>The post <a rel="nofollow" href="http://adventuresinmachinelearning.com/tensorflow-amazon-aws/">How to create a TensorFlow deep learning powerhouse on Amazon AWS</a> appeared first on <a rel="nofollow" href="http://adventuresinmachinelearning.com">Adventures in Machine Learning</a>.</p>
]]></content:encoded>
			<wfw:commentRss>http://adventuresinmachinelearning.com/tensorflow-amazon-aws/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>Recurrent neural networks and LSTM tutorial in Python and TensorFlow</title>
		<link>http://adventuresinmachinelearning.com/recurrent-neural-networks-lstm-tutorial-tensorflow/</link>
		<comments>http://adventuresinmachinelearning.com/recurrent-neural-networks-lstm-tutorial-tensorflow/#comments</comments>
		<pubDate>Mon, 09 Oct 2017 20:34:37 +0000</pubDate>
		<dc:creator><![CDATA[Andy]]></dc:creator>
				<category><![CDATA[Deep learning]]></category>
		<category><![CDATA[LSTMs]]></category>
		<category><![CDATA[Recurrent neural networks]]></category>
		<category><![CDATA[TensorFlow]]></category>

		<guid isPermaLink="false">http://adventuresinmachinelearning.com/?p=432</guid>
		<description><![CDATA[<p>In the deep learning journey so far on this website, I&#8217;ve introduced dense neural networks and convolutional neural networks (CNNs) which explain how to perform classification <a class="mh-excerpt-more" href="http://adventuresinmachinelearning.com/recurrent-neural-networks-lstm-tutorial-tensorflow/" title="Recurrent neural networks and LSTM tutorial in Python and TensorFlow">[...]</a></p>
<p>The post <a rel="nofollow" href="http://adventuresinmachinelearning.com/recurrent-neural-networks-lstm-tutorial-tensorflow/">Recurrent neural networks and LSTM tutorial in Python and TensorFlow</a> appeared first on <a rel="nofollow" href="http://adventuresinmachinelearning.com">Adventures in Machine Learning</a>.</p>
]]></description>
				<content:encoded><![CDATA[<p>In the deep learning journey so far on this website, I&#8217;ve introduced <a href="http://adventuresinmachinelearning.com/neural-networks-tutorial/" target="_blank" rel="noopener">dense neural networks</a> and <a href="http://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-tensorflow/" target="_blank" rel="noopener">convolutional neural networks</a> (CNNs) which explain how to perform classification tasks on static images.  We&#8217;ve seen good results, especially with CNN&#8217;s. However, what happens if we want to analyze dynamic data? What about videos, voice recognition or sequences of text? There are ways to do some of this using CNN&#8217;s, but the most popular method of performing classification and other analysis on <em>sequences</em> of data is recurrent neural networks.  This tutorial will be a very comprehensive introduction to recurrent neural networks and a subset of such networks &#8211; long-short term memory networks (or LSTM networks). I&#8217;ll also show you how to implement such networks in TensorFlow &#8211; including the data preparation step. It&#8217;s going to be a long one, so settle in and enjoy these pivotal networks in deep learning &#8211; at the end of this post, you&#8217;ll have a very solid understanding of recurrent neural networks and LSTMs. By the way, if you&#8217;d like to learn how to build LSTM networks in Keras, see <a href="http://adventuresinmachinelearning.com/keras-lstm-tutorial/" target="_blank" rel="noopener">this tutorial</a>.</p>
<p>As always, all the code for this post can be found on <a href="https://github.com/adventuresinML/adventures-in-ml-code" target="_blank" rel="noopener">this site&#8217;s Github repository</a>.</p>
<hr />
<p><strong>Recommended online course: </strong>If you are more of a video course learner, I&#8217;d recommend this inexpensive Udemy course: <a href="https://click.linksynergy.com/link?id=Jbc0N5ZkDzk&amp;offerid=323058.887814&amp;type=2&amp;murl=https%3A%2F%2Fwww.udemy.com%2Fdeep-learning-recurrent-neural-networks-in-python%2F">Deep Learning: Recurrent Neural Networks in Python</a><img src="https://ad.linksynergy.com/fs-bin/show?id=Jbc0N5ZkDzk&amp;bids=323058.887814&amp;type=2&amp;subid=0" width="1" height="1" border="0" /></p>
<hr />
<h1>An introduction to recurrent neural networks</h1>
<p>A recurrent neural network, at its most fundamental level, is simply a type of densely connected neural network (for an introduction to such networks, <a href="http://adventuresinmachinelearning.com/neural-networks-tutorial/" target="_blank" rel="noopener">see my tutorial</a>). However, the key difference to normal feed forward networks is the introduction of <em>time</em> &#8211; in particular, the output of the hidden layer in a recurrent neural network is <em>fed back </em><em>into itself</em>. Diagrams help here, so observe:</p>
<figure id="attachment_537" style="width: 363px" class="wp-caption aligncenter"><img class="size-full wp-image-537" src="http://adventuresinmachinelearning.com/wp-content/uploads/2017/09/Explicit-RNN.jpg" alt="Recurrent LSTM tutorial - RNN diagram with nodes" width="363" height="229" srcset="http://adventuresinmachinelearning.com/wp-content/uploads/2017/09/Explicit-RNN.jpg 363w, http://adventuresinmachinelearning.com/wp-content/uploads/2017/09/Explicit-RNN-300x189.jpg 300w" sizes="(max-width: 363px) 100vw, 363px" /><figcaption class="wp-caption-text">Recurrent neural network diagram with nodes shown</figcaption></figure>
<p>In the diagram above, we have a simple recurrent neural network with three input nodes.  These input nodes are fed into a hidden layer, with sigmoid activations, as per any normal <a href="http://adventuresinmachinelearning.com/neural-networks-tutorial/" target="_blank" rel="noopener">densely connected neural network</a>. What happens next is what is interesting &#8211; the output of the hidden layer is then <em>fed back</em> into the same hidden layer. As you can see the hidden layer outputs are passed through a conceptual <em>delay </em>block to allow the input of $\textbf{h}^{t-1}$ into the hidden layer.  What is the point of this? Simply, the point is that we can now model <em>time </em>or sequence-dependent data.</p>
<p>A particularly good example of this is predicting text sequences.  Consider the following text string: &#8220;A girl walked into a bar, and she said &#8216;Can I have a drink please?&#8217;.  The bartender said &#8216;Certainly {}&#8221;. There are many options for what could fill in the {} symbol in the above string, for instance, &#8220;miss&#8221;, &#8220;ma&#8217;am&#8221; and so on. However, other words could also fit, such as &#8220;sir&#8221;, &#8220;Mister&#8221; etc. In order to get the correct gender of the noun, the neural network needs to &#8220;recall&#8221; that two previous words designating the likely gender (i.e. &#8220;girl&#8221; and &#8220;she&#8221;) were used. This type of flow of information through time (or sequence) in a recurrent neural network is shown in the diagram below, which <em>unrolls </em>the sequence:</p>
<figure id="attachment_541" style="width: 555px" class="wp-caption aligncenter"><img class=" wp-image-541" src="http://adventuresinmachinelearning.com/wp-content/uploads/2017/09/Recurrent-neural-network.png" alt="Recurrent LSTM tutorial - unrolled RNN" width="555" height="181" srcset="http://adventuresinmachinelearning.com/wp-content/uploads/2017/09/Recurrent-neural-network.png 772w, http://adventuresinmachinelearning.com/wp-content/uploads/2017/09/Recurrent-neural-network-300x98.png 300w, http://adventuresinmachinelearning.com/wp-content/uploads/2017/09/Recurrent-neural-network-768x251.png 768w" sizes="(max-width: 555px) 100vw, 555px" /><figcaption class="wp-caption-text">Unrolled recurrent neural network</figcaption></figure>
<p>On the left-hand side of the above diagram, we have basically the same diagram as the first (the one which shows all the nodes explicitly). What the previous diagram neglected to show explicitly was that we in fact only ever supply finite length sequences to such networks &#8211; therefore we can <em>unroll </em>the network as shown on the right-hand side of the diagram above. This unrolled network shows how we can supply a stream of data to the recurrent neural network. For instance, first, we supply the word vector for &#8220;A&#8221; (more about word vectors later) to the network <em>F</em> &#8211; the output of the nodes in <em>F </em>are fed into the &#8220;next&#8221; network and also act as a stand-alone output ($h_0$).  The next network (though it is really the same network) <em>F</em> at time <em>t=1</em> takes the next word vector for &#8220;girl&#8221; and the previous output $h_0$ into its hidden nodes, producing the next output $h_1$ and so on.</p>
<p>As discussed above, the words themselves i.e. &#8220;A&#8221;, &#8220;girl&#8221; etc. aren&#8217;t input directly into the neural network. Neither are their one-hot vector type representations &#8211; rather, an embedding vector is used for each word. An embedding vector is an efficient vector representation of the word (often between 50-300 in length), which should maintain some meaning or context of the word. Word embedding won&#8217;t be entered into detail here, as I have covered it extensively in other posts &#8211; <a href="http://adventuresinmachinelearning.com/word2vec-tutorial-tensorflow/" target="_blank" rel="noopener">Word2Vec word embedding tutorial in Python and TensorFlow</a>, <a href="http://adventuresinmachinelearning.com/word2vec-keras-tutorial/" target="_blank" rel="noopener">A Word2Vec Keras tutorial</a> and <a href="http://adventuresinmachinelearning.com/gensim-word2vec-tutorial/" target="_blank" rel="noopener">Python gensim Word2Vec tutorial with TensorFlow and Keras</a>. It is an interesting topic and well worth the time investigating.</p>
<p>Now, back to recurrent neural networks themselves. Recurrent neural networks are very flexible. In the implementation shown above, we have a many-to-many model &#8211; in other words, we have the input sequence &#8220;A girl walked into a bar&#8230;&#8221; and many outputs &#8211; $h_0$ to $h_t$. We could also have multiple other configurations.  Another option is one-to-many i.e. supplying one input, say &#8220;girl&#8221; and predicting multiple outputs $h_0$ to $h_t$ (i.e. trying to generate sentences based on a single starting word). A further configuration is many-to-one i.e. supplying many words as input, like the sentence &#8220;A girl walked into a bar, and she said &#8216;Can I have a drink please?&#8217;.  The bartender said &#8216;Certainly {}&#8221; and predicting the next word i.e. {}. The diagram below shows an example one-to-many and many-to-one configuration, respectively (the words next to the outputs are the target words which we would supply during training).</p>
<figure id="attachment_546" style="width: 406px" class="wp-caption aligncenter"><img class=" wp-image-546" src="http://adventuresinmachinelearning.com/wp-content/uploads/2017/09/RNN-one-to-many.png" alt="Recurrent neural network LSTM - one-to-many configuration" width="406" height="227" srcset="http://adventuresinmachinelearning.com/wp-content/uploads/2017/09/RNN-one-to-many.png 502w, http://adventuresinmachinelearning.com/wp-content/uploads/2017/09/RNN-one-to-many-300x168.png 300w" sizes="(max-width: 406px) 100vw, 406px" /><figcaption class="wp-caption-text">Recurrent neural network &#8211; one-to-many configuration</figcaption></figure>
<figure id="attachment_547" style="width: 429px" class="wp-caption aligncenter"><img class=" wp-image-547" src="http://adventuresinmachinelearning.com/wp-content/uploads/2017/09/RNN-many-to-one.png" alt="Recurrent neural network LSTM - many-to-one configuration" width="429" height="238" srcset="http://adventuresinmachinelearning.com/wp-content/uploads/2017/09/RNN-many-to-one.png 507w, http://adventuresinmachinelearning.com/wp-content/uploads/2017/09/RNN-many-to-one-300x166.png 300w" sizes="(max-width: 429px) 100vw, 429px" /><figcaption class="wp-caption-text">Recurrent neural network &#8211; many-to-one configuration</figcaption></figure>
<p>There are also different many-to-many configurations that can be constructed &#8211; but you get the idea: recurrent neural networks are quite flexible. One last thing to note &#8211; the weights of the connections between time steps are <em>shared</em> i.e. there isn&#8217;t a different set of weights for each time step.</p>
<p>Now you have a pretty good idea of what recurrent neural networks are, it is time to point out their dominant problem.</p>
<h2>The problem with basic recurrent neural networks</h2>
<p>Vanilla recurrent neural networks aren&#8217;t actually used very often in practice. Why? The main reason is the vanishing gradient problem. For recurrent neural networks, ideally, we would want to have long memories, so the network can connect data relationships at significant distances in time. That sort of network could make real progress in understanding how language and narrative works, how stock market events are correlated and so on. However, the more time steps we have, the more chance we have of back-propagation gradients either accumulating and exploding or vanishing down to nothing.</p>
<p>Consider the following representation of a recurrent neural network:</p>
<p>$$\textbf{h}_t = \sigma (\textbf{Ux}_t + \textbf{Vh}_{t-1})$$</p>
<p>Where <strong><em>U </em></strong>and <strong><em>V</em></strong><em> </em>are the weight matrices connecting the inputs and the recurrent outputs respectively. We then often will perform a softmax of all the $\textbf{h}_t$ outputs (if we have some sort of many-to-many or one-to-many configuration). Notice, however, that if we go back three time steps in our recurrent neural network, we have the following:</p>
<p>$$\textbf{h}_t = \sigma (\textbf{Ux}_t + \textbf{V}(\sigma(\textbf{Ux}_{t-1} + \textbf{V}(\sigma(\textbf{Ux}_{t-2})))$$</p>
<p>From the above you can see, as we work our way back in time, we are essentially adding deeper and deeper layers to our network. This causes a problem &#8211; consider the gradient of the error with respect to the weight matrix <em><strong>U</strong></em> during backpropagation through time, it looks something along the lines of this:</p>
<p>$$\frac{\partial E_3}{\partial U} = \frac{\partial E_3}{\partial out_3}\frac{\partial out_3}{\partial h_3}\frac{\partial h_3}{\partial h_2}\frac{\partial h_2}{\partial h_1}\frac{\partial h_1}{\partial U}$$</p>
<p>The equation above is only a rough approximation of what is going on during backpropagation through time, but it will suffice for our purposes (for more on back-propagation, see my <a href="http://adventuresinmachinelearning.com/neural-networks-tutorial/" target="_blank" rel="noopener">comprehensive neural networks tutorial</a>). Each of these gradients will involve calculating the gradient of the sigmoid function. The problem with the sigmoid function occurs when the input values are such that the output is close to either 0 or 1 &#8211; at this point, the gradient is very small, see the plot below.</p>
<figure id="attachment_559" style="width: 389px" class="wp-caption aligncenter"><img class="size-full wp-image-559" src="http://adventuresinmachinelearning.com/wp-content/uploads/2017/09/Sigmoid-gradient.png" alt="Recurrent neural network and LSTM tutorial - sigmoid gradient" width="389" height="266" srcset="http://adventuresinmachinelearning.com/wp-content/uploads/2017/09/Sigmoid-gradient.png 389w, http://adventuresinmachinelearning.com/wp-content/uploads/2017/09/Sigmoid-gradient-300x205.png 300w" sizes="(max-width: 389px) 100vw, 389px" /><figcaption class="wp-caption-text">Sigmoid gradient</figcaption></figure>
<p>As you can observe, the values of the gradient (orange line) are always &lt;0.25 and get to very low values when the output gets close to 0 or 1. What does this mean? It means that when you multiply many sigmoid gradients together you are multiplying many values which are potentially much less than zero &#8211; this leads to a vanishing gradient $\frac{\partial E}{\partial U}$. Because the gradient will become basically zero when dealing with many prior time steps, the weights won&#8217;t adjust to take into account these values, and therefore the network won&#8217;t learn relationships separated by significant periods of time. This makes vanilla recurrent neural networks not very useful. If you&#8217;d like to learn more about the vanishing gradient problem, see my dedicated post about it <a href="http://adventuresinmachinelearning.com/vanishing-gradient-problem-tensorflow/">here</a>.</p>
<p>We could use <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)" target="_blank" rel="noopener">ReLU activation functions</a> to reduce this problem, though not eliminate it. However, the most popular way of dealing with this issue in recurrent neural networks is by using long-short term memory (LSTM) networks, which will be introduced in the next section.</p>
<h1>Introduction to LSTM networks</h1>
<p>To reduce the vanishing (and exploding) gradient problem, and therefore allow deeper networks and recurrent neural networks to perform well in practical settings, there needs to be a way to reduce the multiplication of gradients which are less than zero. The LSTM cell is a specifically designed unit of logic that will help reduce the vanishing gradient problem sufficiently to make recurrent neural networks more useful for long-term memory tasks i.e. text sequence predictions. The way it does so is by creating an internal memory state which<em> </em>is simply <em>added</em> to the processed input, which greatly reduces the multiplicative effect of small gradients. The time dependence and effects of previous inputs are controlled by an interesting concept called a <em>forget </em><em>gate</em>, which determines which states are remembered or forgotten. Two other gates, the <em>input gate</em> and <em>output</em><em> gate</em>, are also featured in LSTM cells.</p>
<p>Let&#8217;s first have a look at LSTM cells more carefully, then I&#8217;ll discuss how they help reduce the vanishing gradient problem.</p>
<h2>The structure of an LSTM cell</h2>
<p>The structure of a typical LSTM cell is shown in the diagram below:</p>
<figure id="attachment_564" style="width: 592px" class="wp-caption aligncenter"><img class=" wp-image-564" src="http://adventuresinmachinelearning.com/wp-content/uploads/2017/09/LSTM-diagram.png" alt="Recurrent neural network LSTM tutorial - LSTM cell diagram" width="592" height="285" srcset="http://adventuresinmachinelearning.com/wp-content/uploads/2017/09/LSTM-diagram.png 669w, http://adventuresinmachinelearning.com/wp-content/uploads/2017/09/LSTM-diagram-300x144.png 300w" sizes="(max-width: 592px) 100vw, 592px" /><figcaption class="wp-caption-text">LSTM cell diagram</figcaption></figure>
<p>The data flow is from left-to-right in the diagram above, with the current input $x_t$ and the previous cell output $h_{t-1}$ concatenated together and entering the top &#8220;data rail&#8221;. Here&#8217;s where things get interesting.</p>
<h3>The input gate</h3>
<p>First, the input is squashed between -1 and 1 using a <em>tanh</em> activation function. This can be expressed by:</p>
<p>$$g = tanh(b^g + x_tU^g + h_{t-1}V^g)$$</p>
<p>Where $U^g$ and $V^g$ are the weights for the input and previous cell output, respectively, and $b^g$ is the input bias. Note that the exponents <i>g</i> are not a raised power, but rather signify that these are the input weights and bias values (as opposed to the input gate, forget gate, output gate etc.).</p>
<p>This squashed input is then multiplied element-wise by the output of the <em>input gate</em>. The input gate is basically a hidden layer of sigmoid activated nodes, with weighted $x_t$ and $h_{t-1}$ input values, which outputs values of between 0 and 1 and when multiplied element-wise by the input determines which inputs are switched on and off. In other words, it is a kind of input filter or gate. The expression for the input gate is:</p>
<p>$$i = \sigma(b^i + x_tU^i + h_{t-1}V^i)$$</p>
<p>The output of the input stage of the LSTM cell can be expressed below, where the $\circ$ operator expresses element-wise multiplication:</p>
<p>$$g \circ i$$</p>
<p>As you can observe, the input gate output <em>i</em> acts as the weights for the squashed input <em>g</em>.  We now move onto the next stage of the LSTM cell &#8211; the internal state and the forget gate.</p>
<h3>The internal state and the forget gate</h3>
<p>This stage in the LSTM is where most of the magic happens. As can be observed, there is a new variable<em> </em>$s_t$ which is the inner state of the LSTM cell. This state is delayed by one-time step and is ultimately added to the $g \circ i$ input to provide an internal recurrence loop to learn the relationship between inputs separated by time. Two things to notice &#8211; first, there is a forget gate here &#8211; this forget gate is again a sigmoid activated set of nodes which is element-wise multiplied by $s_{t-1}$ to determine which previous states should be remembered (i.e. forget gate output close to 1) and which should be forgotten (i.e. forget gate output close to 0). This allows the LSTM cell to learn appropriate context. Consider the sentence &#8220;Clare took Helen to Paris and she was very grateful&#8221; &#8211; for the LSTM cell to learn who &#8220;she&#8221; refers to, it needs to forget the subject &#8220;Clare&#8221; and replace it with the subject &#8220;Helen&#8221;. The forget gate can facilitate such operations and is expressed as:<img class="wp-image-569 alignleft" src="http://adventuresinmachinelearning.com/wp-content/uploads/2017/09/Forget-gate-snippet.png" alt="Recurrent neural network LSTM tutorial - forget gate snippet" width="85" height="202" srcset="http://adventuresinmachinelearning.com/wp-content/uploads/2017/09/Forget-gate-snippet.png 193w, http://adventuresinmachinelearning.com/wp-content/uploads/2017/09/Forget-gate-snippet-126x300.png 126w" sizes="(max-width: 85px) 100vw, 85px" /></p>
<p>$$f = \sigma(b^f + x_tU^f + h_{t-1}V^f)$$</p>
<p>The output of the element-wise product of the previous state and the forget gate is expressed as $s_{t-1} \circ f$. Again, the forget gate output acts as weights for the internal state. The second thing to notice about this stage is that the forget-gate-&#8220;filtered&#8221; state is simply added to the input, rather than multiplied by it, or mixed with it via weights and a sigmoid activation function as occurs in a standard recurrent neural network. This is important to reduce the issue of vanishing gradients. The output from this stage, $s_t$ is expressed by:</p>
<p>$$s_t = s_{t-1} \circ f + g \circ i$$</p>
<p>The final stage of the LSTM cell is the output gate.</p>
<h3>The output gate</h3>
<p>The final stage of the LSTM cell is the output gate. The output gate has two components &#8211; another <em>tanh </em>squashing function and an output sigmoid gating function. The output sigmoid gating function, like the other gating functions in the cell, is multiplied by the squashed state $s_t$ to determine which values of the state are output from the cell. As you can tell, the LSTM cell is very flexible, with gating functions controlling what is input, what is &#8220;remembered&#8221; in the internal state variable, and finally what is output from the LSTM cell. <img class="wp-image-575 alignleft" src="http://adventuresinmachinelearning.com/wp-content/uploads/2017/09/Output-gate-snippet.png" alt="Recurrent neural network LSTM tutorial - output gate snippet" width="115" height="203" srcset="http://adventuresinmachinelearning.com/wp-content/uploads/2017/09/Output-gate-snippet.png 262w, http://adventuresinmachinelearning.com/wp-content/uploads/2017/09/Output-gate-snippet-169x300.png 169w" sizes="(max-width: 115px) 100vw, 115px" /></p>
<p>The output gate is expressed as:</p>
<p>$$o = \sigma(b^o + x_tU^o + h_{t-1}V^o)$$</p>
<p>So the final output of the cell can be expressed as:</p>
<p>$$h_t = tanh(s_t) \circ o$$</p>
<p>The next question is, how does the LSTM cell reduce the vanishing gradient problem?</p>
<h2>Reducing the vanishing gradient problem</h2>
<p>Recall before that the issue with vanilla recurrent neural networks is that calculating the gradient to update the weights involves cascading terms like:</p>
<p>$$\frac {\partial h_n}{\partial h_{n-1}} \frac {\partial h_{n-1}}{\partial h_{n-2}} \frac {\partial h_{n-2}}{\partial h_{n-3}} &#8230;$$</p>
<p>This is a problem because of the sigmoid derivative, which is present in all of the partial derivatives above, being &lt;0.25 (often greatly so). There is also a factorial of the weights involved, so if they are consistently &lt;1, we get a similar result &#8211; a vanishing gradient.</p>
<p>In an LSTM cell, the recurrency of the internal state of the LSTM cell involves, as shown above, an addition &#8211; like so:</p>
<p>$$s_t = s_{t-1} \circ f + g \circ i$$</p>
<p>If we take the partial derivative of this recurrency like we did above for a vanilla recurrent neural network, we find the following:</p>
<p>$$\frac{\partial s_t}{\partial s_{t-1}} = f$$</p>
<p>Notice that the $g \circ i$ term drops away and we are just left with a repeated multiplication of $f$. So for three time steps, we would have $f x f x f$. Notice that if the output of $f=1$, there will be no decay of the gradient. Generally, the bias of the sigmoid in $f$ is made large at the beginning of training so that $f$ starts out as 1 , meaning that all past input states will be &#8220;remembered&#8221; in the cell. During training, the forget gate will reduce or eliminate the memory of certain components of the state $s_{t-1}$.</p>
<p>This might be a bit confusing, so I&#8217;ll explain another way before we move on. Imagine if we let in a single input during the first time step, but then we block all future inputs (by setting the input gate to output zeros) and remember all previous states (by setting the forget gate to output ones). We would have a kind of circulating memory of $s_t$ which never decays i.e. $s_t$ = $s_{t-1}$. A back-propagated error &#8220;entering&#8221; this loop would also never decay. With the vanilla recurrent neural network, however, if we did the same thing our back-propagated error would be continuously degraded by the gradient of the activation function of the hidden nodes, and therefore eventually decay to zero.</p>
<p>Hopefully, that helps you to understand, at least in part, why LSTM cells are a great solution to the vanishing gradient problem, and therefore why they are currently used so extensively. Now, so far, we have been dealing with the data in the LSTM cells as if they were single values (i.e. scalars), however, in reality, they are tensors or vectors, and this can get confusing. So in the next section, I&#8217;ll spend a bit of time explaining the tensor sizes we can expect to be flowing around our unrolled LSTM networks.</p>
<h2>The dimensions of data inside an LSTM cell</h2>
<p>In the example code that is going to be discussed below, we are going to be performing text prediction. Now, as discussed in <a href="http://adventuresinmachinelearning.com/word2vec-tutorial-tensorflow/" target="_blank" rel="noopener">previous tutorials on the Word2Vec algorithm</a>, words are input into neural networks using meaningful word vectors i.e. the word &#8220;cat&#8221; might be represented by, say, a 650 length vector. This vector is encoded in such a way as to capture some aspect of the meaning of the word (where meaning is usually construed as the context the word is usually found in). So each word input into our LSTM network below will be a 650 length vector. Next, because we will be inputting a sequence of words into our unrolled LSTM network, for each input row we will be inputting 35 of these word vectors. So the input for each row will be (35 x 650) in size. Finally, with TensorFlow, we can process batches of data via multi-dimensional tensors (to learn more about basic TensorFlow, see <a href="http://adventuresinmachinelearning.com/python-tensorflow-tutorial/" target="_blank" rel="noopener">this TensorFlow tutorial</a>). If we have a batch size of 20, our <em>training</em> input data will be (20 x 35 x 650). For future reference, the way I have presented the tensor size here (i.e. (20 x 35 x 650)) is called a &#8220;batch-major&#8221; arrangement, where the batch size is the first dimension of the tensor. We could also alternatively arrange the data in &#8220;time-major&#8221; format, which would be (35 x 20 x 650) &#8211; same data, just a different arrangement.</p>
<p>Now, the next thing to consider is that each of the input, forget and output gates, along with the inner state variable $s_t$ and the squashing functions, are not single functions with single/scalar weights. Rather, they comprise the hidden layer of the network and therefore include multiple nodes, connecting weights, bias values and so on. It is up to us to set the size of the hidden layer. The output from the unrolled LSTM network will, therefore, include the size of the hidden layer. The size of the output from the unrolled LSTM network with a size 650 hidden layer, and a 20 length batch-size and 35 time steps will be (20, 35, 650). Often, the output of an unrolled LSTM will be partially flattened and fed into a softmax layer for classification &#8211; so, for instance, the first two dimensions of the tensor are flattened to give a softmax layer input size of (700, 650). The output of the softmax is then matched against the expected training outputs during training. The diagram below shows all this:</p>
<figure id="attachment_756" style="width: 503px" class="wp-caption aligncenter"><img class="wp-image-756 " src="http://adventuresinmachinelearning.com/wp-content/uploads/2017/10/LSTM-many-to-many-classifier-3.png" alt="TensorFlow LSTM network architecture" width="503" height="512" srcset="http://adventuresinmachinelearning.com/wp-content/uploads/2017/10/LSTM-many-to-many-classifier-3.png 657w, http://adventuresinmachinelearning.com/wp-content/uploads/2017/10/LSTM-many-to-many-classifier-3-295x300.png 295w" sizes="(max-width: 503px) 100vw, 503px" /><figcaption class="wp-caption-text">LSTM network architecture</figcaption></figure>
<p>As can be observed in the architecture above (which we will be creating in the code below), it is possible to stack layers of LSTM cells on top of each other &#8211; this increases the model complexity and predictive power but at the expense of training times and difficulties. The architecture shown above is what we will implement in TensorFlow in the next section. Note the small batch size &#8211; this is to allow a more stochastic gradient descent which will avoid settling in local minima during many training iterations (see <a href="http://adventuresinmachinelearning.com/stochastic-gradient-descent/" target="_blank" rel="noopener">here</a>).</p>
<h1>Creating an LSTM network in TensorFlow</h1>
<p>We are now going to create an LSTM network in TensorFlow. The code will loosely follow the TensorFlow team tutorial found <a href="https://github.com/tensorflow/models/tree/master/tutorials/rnn/ptb" target="_blank" rel="noopener">here</a>, but with updates and my own substantial modifications. The text dataset that will be used and is a common benchmarking corpus is the <a href="https://catalog.ldc.upenn.edu/ldc99t42" target="_blank" rel="noopener">Penn Tree Bank</a> (PTB) dataset. As usual, all the code for this post can be found on the <a href="https://github.com/adventuresinML/adventures-in-ml-code" target="_blank" rel="noopener">AdventuresinML Github site</a>. To run this code, you&#8217;ll first have to download and extract the .tgz file from <a href="http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz" target="_blank" rel="noopener">here</a>. First off, we&#8217;ll go through the data preparation part of the code.</p>
<h2>Preparing the data</h2>
<p>This code will use, verbatim, the following functions from the <a href="https://github.com/tensorflow/models/tree/master/tutorials/rnn/ptb" target="_blank" rel="noopener">previously mentioned TensorFlow tutorial</a>: <em>read_words, build_vocab </em>and <em>file_to_word_ids. </em>I won&#8217;t go into these functions in detail, but basically, they first split the given text file into separate words and sentence based characters (i.e. end-of-sentence &lt;eos&gt;). Then, each unique word is identified and assigned a unique integer. Finally, the original text file is converted into a list of these unique integers, where each word is substituted with its new integer identifier. This allows the text data to be consumed in the neural network.</p>
<p>The code below shows how these functions are used in my code:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">def load_data():
    # get the data paths
    train_path = os.path.join(data_path, &quot;ptb.train.txt&quot;)
    valid_path = os.path.join(data_path, &quot;ptb.valid.txt&quot;)
    test_path = os.path.join(data_path, &quot;ptb.test.txt&quot;)

    # build the complete vocabulary, then convert text data to list of integers
    word_to_id = build_vocab(train_path)
    train_data = file_to_word_ids(train_path, word_to_id)
    valid_data = file_to_word_ids(valid_path, word_to_id)
    test_data = file_to_word_ids(test_path, word_to_id)
    vocabulary = len(word_to_id)
    reversed_dictionary = dict(zip(word_to_id.values(), word_to_id.keys()))

    print(train_data[:5])
    print(word_to_id)
    print(vocabulary)
    print(&quot; &quot;.join([reversed_dictionary[x] for x in train_data[:10]]))
    return train_data, valid_data, test_data, vocabulary, reversed_dictionary</code></pre> <div class="code-embed-infos"> </div> </div>
<p>First, we simply setup the directory paths for the train, validation and test datasets respectively. Then, <em>build_vocab</em>() is invoked on the training data to create a dictionary that has each word as a key, and a unique integer as the associated value. Here is a sample of what the <em>word_to_id</em> dictionary looks like:</p>
<blockquote><p>{&#8216;write-off&#8217;: 7229, &#8216;ports&#8217;: 8314, &#8216;fundamentals&#8217;: 4478, &#8216;toronto-based&#8217;: 5034, &#8216;head&#8217;: 638, &#8216;fairness&#8217;: 6417,&#8230;</p></blockquote>
<p>Next, we convert the text data for each file into a list of integers using the <em>word_to_id</em> dictionary. The first 5 items of the list <em>train_data </em>looks like:</p>
<blockquote>[9970, 9971, 9972, 9974, 9975]</blockquote>
<p>I&#8217;ve also created a reverse dictionary which allows you to go the other direction &#8211; from a unique integer identifier to the corresponding word. This will be used later when we are reconstructing the outputs of our LSTM network back into plain English sentences.</p>
<p>The next step is to develop an input data pipeline that allows the extraction of batches of data in an efficient manner.</p>
<h2>Creating an input data pipeline</h2>
<p>As discussed in my <a href="http://adventuresinmachinelearning.com/introduction-tensorflow-queuing/" target="_blank" rel="noopener">TensorFlow queues and threads</a> tutorial, the use of a feed dictionary to supply data to your model during training, while common in tutorials, is not efficient &#8211; as can be read <a href="https://www.tensorflow.org/performance/performance_guide#input_pipeline_optimization" target="_blank" rel="noopener">here</a> on the TensorFlow site. Rather, it is more efficient to use TensorFlow queues and threading. Note, that there is a new way of doing things, using the Dataset API, which won&#8217;t be used in this tutorial, but I will perhaps update it in the future to include this new way of doing things. I&#8217;ve packaged up this code in a function called <em>batch_producer</em> &#8211; this function extracts batches of <em>x, y</em> training data &#8211; the <em>x </em>batch is formatted as the time stepped text data. The y batch is the same data, except delayed one time step. So, for instance, a single <em>x, y</em> sample in a batch, with the number of time steps being 8, looks like:</p>
<ul>
<li><em>x = </em>&#8220;A girl walked into a bar, and she&#8221;</li>
<li>y = &#8220;girl walked into a bar, and she said&#8221;</li>
</ul>
<p>Remember that <em>x </em>and <em>y</em> will be batches of integer data, with the size (<em>batch_size</em>, <em>num_steps</em>), not text as shown above &#8211; however, I have shown the above <em>x </em>and <em>y </em>sample in text form to aid understanding. So, as demonstrated in the model architecture diagram above, we are producing a many-to-many LSTM model, where the model will be trained to predict the very next word in the sequence <em>for each</em> word in the number of time steps.</p>
<p>Here&#8217;s what the code looks like:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">def batch_producer(raw_data, batch_size, num_steps):
    raw_data = tf.convert_to_tensor(raw_data, name=&quot;raw_data&quot;, dtype=tf.int32)

    data_len = tf.size(raw_data)
    batch_len = data_len // batch_size
    data = tf.reshape(raw_data[0: batch_size * batch_len],
                      [batch_size, batch_len])

    epoch_size = (batch_len - 1) // num_steps

    i = tf.train.range_input_producer(epoch_size, shuffle=False).dequeue()
    x = data[:, i * num_steps:(i + 1) * num_steps]
    x.set_shape([batch_size, num_steps])
    y = data[:, i * num_steps + 1: (i + 1) * num_steps + 1]
    y.set_shape([batch_size, num_steps])
    return x, y</code></pre> <div class="code-embed-infos"> </div> </div>
<p>In the code above, first, the raw text data is converted into an <em>int32</em> tensor. Next, the length of the full data set is calculated and stored in <em>data_len</em> and this is then divided by the batch size in an <em>integer division (//)</em> to get the number of full batches of data available within the dataset. The next line reshapes the <em>raw_data </em>tensor (restricted in size to the number of full batches of data i.e. 0 to <em>batch_size * batch_len</em>) into a (<em>batch_size, batch_len</em>) shape. The next line sets the number of iterations in each epoch &#8211; usually, this is set so that all the training data is passed through the algorithm in each epoch. This is what occurs here &#8211; the number of batches in the data (<em>batch_len</em>) is integer divided by the number of time steps &#8211; this gives the number of time-step-sized batches that are available to be iterated through in a single epoch.</p>
<p>The next line sets up an input range producer queue &#8211; this is a simple queue which allows the asynchronous and threaded extraction of data batches from a pre-existing dataset. For more on threads and queues, check out <a href="http://adventuresinmachinelearning.com/introduction-tensorflow-queuing/">my tutorial</a>. Basically, each time more data is required in the training of the model, a new integer is extracted between 0 and <em>epoch_size</em> &#8211; this is then used in the following lines to extract a batch of data asynchronously from the <em>data</em> tensor. With the <em>shuffle</em> argument set to False, this integer simply cycles from 0 to <em>epoch_size</em> and then resets back at 0 to repeat.</p>
<p>To produce the <em>x, y</em> batches of data, data slices are extracted from the data tensor based on the dequeued integer <em>i</em>. To see how this works, it is easier to imagine a dummy dataset of integers up to 20 &#8211; [0, 1, 2, 3, 4, 5, 6, &#8230;, 19, 20]. Let&#8217;s say we set the batch size to 3, and the number of steps to 2. The variables <em>batch_len </em>and <em>epoch_size </em>will therefore be equal to 6 and 2, respectively. The dummy reshaped data will look like:</p>
<p>$$\begin{bmatrix}<br />
1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 \\<br />
7 &amp; 8 &amp; 9 &amp; 10 &amp; 11 &amp; 12 \\<br />
13 &amp; 14 &amp; 15 &amp; 16 &amp; 17 &amp; 18 \\<br />
\end{bmatrix}$$</p>
<p>For the first data batch extraction, <em>i = 0</em>, therefore the extracted <em>x</em> for our dummy dataset will be <em>data[:, 0:2]</em>:</p>
<p>$$\begin{bmatrix}<br />
1 &amp; 2\\<br />
7 &amp; 8\\<br />
13 &amp; 14\\<br />
\end{bmatrix}$$</p>
<p>The extracted <em>y</em> will be <em>data[:, 1:3]</em>:</p>
<p>$$\begin{bmatrix}<br />
2 &amp; 3\\<br />
8 &amp; 9\\<br />
14 &amp; 15\\<br />
\end{bmatrix}$$</p>
<p>As can be observed, each row of the extracted <em>x </em>and <em>y </em>tensors will be an individual sample of length <em>num_steps</em> and the number of rows is the batch length. By organizing the data in this fashion, it is straight-forward to extract batch data while still maintaining the correct sentence sequence within each data sample.</p>
<h2>Creating the model</h2>
<p>In this code example, in order to have nice encapsulation and better-looking code, I&#8217;ll be building the model in <a href="https://docs.python.org/3/tutorial/classes.html" target="_blank" rel="noopener">Python classes</a>. The first class is a simple class that contains the input data:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">class Input(object):
    def __init__(self, batch_size, num_steps, data):
        self.batch_size = batch_size
        self.num_steps = num_steps
        self.epoch_size = ((len(data) // batch_size) - 1) // num_steps
        self.input_data, self.targets = batch_producer(data, batch_size, num_steps)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>We pass this object important input data information such as batch size, the number of recurrent time steps and finally the raw data file we wish to extract batch data from. The previously explained <em>batch_producer</em> function, when called, will return our input data batch <em>x</em> and the associated time step + 1 target data batch, <em>y</em>.</p>
<p>The next step is to create our LSTM model. Again, I&#8217;ve used a Python class to hold all the information and TensorFlow operations:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># create the main model
class Model(object):
    def __init__(self, input, is_training, hidden_size, vocab_size, num_layers,
                 dropout=0.5, init_scale=0.05):
        self.is_training = is_training
        self.input_obj = input
        self.batch_size = input.batch_size
        self.num_steps = input.num_steps</code></pre> <div class="code-embed-infos"> </div> </div>
<p>The first part of initialization is pretty self-explanatory, with the input data information and batch producer operation found in <em>input_obj</em>. Another important input is the boolean <em>is_training</em> &#8211; this allows the model instance to be created either as a model setup for training, or alternatively setup for validation or testing only.</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># create the word embeddings
with tf.device(&quot;/cpu:0&quot;):
    embedding = tf.Variable(tf.random_uniform([vocab_size, self.hidden_size], -init_scale, init_scale))
    inputs = tf.nn.embedding_lookup(embedding, self.input_obj.input_data)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>The block of code above creates the word embeddings. As previously discussed and shown in <a href="http://adventuresinmachinelearning.com/word2vec-tutorial-tensorflow/" target="_blank" rel="noopener">my tutorial</a>, word embedding creates meaningful vectors to represent each word. First, we initialize the embedding variable with size (vocab_size, hidden_size) which creates the &#8220;lookup table&#8221; where each row represents a word in the dataset, and the set of columns is the embedding vector. In this case, our embedding vector length is set equal to the size of our LSTM hidden layer.</p>
<p>The next line performs a lookup action on the embedding tensor, where each word in the input data set is matched with a row in the embedding tensor, with the matched embedding vector being returned within <em>inputs.</em></p>
<p>In this model, the embedding layer / vectors will be learned during the model training &#8211; however, if we so desired, we could also pre-learn embedding vectors using another model and upload these into our models. I&#8217;ve shown how to do this in <a href="http://adventuresinmachinelearning.com/gensim-word2vec-tutorial/" target="_blank" rel="noopener">my gensim tutorial</a> if you want to check it out.</p>
<p>The next step adds a <a href="https://en.wikipedia.org/wiki/Dropout_(neural_networks)" target="_blank" rel="noopener">drop-out</a> wrapper to the input data &#8211; this helps prevent overfitting by continually changing the structure of the network connections:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">if is_training and dropout &lt; 1:
    inputs = tf.nn.dropout(inputs, dropout)</code></pre> <div class="code-embed-infos"> </div> </div>
<h3>Creating the LSTM network</h3>
<p>The next step is to setup the initial state TensorFlow placeholder. This placeholder will be loaded with the initial state of the LSTM cells for each training batch. At the beginning of each training epoch, the input data will reset to the beginning of the text data set, so we want to reset the state variables to zero. However, during the multiple training batches executed in each epoch, we want to load the final state variables from the previous training batch into our LSTM cells for the current training batch. This keeps a certain continuity of state in our model, as we are progressing linearly through our text data set. We define the placeholder by:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># set up the state storage / extraction
self.init_state = tf.placeholder(tf.float32, [num_layers, 2, self.batch_size, self.hidden_size])</code></pre> <div class="code-embed-infos"> </div> </div>
<p>The second argument to the placeholder function is the size of the variable &#8211; (num_layers, 2, batch_size, hidden_size) and requires some explanation. If we consider an individual LSTM cell, for each training sample it processes it has two other inputs &#8211; the previous output from the cell ($h_{t-1}$) and the previous state variable ($s_{t-1}$). These two inputs, <em>h</em> and <em>s, </em>are what is required to load the full state data into an LSTM cell. Remember also that <em>h</em> and <em>s</em> for each sample are actually vectors with the size equal to the hidden layer size. Therefore, for all the samples in the batch, for a single LSTM cell we have state data required of shape (2, batch_size, hidden_size). Finally, if we have stacked LSTM cell layers, we need state variables for each layer &#8211; <em>num_layers. </em>This gives the final shape of the state variables: (num_layers, 2, batch_size, hidden_size).</p>
<p>The next two steps involve setting up this state data variable in the format required to feed it into the TensorFlow LSTM data structure:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">state_per_layer_list = tf.unstack(self.init_state, axis=0)
rnn_tuple_state = tuple(
            [tf.contrib.rnn.LSTMStateTuple(state_per_layer_list[idx][0], state_per_layer_list[idx][1])
             for idx in range(num_layers)]
        )</code></pre> <div class="code-embed-infos"> </div> </div>
<p>The TensorFlow LSTM cell can accept the state as a tuple if a flag is set to True (more on this later). The <em>tf.unstack</em> command creates a number of tensors, each of shape (2, batch_size, hidden_size), from the <em>init_state </em>tensor, one for each stacked LSTM layer <em>(num_layer)</em>. These tensors are then loaded into a specific TensorFlow data structure<em>, LSTMStateTuple</em>, which is the required for input into the LSTM cells.</p>
<p>Next, we create an LSTM cell which will be &#8220;unrolled&#8221; over the number of time steps. Following this, we apply a drop-out wrapper to again protect against overfitting. Notice that we set the forget bias values to be equal to 1.0, which helps guard against repeated low forget gate outputs causing vanishing gradients, as explained above:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># create an LSTM cell to be unrolled
cell = tf.contrib.rnn.LSTMCell(hidden_size, forget_bias=1.0)
# add a dropout wrapper if training
if is_training and dropout &lt; 1:
    cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=dropout)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>Next, if we include many layers of stacked LSTM cells in the model, we need to use another TensorFlow object called <em>MultiRNNCell </em>which performs the requisite cell stacking / layering:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">if num_layers &gt; 1:
    cell = tf.contrib.rnn.MultiRNNCell([cell for _ in range(num_layers)], state_is_tuple=True)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>Note that we tell <em>MultiRNNCell </em>to expect the state variables in the form of a <em>LSTMStateTuple</em> by setting the flag <em>state_is_tuple</em> to True.</p>
<p>The final step in creating the LSTM network structure is to create a dynamic RNN object in TensorFlow. This object will dynamically perform the unrolling of the LSTM cell over each time step.</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">output, self.state = tf.nn.dynamic_rnn(cell, inputs, dtype=tf.float32, initial_state=rnn_tuple_state)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>The <em>dynamic_rnn </em>object takes our defined LSTM cell as the first argument, and the embedding vector tensor <em>inputs</em> as the second argument. The final argument, <em>initial_state</em> is where we load our time-step zero state variables, that we created earlier, into the unrolled LSTM network.</p>
<p>This operation creates two outputs, the first is the output from all the unrolled LSTM cells, and will have a shape of (batch_size, num_steps, hidden_size). This data will be flattened in the next step to feed into a softmax classification layer. The second output, <em>state</em>, is the (s, h) state tuple taken from the final time step of the LSTM cells. This <em>state</em> operation / tuple will be extracted during each batch training operation to be used as inputs (via <em>init_state</em>) into the next training batch.</p>
<h3>Creating the softmax, loss and optimizer operations</h3>
<p>Next we have to flatten the outputs so that we can feed them into our proposed softmax classification layer. We can use the -1 notation to reshape our output tensor, with the second axis set to be equal to the hidden layer size:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># reshape to (batch_size * num_steps, hidden_size)
output = tf.reshape(output, [-1, hidden_size])</code></pre> <div class="code-embed-infos"> </div> </div>
<p>Next we setup our softmax weight variables and the standard $xw+b$ operation:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">softmax_w = tf.Variable(tf.random_uniform([hidden_size, vocab_size], -init_scale, init_scale))
softmax_b = tf.Variable(tf.random_uniform([vocab_size], -init_scale, init_scale))
logits = tf.nn.xw_plus_b(output, softmax_w, softmax_b)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>Note that the <em>logits</em> operation is simply the output of our tensor multiplication &#8211; we haven&#8217;t yet added the softmax operation &#8211; this will occur in the loss calculations below (and also in our ancillary accuracy calculations).</p>
<p>Following this, we have to setup our loss or cost function which will be used to train our LSTM network. In this case, we will use the specialized <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/sequence_loss" target="_blank" rel="noopener">TensorFlow sequence to sequence loss function</a>. This loss function allows one to calculate (a potentially) weighted cross entropy loss over a sequence of values. The first argument to this loss function is the <em>logits</em> argument, which requires tensors with the shape (batch_size, num_steps, vocab_size) &#8211; so we&#8217;ll need to reshape our logits tensor. The second argument to the loss function is the <em>targets </em>tensor which has a shape (batch_size, num_steps) with each value being an integer (which corresponds to a unique word in our case) &#8211; in other words, this tensor contains the true values of the word sequence that we want our LSTM network to predict. The third important argument is the weights tensor, of shape (batch_size, num_steps), which allows you to weight different samples or time steps with respect to the loss i.e. you might want the loss to favor the latter time steps rather than the earlier ones. No weighting is applied in this model, so a tensor of ones is passed to this argument.</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># Reshape logits to be a 3-D tensor for sequence loss
logits = tf.reshape(logits, [self.batch_size, self.num_steps, vocab_size])

# Use the contrib sequence loss and average over the batches
loss = tf.contrib.seq2seq.sequence_loss(
            logits,
            self.input_obj.targets,
            tf.ones([self.batch_size, self.num_steps], dtype=tf.float32),
            average_across_timesteps=False,
            average_across_batch=True)
# Update the cost
self.cost = tf.reduce_sum(loss)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>There are two more important arguments for this function &#8211; <em>average_across_timesteps </em>and <em>average_across_batch</em>. If <em>average_across_timesteps </em>is set to True, the cost will be summed across the time dimension, if <em>average_across_batch</em> is True, then the cost will be summed across the batch dimension. In this case we are favoring the latter option.</p>
<p>Finally, we produce the <em>cost</em> operation which reduces the loss to a single scalar value &#8211; we could also do something similar by setting <em>average_across_timesteps</em><em> </em>to True &#8211; however, I am keeping things consistent with the TensorFlow tutorial.</p>
<p>In the next few steps, we set up some operations to calculate the accuracy off predictions over the batch samples:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># get the prediction accuracy
self.softmax_out = tf.nn.softmax(tf.reshape(logits, [-1, vocab_size]))
self.predict = tf.cast(tf.argmax(self.softmax_out, axis=1), tf.int32)
correct_prediction = tf.equal(self.predict, tf.reshape(self.input_obj.targets, [-1]))
self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</code></pre> <div class="code-embed-infos"> </div> </div>
<p>First we apply a softmax operation to get the predicted probabilities of each word for each output of the LSTM network. We then make the network predictions equal to those words with the highest softmax probability by using the <em>argmax</em> function. These predictions are then compared to the actual target words and then averaged to get the accuracy.</p>
<p>Now we move onto constructing the optimization operations &#8211; in this case we aren&#8217;t using a simple &#8220;out of the box&#8221; optimizer &#8211; rather we are doing a few manipulations to improve results:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">if not is_training:
   return
self.learning_rate = tf.Variable(0.0, trainable=False)

tvars = tf.trainable_variables()
grads, _ = tf.clip_by_global_norm(tf.gradients(self.cost, tvars), 5)
optimizer = tf.train.GradientDescentOptimizer(self.learning_rate)
self.train_op = optimizer.apply_gradients(
            zip(grads, tvars),
            global_step=tf.contrib.framework.get_or_create_global_step())</code></pre> <div class="code-embed-infos"> </div> </div>
<p>First off, if the model has been created for predictions, validations or testing only, these operations do not need to be created. The first step if the model is being used for training, is to create a learning rate variable. This will be used so that we can decrease the learning rate during training &#8211; this improves the final outcome of the model.</p>
<p>Next we wish to clip the size of the gradients in our network during back-propagation &#8211; this is recommended in recurrent neural networks to improve outcomes. Clipping values of between 1 and 5 are commonly used. Finally, we create the optimizer operation, using the <em>learning_rate </em>variable, and apply the clipped gradients.. Then a gradient descent step is performed &#8211; assigning this operation to <em>train_op</em>. This operation, <em>train_op</em>, will be called for each training batch.</p>
<p>The final two lines of the model creation involve the updating of the <em>learning_rate</em>:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">self.new_lr = tf.placeholder(tf.float32, shape=[])
self.lr_update = tf.assign(self.learning_rate, self.new_lr)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>First, a placeholder is created which will be input via the <em>feed_dict</em> argument when running the training, <em>new_lr</em>. This new learning rate is then assigned to <em>learning_rate</em> via a <em>tf.assign</em> operation. This operation, <em>lr_update,</em> will be run at the beginning of each epoch.</p>
<p>Now that the model structure is fully created, we can move onto the training loops:</p>
<h2>Training the LSTM model</h2>
<p>The training function will take as input the training data, along with various model parameters (batch sizes, number of steps etc.). The first part of the function looks like:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">def train(train_data, vocabulary, num_layers, num_epochs, batch_size, model_save_name,
          learning_rate=1.0, max_lr_epoch=10, lr_decay=0.93):
    # setup data and models
    training_input = Input(batch_size=batch_size, num_steps=35, data=train_data)
    m = Model(training_input, is_training=True, hidden_size=650, vocab_size=vocabulary,
              num_layers=num_layers)
    init_op = tf.global_variables_initializer()</code></pre> <div class="code-embed-infos"> </div> </div>
<p>First we create an Input object instance and a Model object instance, passing in the necessary parameters. Because the TensorFlow graph is being created during the initialization of these objects, the TensorFlow global variable initializer operation can only be properly run <em>after</em> the creation of these instances.</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">orig_decay = lr_decay
with tf.Session() as sess:
    # start threads
    sess.run([init_op])
    coord = tf.train.Coordinator()
    threads = tf.train.start_queue_runners(coord=coord)
    saver = tf.train.Saver()</code></pre> <div class="code-embed-infos"> </div> </div>
<p>Next we start the session, and run the variable initializer operation. Because we are using queuing in the Input object, we also need to create a thread coordinator and start the running of the threads (for more information, see <a href="http://adventuresinmachinelearning.com/introduction-tensorflow-queuing/" target="_blank" rel="noopener">this tutorial</a>). If you skip this step, or put it before the creation of <em>training_input</em>, your program will hang. Finally, a saver instance is created as we want to store model training checkpoints and the final trained model.</p>
<p>Next, the epochal training loop is entered into:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">for epoch in range(num_epochs):
    new_lr_decay = orig_decay ** max(epoch + 1 - max_lr_epoch, 0.0)
    m.assign_lr(sess, learning_rate * new_lr_decay)
    current_state = np.zeros((num_layers, 2, batch_size, m.hidden_size))
    for step in range(training_input.epoch_size):
        if step % 50 != 0:
            cost, _, current_state = sess.run([m.cost, m.train_op, m.state],
                                                             feed_dict={m.init_state: current_state})
        else:
            cost, _, current_state, acc = sess.run([m.cost, m.train_op, m.state, m.accuracy],
                                                      feed_dict={m.init_state: current_state})
            print(&quot;Epoch {}, Step {}, cost: {:.3f}, accuracy: {:.3f}&quot;.format(epoch, step, cost, acc))
    # save a model checkpoint
    saver.save(sess, data_path + &#039;\\&#039; + model_save_name, global_step=epoch)
# do a final save
saver.save(sess, data_path + &#039;\\&#039; + model_save_name + &#039;-final&#039;)
# close threads
coord.request_stop()
coord.join(threads)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>The first step in every epoch is to calculate the learning rate decay factor, which gradually decreases after <em>max_lr_epoch</em> number of epochs has been reached. This learning rate decay factor, <em>new_lr_decay</em>, is multiplied by the learning rate and assigned to the model by calling the Model method <em>assign_lr</em>. This method looks like:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">def assign_lr(self, session, lr_value):
    session.run(self.lr_update, feed_dict={self.new_lr: lr_value})</code></pre> <div class="code-embed-infos"> </div> </div>
<p>As can be observed, this function simply runs the <em>lr_update </em>operation which was explained in the prior section.</p>
<p>The next step is to create a zeroed initial state tensor for our LSTM model &#8211; we assign this zeroed tensor to the variable <em>current_state</em>. Then each training operation is looped through within our specified epoch size. Every iteration we run the following operations: <em>m.train_op</em> and <em>m.state</em>. The <em>train_op </em>operation, as previously shown, calculates the clipped gradients of the model and takes a batched step to minimize the cost. The <em>state </em>operation returns the <em>state </em>of the final unrolled LSTM cell which we will require to input as the state for the next training batch &#8211; note that it replaces the contents of the <em>current_state</em> variable. This <em>current_state </em>variable is inserted into the <em>m.init_state </em>placeholder via the <em>feed_dict.</em></p>
<p>Every 50 iterations we also extract the current cost of the model in training, as well as the accuracy against the current training batch, to provide printed feedback during training. The outputs look like this:</p>
<blockquote><p>Epoch 9, Step 1850, cost: 96.185, accuracy: 0.198<br />
Epoch 9, Step 1900, cost: 94.755, accuracy: 0.235</p></blockquote>
<p>Finally, at the end of each epoch, we use the <em>saver </em>object to save a model checkpoint, and finally at the end of the training a final save of the state of the model is performed.</p>
<h3>Expected training outcomes</h3>
<p>The expected cost and accuracy progress through the epochs depends on the multitude of parameters supplied to the models and also the results of the random initialization of the variables. Training time is also dependent on whether you are using only CPUs, or whether you are using GPUs too (note, I have not tested the code on the Github repository with GPUs).</p>
<p>My model achieved an average cost and <em>training batch</em> accuracy on the order of 110-120 and 30%, respectively, after 38 epochs with the following paramters:</p>
<p>Hidden size:650, Number of steps:35, Initialization scale:0.05, Batch size:20, Number of stacked LSTM layers:2, Keep probability / dropout: 0.5</p>
<p>You are probably thinking the accuracy isn&#8217;t very high, and you are correct, however further training and a larger hidden layer would provide better final accuracy values. To perform further training on a larger network you really need to be using GPUs to accelerate the training &#8211; I&#8217;ll do this in a future post and present the results.</p>
<h2>Testing the model</h2>
<p>To test the model on the test or validation data, I&#8217;ve created another function called <em>test</em> which looks like so:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">def test(model_path, test_data, reversed_dictionary):
    test_input = Input(batch_size=20, num_steps=35, data=test_data)
    m = Model(test_input, is_training=False, hidden_size=650, vocab_size=vocabulary,
              num_layers=2)
    saver = tf.train.Saver()
    with tf.Session() as sess:
        # start threads
        coord = tf.train.Coordinator()
        threads = tf.train.start_queue_runners(coord=coord)
        current_state = np.zeros((2, 2, m.batch_size, m.hidden_size))
        # restore the trained model
        saver.restore(sess, model_path)
        # get an average accuracy over num_acc_batches
        num_acc_batches = 30
        check_batch_idx = 25
        acc_check_thresh = 5
        accuracy = 0
        for batch in range(num_acc_batches):
            if batch == check_batch_idx:
                true_vals, pred, current_state, acc = sess.run([m.input_obj.targets, m.predict, m.state, m.accuracy],
                                                               feed_dict={m.init_state: current_state})
                pred_string = [reversed_dictionary[x] for x in pred[:m.num_steps]]
                true_vals_string = [reversed_dictionary[x] for x in true_vals[0]]
                print(&quot;True values (1st line) vs predicted values (2nd line):&quot;)
                print(&quot; &quot;.join(true_vals_string))
                print(&quot; &quot;.join(pred_string))
            else:
                acc, current_state = sess.run([m.accuracy, m.state], feed_dict={m.init_state: current_state})
            if batch &gt;= acc_check_thresh:
                accuracy += acc
        print(&quot;Average accuracy: {:.3f}&quot;.format(accuracy / (num_acc_batches-acc_check_thresh)))
        # close threads
        coord.request_stop()
        coord.join(threads)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>We start with creating an Input and Model class that matches our training Input and Model classes. It is important that key parameters match the training model, such as the hidden size, number of steps, batch size etc. We are going to load our saved model variables into the computational graph created by the test Model instance, and if the dimensions don&#8217;t match TensorFlow will throw an error.</p>
<p>Next we create a <em>tf.train.Saver() </em>operation &#8211; this will load all our saved model variables into our test model when we run the line <em>saver.restore(sess, model_path). </em>After dealing with all of the threads and creating a zeroed state variable, we setup some variables which relate to how we are going to assess the accuracy and look at some specific instances of predicted strings. Because we have to &#8220;warm up&#8221; the model by feeding it some data to get good state variables, we only measure the accuracy after a certain number of batches i.e. <em>acc_check_thresh.</em></p>
<p>When the batch number is equal to <em>check_batch_idx</em> the code runs the <em>m.predict</em> operation to extract the predictions for the particular batch of data. The first prediction of the batch is passed through the reverse dictionary to convert them back to actual words (along with the batch target words) and then compared with what should have been predicted via printing.</p>
<p>Using the trained model, we can see the following output:</p>
<p>True values (1st line) vs <em>predicted values</em> (2nd line):<br />
stock market is headed many traders were afraid to trust stock prices quoted on the big board &lt;eos&gt; the futures halt was even &lt;unk&gt; by big board floor traders &lt;eos&gt; it &lt;unk&gt; things up said<br />
<em>market market is n&#8217;t for traders say willing to buy the prices &lt;eos&gt; &lt;eos&gt; the big board &lt;eos&gt; the dow market is a worse &lt;eos&gt; the board traders traders &lt;eos&gt; the &#8216;s the to to</em><br />
Average accuracy: 0.283</p>
<p>The accuracy isn&#8217;t fantastic, but you can see the network is matching the &#8220;gist&#8221; of the sentence i.e. not producing all of the exact words but matching the general subject matter. As I mentioned above, in a future post I&#8217;ll present the data from a model trained for longer using GPUs.</p>
<p>I hope you enjoyed the post &#8211; it&#8217;s been a long one, but I hope that this gives you a solid foundation in understanding recurrent neural networks and LSTMs and how to implement them in TensorFlow. If you&#8217;d like to learn how to build LSTM networks in Keras, see <a href="http://adventuresinmachinelearning.com/keras-lstm-tutorial/" target="_blank" rel="noopener">this tutorial</a>.</p>
<hr />
<p><strong>Recommended online course: </strong>If you are more of a video course learner, I&#8217;d recommend this inexpensive Udemy course: <a href="https://click.linksynergy.com/link?id=Jbc0N5ZkDzk&amp;offerid=323058.887814&amp;type=2&amp;murl=https%3A%2F%2Fwww.udemy.com%2Fdeep-learning-recurrent-neural-networks-in-python%2F">Deep Learning: Recurrent Neural Networks in Python</a><img src="https://ad.linksynergy.com/fs-bin/show?id=Jbc0N5ZkDzk&amp;bids=323058.887814&amp;type=2&amp;subid=0" width="1" height="1" border="0" /></p>
<hr />
<p>&nbsp;</p>
<p>The post <a rel="nofollow" href="http://adventuresinmachinelearning.com/recurrent-neural-networks-lstm-tutorial-tensorflow/">Recurrent neural networks and LSTM tutorial in Python and TensorFlow</a> appeared first on <a rel="nofollow" href="http://adventuresinmachinelearning.com">Adventures in Machine Learning</a>.</p>
]]></content:encoded>
			<wfw:commentRss>http://adventuresinmachinelearning.com/recurrent-neural-networks-lstm-tutorial-tensorflow/feed/</wfw:commentRss>
		<slash:comments>9</slash:comments>
		</item>
		<item>
		<title>Python gensim Word2Vec tutorial with TensorFlow and Keras</title>
		<link>http://adventuresinmachinelearning.com/gensim-word2vec-tutorial/</link>
		<comments>http://adventuresinmachinelearning.com/gensim-word2vec-tutorial/#comments</comments>
		<pubDate>Fri, 01 Sep 2017 22:24:41 +0000</pubDate>
		<dc:creator><![CDATA[Andy]]></dc:creator>
				<category><![CDATA[gensim]]></category>
		<category><![CDATA[Keras]]></category>
		<category><![CDATA[NLP]]></category>
		<category><![CDATA[TensorFlow]]></category>
		<category><![CDATA[Word2Vec]]></category>

		<guid isPermaLink="false">http://adventuresinmachinelearning.com/?p=517</guid>
		<description><![CDATA[<p>I&#8217;ve been dedicating quite a bit of time recently to Word2Vec tutorials because of the importance of the Word2Vec concept for natural language processing (NLP) <a class="mh-excerpt-more" href="http://adventuresinmachinelearning.com/gensim-word2vec-tutorial/" title="Python gensim Word2Vec tutorial with TensorFlow and Keras">[...]</a></p>
<p>The post <a rel="nofollow" href="http://adventuresinmachinelearning.com/gensim-word2vec-tutorial/">Python gensim Word2Vec tutorial with TensorFlow and Keras</a> appeared first on <a rel="nofollow" href="http://adventuresinmachinelearning.com">Adventures in Machine Learning</a>.</p>
]]></description>
				<content:encoded><![CDATA[<p>I&#8217;ve been dedicating quite a bit of time recently to Word2Vec tutorials because of the importance of the Word2Vec concept for natural language processing (NLP) and also because I&#8217;ll soon be presenting some tutorials on recurrent neural networks and LSTMs for sequence prediction/NLP (UPDATE: I&#8217;ve completed a comprehensive tutorial on these topics &#8211; <a href="http://adventuresinmachinelearning.com/recurrent-neural-networks-lstm-tutorial-tensorflow/" target="_blank" rel="noopener">Recurrent neural networks and LSTM tutorial in Python and TensorFlow</a>).  There are also some very interesting ideas floating around such as <a href="https://deeplearning4j.org/thoughtvectors" target="_blank" rel="noopener">thought vectors</a> which require an understanding of the Word2Vec concept.  My two Word2Vec tutorials are <a href="http://adventuresinmachinelearning.com/word2vec-tutorial-tensorflow/" target="_blank" rel="noopener">Word2Vec word embedding tutorial in Python and TensorFlow</a> and <a href="http://adventuresinmachinelearning.com/word2vec-keras-tutorial/" target="_blank" rel="noopener">A Word2Vec Keras tutorial</a> showing the concepts of Word2Vec and implementing in TensorFlow and Keras, respectively.  In this tutorial, I am going to show you how you can use the original Google Word2Vec C code to generate word vectors, using the Python gensim library which wraps this cod,e and apply the results to TensorFlow and Keras.</p>
<p>The gensim Word2Vec implementation is very fast due to its C implementation &#8211; but to use it properly you will first need to install the <a href="http://cython.org/" target="_blank" rel="noopener">Cython library</a>. In this tutorial, I&#8217;ll show how to load the resulting embedding layer generated by gensim into TensorFlow and Keras embedding implementations.  Because of gensim&#8217;s blazing fast C wrapped code, this is a good alternative to running native Word2Vec embeddings in TensorFlow and Keras.</p>
<hr />
<p><strong>Recommended online course: </strong>If you are more of a video course learner, check out this inexpensive Udemy course: <a href="https://click.linksynergy.com/link?id=Jbc0N5ZkDzk&amp;offerid=323058.918390&amp;type=2&amp;murl=https%3A%2F%2Fwww.udemy.com%2Fnatural-language-processing-with-deep-learning-in-python%2F" target="new">Natural Language Processing with Deep Learning in Python</a><img src="https://ad.linksynergy.com/fs-bin/show?id=Jbc0N5ZkDzk&amp;bids=323058.918390&amp;type=2&amp;subid=0" width="1" height="1" border="0" /></p>
<hr />
<h1>Word2Vec and gensim</h1>
<p>I&#8217;ve devoted plenty of words to explaining Word2Vec in my previous tutorials (<a href="http://adventuresinmachinelearning.com/word2vec-tutorial-tensorflow/" target="_blank" rel="noopener">here</a> and <a href="http://adventuresinmachinelearning.com/word2vec-keras-tutorial/" target="_blank" rel="noopener">here</a>) so I&#8217;ll only briefly introduce the Word2Vec concepts here.  For further details, check out those tutorials. Here&#8217;s the (relatively) quick version &#8211; for each text data set that we create, we have to create a <em>vocabulary</em>. The <em>vocabulary</em> is the list of unique words within the text.  Often it is &gt;10,000 words for serious data sets.  Machine learning models generally can&#8217;t take raw word inputs, so we first need to convert our data set into some number format &#8211; generally a list of unique integers.</p>
<p>Neural network based models like vector inputs. We, therefore, need to convert the integers into vectors.  A naive way of converting integers into vectors is to convert them into one-hot vectors &#8211; these are vectors where all of the values are set to zero, except for one i.e. [0, 0, 0, &#8230;, 1, &#8230;, 0, 0].  The &#8220;one-hot&#8221; value is located at the array index which matches the unique integer representation of the word. Therefore, our input one-hot vector must be at least the size of the vocabulary in length &#8211; i.e. &gt;10,000 words.</p>
<p>There are two main problems with this type of representation of words &#8211; the first is that it is inefficient. Each word is represented by a 10,000 word plus vector, which for neural networks means a heck of a lot of associated weights between the input layer and the first hidden layer (generally millions).  The second is that it loses all contextual meaning of the words.  We need a way of representing words that is both efficient and yet retains some of the original meaning of the word and its relation to other words. Enter word embedding and Word2Vec.</p>
<h2>Word embedding and Word2Vec</h2>
<p>Word embedding involves creating better vector representations of words &#8211; both in terms of efficiency and maintaining meaning. For instance, a word embedding layer may involve creating a 10,000 x 300 sized matrix, whereby we look up a 300 length vector representation for each of the 10,000 words in our vocabulary.  This new, 300 length vector is obviously a lot more efficient than a 10,000 length one-hot representation.  But we also need to create this 300 length vector in such a way as to preserve some semblance of the meaning of the word.</p>
<p>Word2Vec does this by taking the <em>context </em>of words surrounding the <em>target </em>word.  So, if we have a context window of 2, the context of the <em>target</em> word &#8220;sat&#8221; in the sentence &#8220;the cat sat on the mat&#8221; is the list of words [&#8220;the&#8221;, &#8220;cat&#8221;, &#8220;on&#8221;, &#8220;the&#8221;]. In Word2Vec, the meaning of a word is roughly translatable to context &#8211; and it basically works. Target words which share similar common context words often have similar meanings. The way Word2Vec trains the embedding vectors is via a neural network of sorts &#8211; the neural network, given a one-hot representation of a <em>target</em> word, tries to predict the most likely context words.  For an introduction to neural networks, see <a href="http://adventuresinmachinelearning.com/neural-networks-tutorial/" target="_blank" rel="noopener">this tutorial</a>.</p>
<p>Here&#8217;s a naive way of performing the neural network training using an output softmax layer:</p>
<figure id="attachment_395" style="width: 676px" class="wp-caption alignnone"><img class="size-full wp-image-395" src="http://adventuresinmachinelearning.com/wp-content/uploads/2017/07/Word2Vec-softmax.jpg" alt="gensim word embedding softmax trainer" width="676" height="425" srcset="http://adventuresinmachinelearning.com/wp-content/uploads/2017/07/Word2Vec-softmax.jpg 676w, http://adventuresinmachinelearning.com/wp-content/uploads/2017/07/Word2Vec-softmax-300x189.jpg 300w" sizes="(max-width: 676px) 100vw, 676px" /><figcaption class="wp-caption-text">A word embedding softmax trainer</figcaption></figure>
<p>In this network, the 300 node hidden layer weights are training by trying to predict (via a softmax output layer) genuine, high probability context words.  Once the training is complete, the output softmax layer is discarded and what is of real value is the 10,000 x 300 weight matrix connecting the input to the hidden layer. This is our embedding matrix, and we can look up any member of our 10,000-word vocabulary and get it&#8217;s 300 length vector representation.</p>
<p>It turns out that this softmax way of training the embedding layer is very inefficient, due to the millions of weights that need to be involved in updating and calculating the softmax values. Therefore, a concept called <em>negative sampling </em>is used in the real Word2Vec, which involves training the layer with real context words and a few <em>negative samples</em> which are chosen randomly from outside the context.  For more details on this, see my <a href="http://adventuresinmachinelearning.com/word2vec-keras-tutorial/" target="_blank" rel="noopener">Word2Vec Keras tutorial</a>.</p>
<p>Now we understand what Word2Vec training of embedding layers involves, let&#8217;s talk about the gensim Word2Vec module.</p>
<h2>A gensim Word2Vec tutorial</h2>
<figure id="attachment_532" style="width: 1139px" class="wp-caption alignnone"><img class="size-full wp-image-532" src="http://adventuresinmachinelearning.com/wp-content/uploads/2017/09/Closest-words-output.jpg" alt="gensim Word2Vec - nearest words" width="1139" height="327" srcset="http://adventuresinmachinelearning.com/wp-content/uploads/2017/09/Closest-words-output.jpg 1139w, http://adventuresinmachinelearning.com/wp-content/uploads/2017/09/Closest-words-output-300x86.jpg 300w, http://adventuresinmachinelearning.com/wp-content/uploads/2017/09/Closest-words-output-768x220.jpg 768w, http://adventuresinmachinelearning.com/wp-content/uploads/2017/09/Closest-words-output-1024x294.jpg 1024w" sizes="(max-width: 1139px) 100vw, 1139px" /><figcaption class="wp-caption-text">Nearest words by cosine similarity</figcaption></figure>
<p>This section will give a brief introduction to the gensim Word2Vec module.  The gensim library is an open-source Python library that specializes in vector space and topic modeling.  It can be made very fast with the use of the Cython Python model, which allows C code to be run inside the Python environment. This is good for our purposes, as the <a href="https://code.google.com/archive/p/word2vec/" target="_blank" rel="noopener">original Google Word2Vec implementation</a> is written in C, and gensim has a wrapper for this code, which will be explained below.</p>
<p>For this tutorial, we are going to use the <em>text8</em> corpus sourced from <a href="http://mattmahoney.net/dc/" target="_blank" rel="noopener">here</a> for our text data. All the code for this tutorial can be found on this site&#8217;s <a href="https://github.com/adventuresinML/adventures-in-ml-code" target="_blank" rel="noopener">Github repository</a>.</p>
<p>First off, we need to download the <em>text8.zip</em> file (if required) and extract it:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">url = &#039;http://mattmahoney.net/dc/&#039;
filename = maybe_download(&#039;text8.zip&#039;, url, 31344016)
root_path = &quot;C:\\Users\Andy\PycharmProjects\\adventures-in-ml-code\\&quot;
if not os.path.exists((root_path + filename).strip(&#039;.zip&#039;)):
    zipfile.ZipFile(root_path+filename).extractall()</code></pre> <div class="code-embed-infos"> </div> </div>
<p>This is all fairly straightforward Python file handling, downloading and zip file manipulation, so I won&#8217;t go into it here.</p>
<p>The next step that is required is to create an iterator for gensim to extract its data from.  We can cheat a little bit here and use a supplied iterator that gensim provides for the <em>text8</em> corpus:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">sentences = word2vec.Text8Corpus((root_path + filename).strip(&#039;.zip&#039;))</code></pre> <div class="code-embed-infos"> </div> </div>
<p>The required input to the gensim Word2Vec module is an <a href="http://pymbook.readthedocs.io/en/latest/igd.html" target="_blank" rel="noopener">iterator object</a>, which sequentially supplies sentences from which gensim will train the embedding layer. The line above shows the supplied gensim iterator for the <em>text8</em> corpus, but below shows another generic form that could be used in its place for a different data set (not actually implemented in the code for this tutorial), where the data set also contains multiple files:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">class MySentences(object):
    def __init__(self, dirname):
        self.dirname = dirname
 
    def __iter__(self):
        for fname in os.listdir(self.dirname):
            for line in open(os.path.join(self.dirname, fname)):
                yield line.split()</code></pre> <div class="code-embed-infos"> </div> </div>
<p>This capability of gensim is great, as it means you can setup iterators which cycle through the data without having to load the entire data set into memory.  This is vital, as some text data sets are huge  i.e. tens of GB.</p>
<p>After we&#8217;ve setup the iterator object, it is dead simple to train our word vectors:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">logging.basicConfig(format=&#039;%(asctime)s : %(levelname)s : %(message)s&#039;, level=logging.INFO)
model = word2vec.Word2Vec(sentences, iter=10, min_count=10, size=300, workers=4)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>The first line just lets us see the INFO logging that gensim provides as it trains. The second line will execute the training on the provided <em>sentences</em> iterator.  The first optional argument <em>iter</em> specifies how many times the training code will run through the data set to train the neural network (kind of like the number of training epochs). The gensim training code will actually run through all the data <em>iter+1</em> time, as the first pass involves collecting all the unique words, creating dictionaries etc.  The next argument,<em> min_count,</em> specifies the minimum amount of times that the word has to appear in the corpus before it is included in the vocabulary &#8211; this allows us to easily eliminate rare words and reduce our vocabulary size.  The third argument is the size of the resultant word vector &#8211; in this case, we set it to 300. In other words, each word in our vocabulary, after training, will be represented by a 300 length word vector. Finally, if we are using Cython, we can specify how many parallel workers we would like to work on the data &#8211; this will speed up the training process. There are <a href="https://radimrehurek.com/gensim/models/word2vec.html" target="_blank" rel="noopener">lots of other arguments</a>, but these are the main ones to consider.</p>
<p>Let&#8217;s examine our results and see what else gensim can do.</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># get the word vector of &quot;the&quot;
print(model.wv[&#039;the&#039;])</code></pre> <div class="code-embed-infos"> </div> </div>
<p>This returns a 300 length numpy vector &#8211; as you can see, each word vector can be retrieved from the model via a dictionary key i.e. a word within our vocabulary.</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># get the most common words
print(model.wv.index2word[0], model.wv.index2word[1], model.wv.index2word[2])</code></pre> <div class="code-embed-infos"> </div> </div>
<p>The word vectors are also arranged within the <em>wv</em> object with indexes &#8211; the lowest index (i.e. 0) represents the most common word, the highest (i.e. the length of the vocabulary minus 1) the least common word.  The above code returns: &#8220;the of and&#8221;, which is unsurprising, as these are very common words.</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># get the least common words
vocab_size = len(model.wv.vocab)
print(model.wv.index2word[vocab_size - 1], model.wv.index2word[vocab_size - 2], model.wv.index2word[vocab_size - 3])</code></pre> <div class="code-embed-infos"> </div> </div>
<p>The discovered vocabulary is found in <em>model.wv.vocab</em> &#8211; by taking the length of this dictionary, we can determine the vocabulary size (in this case, it is 47,134 elements long). The code above returns: &#8220;zanetti markschies absentia&#8221; &#8211; rare words indeed.</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># find the index of the 2nd most common word (&quot;of&quot;)
print(&#039;Index of &quot;of&quot; is: {}&#039;.format(model.wv.vocab[&#039;of&#039;].index))</code></pre> <div class="code-embed-infos"> </div> </div>
<p>We can also go the other way i.e. retrieve the index of a word we supply.  In this case, we are getting the index of the second most common word &#8220;of&#8221;. As expected the above code returns &#8220;Index of &#8220;of&#8221; is: 1&#8243;.</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># some similarity fun
print(model.wv.similarity(&#039;woman&#039;, &#039;man&#039;), model.wv.similarity(&#039;man&#039;, &#039;elephant&#039;))</code></pre> <div class="code-embed-infos"> </div> </div>
<p>We can also easily extract similarity measures between word vectors (gensim uses <a href="https://en.wikipedia.org/wiki/Cosine_similarity" target="_blank" rel="noopener">cosine similarity</a>). The above code returns &#8220;0.6599 0.2955&#8221;, which again makes sense given the context such words are generally used in.</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># what doesn&#039;t fit?
print(model.wv.doesnt_match(&quot;green blue red zebra&quot;.split()))</code></pre> <div class="code-embed-infos"> </div> </div>
<p>This fun function determines which word doesn&#8217;t match the context of the others &#8211; in this case, &#8220;zebra&#8221; is returned.</p>
<p>We also want to able to convert our data set from a list of words to a list of integer indexes, based on the vocabulary developed by gensim.  To do so, we can use the following code:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># convert the input data into a list of integer indexes aligning with the wv indexes
# Read the data into a list of strings.
def read_data(filename):
    &quot;&quot;&quot;Extract the first file enclosed in a zip file as a list of words.&quot;&quot;&quot;
    with zipfile.ZipFile(filename) as f:
        data = f.read(f.namelist()[0]).split()
    return data

def convert_data_to_index(string_data, wv):
    index_data = []
    for word in string_data:
        if word in wv:
            index_data.append(wv.vocab[word].index)
    return index_data

str_data = read_data(root_path + filename)
index_data = convert_data_to_index(str_data, model.wv)
print(str_data[:4], index_data[:4])</code></pre> <div class="code-embed-infos"> </div> </div>
<p>The first function, <em>read_data</em> simply extracts the zip file data and returns a list of strings in the same order as our original text data set.  The second function loops through each word in the data set, determines if it is in the vocabulary*, and if so, adds the matching integer index to a list.  The code above returns: &#8220;[&#8216;anarchism&#8217;, &#8216;originated&#8217;, &#8216;as&#8217;, &#8216;a&#8217;] [5237, 3080, 11, 5]&#8221;.</p>
<p>* Remember that some words in the data set will be missing from the vocabulary if they are very rare in the corpus.</p>
<p>We can also save and reload our trained word vectors/embeddings by the following simple code:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># save and reload the model
model.save(root_path + &quot;mymodel&quot;)
model = gensim.models.Word2Vec.load(root_path + &quot;mymodel&quot;)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>Finally, I&#8217;ll show you how we can extract the embedding weights from the gensim Word2Vec embedding layer and store it in a numpy array, ready for use in TensorFlow and Keras.</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># convert the wv word vectors into a numpy matrix that is suitable for insertion
# into our TensorFlow and Keras models
embedding_matrix = np.zeros((len(model.wv.vocab), vector_dim))
for i in range(len(model.wv.vocab)):
    embedding_vector = model.wv[model.wv.index2word[i]]
    if embedding_vector is not None:
        embedding_matrix[i] = embedding_vector</code></pre> <div class="code-embed-infos"> </div> </div>
<p>In this case, we first create an appropriately sized numpy zeros array.  Then we loop through each word in the vocabulary, grabbing the word vector associated with that word by using the <em>wv</em> dictionary.  We then add the word vector into our numpy array.</p>
<p>So there we have it &#8211; gensim Word2Vec is a great little library that can execute the word embedding process very quickly, and also has a host of other useful functionality.</p>
<p>Now I will show how you can use pre-trained gensim embedding layers in our TensorFlow and Keras models.</p>
<h1>Using gensim Word2Vec embeddings in TensorFlow</h1>
<p>For this application, we&#8217;ll setup a dummy TensorFlow network with an embedding layer and measure the similarity between some words.  If you&#8217;re not up to speed with TensorFlow, I suggest you check out my <a href="http://adventuresinmachinelearning.com/python-tensorflow-tutorial/" target="_blank" rel="noopener">TensorFlow tutorial</a> or this online course <a href="https://click.linksynergy.com/link?id=Jbc0N5ZkDzk&amp;offerid=323058.772462&amp;type=2&amp;murl=https%3A%2F%2Fwww.udemy.com%2Fdata-science-deep-learning-in-theano-tensorflow%2F" target="new">Data Science: Practical Deep Learning in Theano + TensorFlow</a><img src="https://ad.linksynergy.com/fs-bin/show?id=Jbc0N5ZkDzk&amp;bids=323058.772462&amp;type=2&amp;subid=0" width="1" height="1" border="0" />.  Also, it&#8217;s probably a good idea to check out my <a href="http://adventuresinmachinelearning.com/word2vec-tutorial-tensorflow/" target="_blank" rel="noopener">Word2Vec TensorFlow tutorial</a> to understand how the embedding layer works.</p>
<p>The first step is to select some random words from the top 100 most common words in our text data set.</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">valid_size = 16  # Random set of words to evaluate similarity on.
valid_window = 100  # Only pick dev samples in the head of the distribution.
valid_examples = np.random.choice(valid_window, valid_size, replace=False)
valid_dataset = tf.constant(valid_examples, dtype=tf.int32)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>The last line saves the array of 16 random words into a TensorFlow constant <em>valid_dataset.</em></p>
<p>For the next step, we take the embedding matrix from our gensim Word2Vec simulation and &#8220;implant it&#8221; into a TensorFlow variable which we use as our embedding layer.</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># embedding layer weights are frozen to avoid updating embeddings while training
saved_embeddings = tf.constant(embedding_matrix)
embedding = tf.Variable(initial_value=saved_embeddings, trainable=False)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>Note that in the second line above for the TensorFlow variable declaration, I&#8217;ve set the <em>trainable</em> argument to <em>False. </em>If we were using this layer in, say, training a recurrent neural network, if we didn&#8217;t set this argument to <em>False</em> our embedding layer would be trained in TensorFlow with negative performance impacts. It&#8217;s probably not an overall bad strategy, i.e. starting with a gensim embedding matrix and then training further using something like a recurrent NN, but if you want your embedding layer fixed for performance reasons, you need to set <em>trainable</em> to <em>False</em>.</p>
<p>The next chunk of code calculates the similarity between each of the word vectors using the <a href="https://en.wikipedia.org/wiki/Cosine_similarity" target="_blank" rel="noopener">cosine similarity</a> measure. It is explained more fully in my <a href="http://adventuresinmachinelearning.com/word2vec-tutorial-tensorflow/" target="_blank" rel="noopener">Word2Vec TensorFlow tutorial</a>, but basically it calculates the norm of all the embedding vectors, then performs a dot product between the validation words and all other word vectors.</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># create the cosine similarity operations
norm = tf.sqrt(tf.reduce_sum(tf.square(embedding), 1, keep_dims=True))
normalized_embeddings = embedding / norm
valid_embeddings = tf.nn.embedding_lookup(
      normalized_embeddings, valid_dataset)
similarity = tf.matmul(valid_embeddings, normalized_embeddings, transpose_b=True)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>Now we can run our TensorFlow session and sort the eight words which are closest to our validation example words.  Again, this code is explained in more detail in the previously mentioned tutorial.</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># Add variable initializer.
init = tf.global_variables_initializer()

with tf.Session() as sess:
    sess.run(init)
    # call our similarity operation
    sim = similarity.eval()
    # run through each valid example, finding closest words
    for i in range(valid_size):
        valid_word = wv.index2word[i]
        top_k = 8  # number of nearest neighbors
        nearest = (-sim[i, :]).argsort()[1:top_k + 1]
        log_str = &#039;Nearest to %s:&#039; % valid_word
            for k in range(top_k):
            close_word = wv.index2word[nearest[k]]
            log_str = &#039;%s %s,&#039; % (log_str, close_word)
        print(log_str)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>This code will produce lines like:</p>
<blockquote><p>Nearest to two: three, five, zero, four, six, one, seven, eight</p></blockquote>
<p>As you can see, our Word2Vec embeddings produced by gensim have the expected results &#8211; in this example, we have number words being grouped together in similarity which makes sense.</p>
<p>Next up, let&#8217;s see how we can use the gensim Word2Vec embeddings in Keras.</p>
<h1>Using gensim Word2Vec embeddings in Keras</h1>
<p>We can perform similar steps with a Keras model. In this case, following the example code previously shown in <a href="http://adventuresinmachinelearning.com/word2vec-keras-tutorial/" target="_blank" rel="noopener">the Keras Word2Vec tutorial</a>, our model takes two single word samples as input and finds the similarity between them.  The top 8 closest words loop is therefore slightly different than the previous example:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">valid_size = 16  # Random set of words to evaluate similarity on.
valid_window = 100  # Only pick dev samples in the head of the distribution.
valid_examples = np.random.choice(valid_window, valid_size, replace=False)
# input words - in this case we do sample by sample evaluations of the similarity
valid_word = Input((1,), dtype=&#039;int32&#039;)
other_word = Input((1,), dtype=&#039;int32&#039;)
# setup the embedding layer
embeddings = Embedding(input_dim=embedding_matrix.shape[0], output_dim=embedding_matrix.shape[1],
                      weights=[embedding_matrix])
embedded_a = embeddings(valid_word)
embedded_b = embeddings(other_word)
similarity = merge([embedded_a, embedded_b], mode=&#039;cos&#039;, dot_axes=2)
# create the Keras model
k_model = Model(input=[valid_word, other_word], output=similarity)

def get_sim(valid_word_idx, vocab_size):
    sim = np.zeros((vocab_size,))
    in_arr1 = np.zeros((1,))
        in_arr2 = np.zeros((1,))
    in_arr1[0,] = valid_word_idx
    for i in range(vocab_size):
        in_arr2[0,] = i
        out = k_model.predict_on_batch([in_arr1, in_arr2])
        sim[i] = out
    return sim

# now run the model and get the closest words to the valid examples
for i in range(valid_size):
    valid_word = wv.index2word[valid_examples[i]]
    top_k = 8  # number of nearest neighbors
    sim = get_sim(valid_examples[i], len(wv.vocab))
    nearest = (-sim).argsort()[1:top_k + 1]
    log_str = &#039;Nearest to %s:&#039; % valid_word
    for k in range(top_k):
        close_word = wv.index2word[nearest[k]]
        log_str = &#039;%s %s,&#039; % (log_str, close_word)
    print(log_str)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>As you can see when I setup the <em>embeddings</em> layer (using Keras&#8217; dedicated <em>Embedding()</em> layer), all we need to do is specify the input and output dimensions (vocabulary size and embedding vector length, respectively) and then assign the gensim <em>embedding_matrix </em>to the <em>weights</em> argument. All the remaining logic is a copy from the <a href="http://adventuresinmachinelearning.com/word2vec-keras-tutorial/" target="_blank" rel="noopener">Keras Word2Vec tutorial</a>, so check that post out for more details.</p>
<p>The code produces lines like:</p>
<blockquote><p>Nearest to when: unless, if, where, whenever, then, before, once, finally</p></blockquote>
<p>Here we can see that <a href="https://en.wikipedia.org/wiki/Conjunction_(grammar)" target="_blank" rel="noopener">subordinating conjunction</a> word types have been grouped together &#8211; which is a good, expected result.</p>
<p>So that wraps up the tutorial &#8211; in this post, I&#8217;ve shown you how to use gensim to create Word2Vec word embeddings in a quick and efficient fashion.  I then gave an overview of how to &#8220;upload&#8221; these learned embeddings into TensorFlow and Keras.  I hope it has been helpful.</p>
<p>&nbsp;</p>
<hr />
<p><strong>Recommended online course: </strong>If you are more of a video course learner, check out this inexpensive Udemy course: <a href="https://click.linksynergy.com/link?id=Jbc0N5ZkDzk&amp;offerid=323058.918390&amp;type=2&amp;murl=https%3A%2F%2Fwww.udemy.com%2Fnatural-language-processing-with-deep-learning-in-python%2F" target="new">Natural Language Processing with Deep Learning in Python</a><img src="https://ad.linksynergy.com/fs-bin/show?id=Jbc0N5ZkDzk&amp;bids=323058.918390&amp;type=2&amp;subid=0" width="1" height="1" border="0" /></p>
<hr />
<p>&nbsp;</p>
<p>The post <a rel="nofollow" href="http://adventuresinmachinelearning.com/gensim-word2vec-tutorial/">Python gensim Word2Vec tutorial with TensorFlow and Keras</a> appeared first on <a rel="nofollow" href="http://adventuresinmachinelearning.com">Adventures in Machine Learning</a>.</p>
]]></content:encoded>
			<wfw:commentRss>http://adventuresinmachinelearning.com/gensim-word2vec-tutorial/feed/</wfw:commentRss>
		<slash:comments>7</slash:comments>
		</item>
		<item>
		<title>An introduction to TensorFlow queuing and threading</title>
		<link>http://adventuresinmachinelearning.com/introduction-tensorflow-queuing/</link>
		<comments>http://adventuresinmachinelearning.com/introduction-tensorflow-queuing/#comments</comments>
		<pubDate>Sat, 12 Aug 2017 01:18:22 +0000</pubDate>
		<dc:creator><![CDATA[Andy]]></dc:creator>
				<category><![CDATA[Deep learning]]></category>
		<category><![CDATA[TensorFlow]]></category>

		<guid isPermaLink="false">http://adventuresinmachinelearning.com/?p=453</guid>
		<description><![CDATA[<p>One of the great things about TensorFlow is its ability to handle multiple threads and therefore allow asynchronous operations.  If we have large datasets this can <a class="mh-excerpt-more" href="http://adventuresinmachinelearning.com/introduction-tensorflow-queuing/" title="An introduction to TensorFlow queuing and threading">[...]</a></p>
<p>The post <a rel="nofollow" href="http://adventuresinmachinelearning.com/introduction-tensorflow-queuing/">An introduction to TensorFlow queuing and threading</a> appeared first on <a rel="nofollow" href="http://adventuresinmachinelearning.com">Adventures in Machine Learning</a>.</p>
]]></description>
				<content:encoded><![CDATA[<p>One of the great things about TensorFlow is its ability to handle multiple threads and therefore allow asynchronous operations.  If we have large datasets this can significantly speed up the training process of our models.  This functionality is especially handy when reading, pre-processing and extracting in mini-batches our training data.  The secret to being able to do professional and high-performance training of our models is understanding TensorFlow queuing operations.  The particular queuing operations/objects we will be looking at in this tutorial are <em>FIFOQueue, </em><em>RandomShuffleQueue, </em> <em>QueueRunner, Coordinator, </em><em>string_input_producer </em>and <em>shuffle_batch</em>, but the concepts that I will introduce are common to the multitude of <a href="https://www.tensorflow.org/api_guides/python/io_ops" target="_blank" rel="noopener">queuing and threading operations available in TensorFlow</a>.</p>
<p><strong>Note: </strong>While the content of this post is still relevant and is the core of TensorFlow&#8217;s efficient data consumption pipelines, there is an updated API called the Dataset API. After reading this post, it might be an idea to check out <a href="http://adventuresinmachinelearning.com/tensorflow-dataset-tutorial/">my post on the Dataset API too</a>.</p>
<p>If you&#8217;re a beginner to TensorFlow, I&#8217;d recommend first checking out some of my other TensorFlow tutorials <a href="http://adventuresinmachinelearning.com/python-tensorflow-tutorial/" target="_blank" rel="noopener">Python TensorFlow Tutorial – Build a Neural Network</a> and/or <a href="http://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-tensorflow/" target="_blank" rel="noopener">Convolutional Neural Networks Tutorial in TensorFlow</a>.  If you&#8217;re more of a video learning person, get up to speed with the online course below.</p>
<hr />
<p><strong>Recommended</strong><strong> online course: </strong>If you want a video introduction to TensorFlow, I recommend the following inexpensive Udemy course: <a href="https://click.linksynergy.com/link?id=Jbc0N5ZkDzk&amp;offerid=323058.1326292&amp;type=2&amp;murl=https%3A%2F%2Fwww.udemy.com%2Fcomplete-guide-to-tensorflow-for-deep-learning-with-python%2F">Complete Guide to TensorFlow for Deep Learning with Python</a><img src="https://ad.linksynergy.com/fs-bin/show?id=Jbc0N5ZkDzk&amp;bids=323058.1326292&amp;type=2&amp;subid=0" width="1" height="1" border="0" /></p>
<hr />
<p>As usual, all the code for this post is on <a href="https://github.com/adventuresinML/adventures-in-ml-code" target="_blank" rel="noopener">this site&#8217;s Github repository</a>.</p>
<h1>TensorFlow queuing and threads &#8211; introductory concepts</h1>
<p>We know from our common day experience that certain tasks can be performed in parallel, and when we do such tasks in parallel we can get great reductions in the time it takes to complete complex tasks.  The same is true in computing &#8211; often our CPU will get stuck waiting for the completion of a single task, such as waiting to read in data from a file or database, and it <em>blocks</em> any other tasks from occurring in the program.  Needless to say, this impacts performance and doesn&#8217;t utilize our CPUs effectively.</p>
<p>These types of issues are tackled in computing by using <em>threading</em>.  Threading involves multiple tasks running <em>asynchronously &#8211; </em>that is when one thread is <em>blocked</em> another thread gets to run.  When we have multiple CPUs, we can also have multi-threading which allows different threads to run <em>at the same time</em>.  Unfortunately, threading is notoriously difficult to manage, especially in Python.  Thankfully, TensorFlow has come to the rescue and provided us means of including threading in our input data processing.</p>
<p>In fact, TensorFlow has released a <a href="https://www.tensorflow.org/performance/performance_guide" target="_blank" rel="noopener">performance guide</a> which specifically recommends the use of threading when inputting data to our training processes.  Their method of threading is called <em>Queuing.</em>  Often when you read introductory tutorials on TensorFlow (<a href="http://adventuresinmachinelearning.com/python-tensorflow-tutorial/" target="_blank" rel="noopener">mine included</a>), you won&#8217;t hear about TensorFlow <em>queuing</em><em>.</em>  Instead, you&#8217;ll see the following <em>feed_dict</em> syntax as the method of feeding data into the training graph:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})</code></pre> <div class="code-embed-infos"> </div> </div>
<p>Here data is fed into the final training operation via the <em>feed_dict</em> argument.  TensorFlow, in its performance guide, <em>specifically discourages </em>the use of the <em>feed_dict</em> method.  It&#8217;s great for tutorials if you want to focus on core TensorFlow functionality, but not so good for overall performance.  This tutorial will introduce you to the concept of TensorFlow <em>queuing</em>.</p>
<p>What are TensorFlow queues exactly?  They are data storage objects which can be loaded and de-loaded with information asynchronously using threads.  This allows us to stream data into our training algorithms more seamlessly, as loading and de-loading of data can be performed at the same time (or when one thread is blocking) &#8211; with our queue being &#8220;topped up&#8221; when required with new data to ensure a steady stream of data.  This process will be shown more fully below, as I introduce different TensorFlow queuing concepts.</p>
<p>The first TensorFlow queue that I will introduce is the first-in, first-out queue called <em>FIFOQueue.</em></p>
<h2>The <em>FIFOQueue</em> &#8211; first in, first out</h2>
<p>The illustration below, from the <a href="https://www.tensorflow.org/programmers_guide/threading_and_queues" target="_blank" rel="noopener">TensorFlow website</a>,  shows a <em>FIFOQueue </em>in action:</p>
<figure id="attachment_467" style="width: 641px" class="wp-caption aligncenter"><img class=" wp-image-467" src="http://adventuresinmachinelearning.com/wp-content/uploads/2017/08/IncremeterFifoQueue.gif" alt="TensorFlow queuing - FIFOqueue" width="641" height="275" /><figcaption class="wp-caption-text">A FIFOQueue in action</figcaption></figure>
<p>Here is what is happening in the <em>gif</em> above &#8211; first a <em>FIFOQueue </em>object is created with a capacity of 3 and a data type = &#8220;float&#8221;.  An <em>enqueue_many</em> operation is then performed on the queue &#8211; this basically loads up the queue to capacity with the vector [0, 0, 0].  Next, the code creates a dequeue operation &#8211; where the first value to enter the queue is unloaded.  The next operation simply adds 1 to the dequeued value.  The last operation adds this incremented number back to the top of the <em>FIFOQueue</em> to &#8220;top it up&#8221; &#8211; making sure it doesn&#8217;t run out of values to dequeue.  These operations are then run and you can see the result &#8211; a kind of slowly incrementing counter.</p>
<p>Let&#8217;s have another look at how this works by introducing some real TensorFlow code:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">dummy_input = tf.random_normal([3], mean=0, stddev=1)
dummy_input = tf.Print(dummy_input, data=[dummy_input],
                           message=&#039;New dummy inputs have been created: &#039;, summarize=6)
q = tf.FIFOQueue(capacity=3, dtypes=tf.float32)
enqueue_op = q.enqueue_many(dummy_input)
data = q.dequeue()
data = tf.Print(data, data=[q.size()], message=&#039;This is how many items are left in q: &#039;)
# create a fake graph that we can call upon
fg = data + 1</code></pre> <div class="code-embed-infos"> </div> </div>
<p>In this code example, I&#8217;ve created, I first create a random normal tensor, of size 3, and then I create a printing operation so we can see what values have been randomly selected.  After that, I set up a <em>FIFOQueue</em>, with capacity = 3 as in the example above.  I enqueue all three values of the random tensor in the <em>enqueue_op</em>.  Then I immediately attempt to <em>dequeue</em> a value from <em>q</em> and assign it to <em>data</em>.  Another print operation follows and then I create basically a fake graph, where I simply add 1 to the dequeued <em>data</em> variable.  This step is required so TensorFlow knows that it needs to execute all the preceding operations which lead up to producing <em>data</em>.  Next, we start up a session and run:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">with tf.Session() as sess:
    # first load up the queue
    sess.run(enqueue_op)
    # now dequeue a few times, and we should see the number of items
    # in the queue decrease
    sess.run(fg)
    sess.run(fg)
    sess.run(fg)
    # by this stage the queue will be emtpy, if we run the next time, the queue
    # will block waiting for new data
    sess.run(fg)
    # this will never print:
    print(&quot;We&#039;re here!&quot;)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>All that is performed in the code above is running the <em>enqueue_many</em> operation (<em>enqueue_op</em>) which loads up our <em>queue</em> to capacity, and then we run the fake graph operation, which involves emptying our queue of values, one at a time.  After we&#8217;ve run this operation a few times the queue will be empty &#8211; if we try and run the operation again, the main thread of the program will hang or block &#8211; this is because it will be waiting for another operation to be run to put more values in the queue.  As such, the final print statement is never run.  The output looks like this:</p>
<div class="code-embed-wrapper"> <pre class="language-markdown code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-markdown code-embed-code">New dummy inputs have been created: [0.73847228 0.086355612 0.56138796]
This is how many items are left in q: [3]
This is how many items are left in q: [2]
This is how many items are left in q: [1]</code></pre> <div class="code-embed-infos"> </div> </div>
<p>Once the output gets to the point above you&#8217;ll actually have to terminate the program as it is blocked. Now, this isn&#8217;t very useful.  What we really want to happen is for our little program to reload or enqueue more values whenever our queue is empty or is about to become empty.  We could fix this by explicitly running our <em>enqueue_op </em>again in the code above to reload our queue with values.  However, for large, more realistic programs, this will become unwieldy.  Thankfully, TensorFlow has a solution.</p>
<h2>QueueRunners and the Coordinator</h2>
<p>The first object that TensorFlow has for us is the QueueRunner object.  A QueueRunner will control the asynchronous execution of enqueue operations to ensure that our queues never run dry.  Not only that, but it can create multiple threads of enqueue operations, all of which it will handle in an asynchronous fashion.  This makes things easy for us.  We have to add all our queue runners, after we&#8217;ve created them, to the <a href="https://www.tensorflow.org/api_docs/python/tf/GraphKeys" target="_blank" rel="noopener">GraphKeys collection</a> called <em>QUEUE_RUNNERS.  </em>This is a collection of all the queue runners, and adding our runners to this collection allows TensorFlow to include them when constructing its computational graph (for more information on computational graphs check out my <a href="http://adventuresinmachinelearning.com/python-tensorflow-tutorial/" target="_blank" rel="noopener">TensorFlow tutorial</a>).  This is what the first half of our previous code example now looks like after incorporating these concepts:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">dummy_input = tf.random_normal([5], mean=0, stddev=1)
dummy_input = tf.Print(dummy_input, data=[dummy_input],
                           message=&#039;New dummy inputs have been created: &#039;, summarize=6)
q = tf.FIFOQueue(capacity=3, dtypes=tf.float32)
enqueue_op = q.enqueue_many(dummy_input)
# now setup a queue runner to handle enqueue_op outside of the main thread asynchronously
qr = tf.train.QueueRunner(q, [enqueue_op] * 1)
tf.train.add_queue_runner(qr)

data = q.dequeue()
data = tf.Print(data, data=[q.size(), data], message=&#039;This is how many items are left in q: &#039;)
# create a fake graph that we can call upon
fg = data + 1</code></pre> <div class="code-embed-infos"> </div> </div>
<p>The first change is to increase the size of <em>dummy_input</em> &#8211; more on this later.  The most important change is the <em>qr = tf.train.QueueRunner(q, [enqueue_op] * 1)  </em>operation.  The first argument in this definition is the queue we want to run &#8211; in this case, it is the <em>q</em> assigned to the creation of our <em>FIFOQueue</em> object.  The next argument is a list argument, and this specifies how many enqueue operation threads we want to create.  In this case, my &#8220;<em>* 1&#8243; </em>is not required, but it is meant to be illustrative to show that I am just creating a single enqueuing thread which will run asynchronously with the main thread of the program.  If I wanted to create, say, 10 threads, this line would look like:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">qr = tf.train.QueueRunner(q, [enqueue_op] * 10)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>The next addition is the <em>add_queue_runner</em> operation which adds our queue runner (<em>qr</em>) to the QUEUE_RUNNERS collection.</p>
<p>At this point, you may think that we are all set &#8211; but not quite.  Finally, we have to add a TensorFlow object called a <em>Coordinator.  </em>A coordinator object helps to make sure that all the threads we create stop together &#8211; this is important at any point in our program where we want to bring all the multiple threads together and rejoin the main thread (usually at the end of the program).  It is also important if an exception occurs on one of the threads &#8211; we want this exception broadcast to all of the threads so that they all stop.  More on the Coordinator object can be found <a href="https://www.tensorflow.org/programmers_guide/threading_and_queues" target="_blank" rel="noopener">here</a> &#8211; in our code, we will be implementing it rather naively.  The session part of our example now looks like this:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">with tf.Session() as sess:
    coord = tf.train.Coordinator()
    threads = tf.train.start_queue_runners(coord=coord)
    # now dequeue a few times, and we should see the number of items
    # in the queue decrease
    sess.run(fg)
    sess.run(fg)
    sess.run(fg)
    # previously the main thread blocked / hung at this point, as it was waiting
    # for the queue to be filled.  However, it won&#039;t this time around, as we
    # now have a queue runner on another thread making sure the queue is
    # filled asynchronously
    sess.run(fg)
    sess.run(fg)
    sess.run(fg)
    # this will print, but not necessarily after the 6th call of sess.run(fg)
    # due to the asynchronous operations
    print(&quot;We&#039;re here!&quot;)
    # we have to request all threads now stop, then we can join the queue runner
    # thread back to the main thread and finish up
    coord.request_stop()
    coord.join(threads)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>The first two lines create a generic Coordinator object and the second starts our queue runners, specifying our coordinator object which will handle the stopping of the threads.  We now can run <em>sess.run(fg)</em> as many times as we like, with the queue runners now ensuring that the <em>FIFOQueue </em>always has data in it when we need it &#8211; it will no longer hang or block.  Finally, once we are done we ask the threads to stop operation <em>(coord.request_stop())</em> and then we ask the coordinator to join the threads back into the main program thread (<em>coord.join(threads)</em>).  The output looks like this:</p>
<div class="code-embed-wrapper"> <pre class="language-markdown code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-markdown code-embed-code">New dummy inputs have been created: [-0.81459045 -1.9739552 -0.9398123 1.0848273 1.0323733]
This is how many items are left in q: [0][-0.81459045]
This is how many items are left in q: [3][-1.9739552]
New dummy inputs have been created: [-0.03232909 -0.34122062 0.85883951 -0.95554483 1.1082178]
This is how many items are left in q: [3][-0.9398123]
We&#039;re here!
This is how many items are left in q: [3][1.0848273]
This is how many items are left in q: [3][1.0323733]
This is how many items are left in q: [3][-0.03232909]</code></pre> <div class="code-embed-infos"> </div> </div>
<p>The first thing to notice about the above is that the printing of outputs is all over the place i.e. not in a linear order.  This is because of the asynchronous, nonlinear, running of the thread and enqueuing operations.  The second thing to notice is that our dummy inputs are of size 5, while our queue only has a capacity of 3.  In other words, when we run the <em>enqueue_many</em> operation we, in a sense, <em>overflow</em> the queue.  You&#8217;d think that this would result in the overflowed values being discarded (or an exception being raised), but if you look at the flow of outputs carefully, you can see that these values are simply held in &#8220;stasis&#8221; until they have room to be loaded.  This is a pretty robust way for TensorFlow to handle things.</p>
<p>Ok, so that&#8217;s a good introduction to the main concepts of queues and threading in TensorFlow.  Now let&#8217;s look at using these objects in a more practical example.</p>
<h1>A more practical example &#8211; reading the CIFAR-10 dataset</h1>
<p>The <a href="https://www.cs.toronto.edu/~kriz/cifar.html" target="_blank" rel="noopener">CIFAR-10 dataset</a> is a series of labeled images which contain objects such as cars, planes, cats, dogs etc.  It is a frequently used benchmark for image classification tasks.  It is a large dataset (166MB) and is a prime example of where a good data streaming queuing routine is needed for high performance.  In the following example, I am going to show how to read in this data using a <em>FIFOQueue </em>and create data-batches using another queue object called a <em>RandomShuffleQueue.  </em>To learn more about batching, have a look at my <a href="http://adventuresinmachinelearning.com/stochastic-gradient-descent/" target="_blank" rel="noopener">Stochastic Gradient Descent tutorial</a>.  Included in the code example is a number of steps required to process the images, but I am not going to concentrate on these steps in this tutorial &#8211; that&#8217;s fodder for a future post.  Rather, I will focus on the queuing aspects.  The code will include a number of steps:</p>
<ol>
<li>Create a list of filenames which hold the CIFAR-10 data</li>
<li>Create a <em>FIFOQueue </em>to hold the randomly shuffled filenames, and associated enqueuing</li>
<li>Dequeue files and extract image data</li>
<li>Perform image processing</li>
<li>Enqueue processed image data into a <em>RandomShuffleQueue</em></li>
<li>Dequeue data batches for classifier training (the classifier training won&#8217;t be covered in this tutorial &#8211; that&#8217;s for a future post)</li>
</ol>
<p>This process will closely resemble the following <em>gif</em>, again from the TensorFlow site:</p>
<figure id="attachment_475" style="width: 663px" class="wp-caption aligncenter"><img class=" wp-image-475" src="http://adventuresinmachinelearning.com/wp-content/uploads/2017/08/AnimatedFileQueues.gif" alt="TensorFlow queuing - filename and processing queue" width="663" height="165" /><figcaption class="wp-caption-text">Filename and processing queue</figcaption></figure>
<p>The main flow of the program looks like this:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">def cifar_shuffle_batch():
    batch_size = 128
    num_threads = 16
    # create a list of all our filenames
    filename_list = [data_path + &#039;data_batch_{}.bin&#039;.format(i + 1) for i in range(5)]
    # create a filename queue
    file_q = cifar_filename_queue(filename_list)
    # read the data - this contains a FixedLengthRecordReader object which handles the
    # de-queueing of the files.  It returns a processed image and label, with shapes
    # ready for a convolutional neural network
    image, label = read_data(file_q)
    # setup minimum number of examples that can remain in the queue after dequeuing before blocking
    # occurs (i.e. enqueuing is forced) - the higher the number the better the mixing but
    # longer initial load time
    min_after_dequeue = 10000
    # setup the capacity of the queue - this is based on recommendations by TensorFlow to ensure
    # good mixing
    capacity = min_after_dequeue + (num_threads + 1) * batch_size
    image_batch, label_batch = cifar_shuffle_queue_batch(image, label, batch_size, num_threads)
    # now run the training
    cifar_run(image_batch, label_batch)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>I&#8217;ll go through each of the main queuing steps below.</p>
<h2>The filename queue</h2>
<p>First, after defining a few parameters, we create a filename list to pull in the 5 binary data files which comprise the CIFAR-10 data set.  Then we run the <em>cifar_filename_queue()</em> function which I&#8217;ve created &#8211; it looks like this:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">def cifar_filename_queue(filename_list):
    # convert the list to a tensor
    string_tensor = tf.convert_to_tensor(filename_list, dtype=tf.string)
    # randomize the tensor
    tf.random_shuffle(string_tensor)
    # create the queue
    fq = tf.FIFOQueue(capacity=10, dtypes=tf.string)
    # create our enqueue_op for this q
    fq_enqueue_op = fq.enqueue_many([string_tensor])
    # create a QueueRunner and add to queue runner list
    # we only need one thread for this simple queue
    tf.train.add_queue_runner(tf.train.QueueRunner(fq, [fq_enqueue_op] * 1))
    return fq</code></pre> <div class="code-embed-infos"> </div> </div>
<p>The first thing that is performed in the above function is to convert the <em>filename_list</em> to a tensor.  Then we randomly shuffle the list and create a capacity = 10 <em>FIFOQueue.  </em>We then enqueue <em>fq</em> with our tensor of randomly shuffled file names and add a queue runner.  This is all pretty straightforward and produces a randomly shuffled queue of filenames to dequeue from.  We only need one thread to perform this operation, as it is pretty simple.  We return the filename queue, <em>fq, </em>from the function.</p>
<p>Next up in the main flow of our program is the <em>read_data</em> function.</p>
<h2>The FixedLengthRecordReader</h2>
<p>The <em>read_data</em> function takes the filename queue, dequeues file names and extracts the image and label data from the CIFAR-10 data set.  Most of the function deals with preprocessing the image data, so we&#8217;ll skip over most of it (you can have a look at the <a href="https://github.com/adventuresinML/adventures-in-ml-code" target="_blank" rel="noopener">code on Github</a> if you like).  However, there is a special TensorFlow object that we want to pay attention to:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">reader = tf.FixedLengthRecordReader(record_bytes=record_bytes)
result.key, value = reader.read(file_q)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>The FixedLengthRecordReader is a TensorFlow reader which is especially useful for reading binary files, where each record or row is a fixed number of bytes.  Previously in <em>read_data</em> the number of bytes per record or data file row is calculated and stored in <em>record_bytes.  </em>Of particular note is that this reader also implicitly handles the dequeuing operation from <em>file_q</em> (our filename queue).  So we don&#8217;t have to worry about explicitly dequeuing from our filename queue.  The reader will also parse the files it dequeues and return the image data.  The rest of the <em>read_data</em> function deals with shaping up the image and label data from the raw binary information.  Note that the <em>read_data</em> function returns a single image and label record, of size (24, 24, 3) and (1), respectively.  The image size, (24, 24, 3), represents a 24 x 24 pixel image, with an RGB depth of 3.</p>
<p>The next step in the main flow of the program is to setup the minimum number of examples in the upcoming <em>RandomShuffleQueue.</em></p>
<h2>The minimum number of examples in the RandomShuffleQueue</h2>
<p>When we want to extract randomized batch data from a queue which is fed by a queue of filenames, we want to make sure that the data is truly randomized across the data set.  To ensure this occurs, we want new data flowing into the randomized queue regularly.  TensorFlow handles this by including an argument for the <em>RandomShuffleQueue </em>called <em>min_after_dequeue</em>.  If, after a dequeuing operation, the number of examples or samples in the queue falls below this value it will block any further dequeuing until more samples are added to the queue.  In other words, it will force an enqueuing operation.  TensorFlow has some things to say about what our queue <em>capacity</em> and <em>min_after_dequeue </em>values should be to ensure good mixing when extracting random batch samples <a href="https://www.tensorflow.org/programmers_guide/reading_data" target="_blank" rel="noopener">in their documentation</a>.  In our case, we will follow their recommendations:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># setup minimum number of examples that can remain in the queue after dequeuing before blocking
# occurs (i.e. enqueuing is forced) - the higher the number the better the mixing but
# longer initial load time
min_after_dequeue = 10000
# setup the capacity of the queue - this is based on recommendations by TensorFlow to ensure
# good mixing
capacity = min_after_dequeue + (threads + 1) * batch_size</code></pre> <div class="code-embed-infos"> </div> </div>
<h2>The RandomShuffleQueue</h2>
<p>We now want to setup our <em>RandomShuffleQueue</em> which enables us to extract randomized batch data which can then be fed into our <a href="http://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-tensorflow/" target="_blank" rel="noopener">convolutional neural network</a> or some other training graph.  The <em>RandomShuffleQueue</em> is similar to the <em>FIFOQueue</em>, in that it involves the same sort of enqueuing and dequeuing operations.  The only real difference is that the <em>RandomShuffleQueue </em>dequeues elements in a random manner.  This is obviously useful when we are training our neural networks using <a href="http://adventuresinmachinelearning.com/stochastic-gradient-descent/" target="_blank" rel="noopener">mini-batches</a>.  The implementation of this functionality is in my function <em>cifar_shuffle_queue_batch, </em>which I reproduce below:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">def cifar_shuffle_queue_batch(image, label, batch_size, capacity, min_after_dequeue, threads):
    tensor_list = [image, label]
    dtypes = [tf.float32, tf.int32]
    shapes = [image.get_shape(), label.get_shape()]
    q = tf.RandomShuffleQueue(capacity=capacity, min_after_dequeue=min_after_dequeue,
                              dtypes=dtypes, shapes=shapes)
    enqueue_op = q.enqueue(tensor_list)
    # add to the queue runner
    tf.train.add_queue_runner(tf.train.QueueRunner(q, [enqueue_op] * threads))
    # now extract the batch
    image_batch, label_batch = q.dequeue_many(batch_size)
    return image_batch, label_batch</code></pre> <div class="code-embed-infos"> </div> </div>
<p>We first create a variable called <em>tensor_list</em> which is simply a list of the image and label data &#8211; this will be the data which is enqueued to the <em>RandomShuffleQueue.  </em>We then specify the data types and tensor sizes which match this data and is required as input to the <em>RandomShuffleQueue </em>definition.  Because of the large volumes of data, we setup 16 threads for this queue.  The enqueuing and adding to the QUEUE_RUNNERS collection operations are things we have seen before.  In the final line of the function, we perform a <em>dequeue_many</em> operation and the number of examples we dequeue is equal to the batch size we desire for our training.  Finally, the image batches and label batches are returned as a tuple.</p>
<p>All that is left now is to specify the session which runs our operations.</p>
<h2>Running the operations</h2>
<p>The final function I created in the main flow of the program is called <em>cifar_run</em>:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">def cifar_run(image, label):
    with tf.Session() as sess:
        coord = tf.train.Coordinator()
        threads = tf.train.start_queue_runners(coord=coord)
        for i in range(5):
            image_batch, label_batch = sess.run([image, label])
            print(image_batch.shape, label_batch.shape)

        coord.request_stop()
        coord.join(threads)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>In this function, all I do is run the operations which were passed into this function &#8211; <em>image</em> and <em>label</em>.  Remember that to execute these operations, the <em>dequeue_many</em> operation must be run for the <em>RandomShuffleQueue</em> along with all the preceding operations in the computational graph (i.e. pre-processing, file name queue etc.).  Running these operations returns the actual batch data, and I then print the shape of these batches.  I perform 5 batch extractions, but one could perform an indefinite number of these extractions, with the enqueuing and dequeuing all being taken care of via the queue runners.  The output looks like this:</p>
<div class="code-embed-wrapper"> <pre class="language-markdown code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-markdown code-embed-code">(128, 24, 24, 3) (128, 1)
(128, 24, 24, 3) (128, 1)
(128, 24, 24, 3) (128, 1)
(128, 24, 24, 3) (128, 1)
(128, 24, 24, 3) (128, 1)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>This output isn&#8217;t very interesting &#8211; but it shows you that the whole queuing process is working as it should &#8211; each time returning 128 examples (128 is our specified batch size) of image and label data.  You can also look at each batch and find that the data is indeed randomized as we had hoped it would be.  So there you have it, you now know how TensorFlow queuing and threads work.</p>
<p>In the above explanation, for illustrative purposes, I&#8217;ve actually shown you the long way of creating filename and random batch shuffle queues.  TensorFlow has created a couple of helper functions which reduce the amount of code we need to implement these queues.</p>
<h2>The <em>string_input_producer</em> and <em>shuffle_batch</em></h2>
<p>There are two queue helpers in TensorFlow which basically replicate the functionality of my custom functions which utilize <em>FIFOQueue </em>and <em>RandomShuffleQueue.  </em>These functions are called <em>string_input_producer</em> which takes a list of filenames and creates a <em>FIFOQueue </em>with enqueuing<em> </em>implicitely provided, and <em>shuffle_batch</em> which creates a <em>RandomShuffleQueue </em>with enqueuing <em>and </em>batch-sized dequeuing<em> </em>already provided.  In my main program (<em>cifar_shuffle_batch</em>) you can replace my <em>cifar_filename_queue</em> and <em>cifar_shuffle_batch_queue</em> functions with calls to <em>string_input_producer </em>and <em>shuffle_batch</em> respectively, like so:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># file_q = cifar_filename_queue(filename_list)
file_q = tf.train.string_input_producer(filename_list)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>and:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># image_batch, label_batch = cifar_shuffle_queue_batch(image, label, batch_size, num_threads)
image_batch, label_batch = tf.train.shuffle_batch([image, label], batch_size, capacity, min_after_dequeue,
                                                      num_threads=num_threads)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>By running the script (at the Github repository <a href="https://github.com/adventuresinML/adventures-in-ml-code" target="_blank" rel="noopener">here</a>) with these replacements, you will get the same results as before.</p>
<p>We have now covered how TensorFlow queuing and threading works.  I hope you now feel confident to implement these concepts in your TensorFlow programs, which will allow you to build high-performance TensorFlow training algorithms.  As always, have fun.</p>
<hr />
<p><strong>Recommended</strong><strong> online course: </strong>If you want learn more about TensorFlow and like video courses I recommend the following inexpensive Udemy course: <a href="https://click.linksynergy.com/link?id=Jbc0N5ZkDzk&amp;offerid=323058.1326292&amp;type=2&amp;murl=https%3A%2F%2Fwww.udemy.com%2Fcomplete-guide-to-tensorflow-for-deep-learning-with-python%2F">Complete Guide to TensorFlow for Deep Learning with Python</a><img src="https://ad.linksynergy.com/fs-bin/show?id=Jbc0N5ZkDzk&amp;bids=323058.1326292&amp;type=2&amp;subid=0" width="1" height="1" border="0" /></p>
<hr />
<p>&nbsp;</p>
<p>The post <a rel="nofollow" href="http://adventuresinmachinelearning.com/introduction-tensorflow-queuing/">An introduction to TensorFlow queuing and threading</a> appeared first on <a rel="nofollow" href="http://adventuresinmachinelearning.com">Adventures in Machine Learning</a>.</p>
]]></content:encoded>
			<wfw:commentRss>http://adventuresinmachinelearning.com/introduction-tensorflow-queuing/feed/</wfw:commentRss>
		<slash:comments>3</slash:comments>
		</item>
		<item>
		<title>Word2Vec word embedding tutorial in Python and TensorFlow</title>
		<link>http://adventuresinmachinelearning.com/word2vec-tutorial-tensorflow/</link>
		<comments>http://adventuresinmachinelearning.com/word2vec-tutorial-tensorflow/#comments</comments>
		<pubDate>Fri, 21 Jul 2017 23:45:40 +0000</pubDate>
		<dc:creator><![CDATA[Andy]]></dc:creator>
				<category><![CDATA[NLP]]></category>
		<category><![CDATA[TensorFlow]]></category>
		<category><![CDATA[Word2Vec]]></category>

		<guid isPermaLink="false">http://adventuresinmachinelearning.com/?p=392</guid>
		<description><![CDATA[<p>In coming tutorials on this blog I will be dealing with how to create deep learning models that predict text sequences.  However, before we get <a class="mh-excerpt-more" href="http://adventuresinmachinelearning.com/word2vec-tutorial-tensorflow/" title="Word2Vec word embedding tutorial in Python and TensorFlow">[...]</a></p>
<p>The post <a rel="nofollow" href="http://adventuresinmachinelearning.com/word2vec-tutorial-tensorflow/">Word2Vec word embedding tutorial in Python and TensorFlow</a> appeared first on <a rel="nofollow" href="http://adventuresinmachinelearning.com">Adventures in Machine Learning</a>.</p>
]]></description>
				<content:encoded><![CDATA[<p>In coming tutorials on this blog I will be dealing with how to create deep learning models that predict text sequences.  However, before we get to that point we have to understand some key Natural Language Processing (NLP) ideas.  One of the key ideas in NLP is how we can efficiently convert words into numeric vectors which can then be &#8220;fed into&#8221; various machine learning models to perform predictions.  The current key technique to do this is called &#8220;Word2Vec&#8221; and this is what will be covered in this tutorial.  After discussing the relevant background material, we will be implementing Word2Vec embedding using TensorFlow (which makes our lives a lot easier).  To get up to speed in TensorFlow, check out my <a href="http://adventuresinmachinelearning.com/python-tensorflow-tutorial/" target="_blank" rel="noopener">TensorFlow tutorial</a>. Also, if you prefer Keras &#8211; check out my <a href="http://adventuresinmachinelearning.com/word2vec-keras-tutorial/" target="_blank" rel="noopener">Word2Vec Keras tutorial</a>.</p>
<hr />
<p><strong>Recommended online course: </strong>If you are more of a video course learner, check out this inexpensive Udemy course: <a href="https://click.linksynergy.com/link?id=Jbc0N5ZkDzk&amp;offerid=323058.918390&amp;type=2&amp;murl=https%3A%2F%2Fwww.udemy.com%2Fnatural-language-processing-with-deep-learning-in-python%2F" target="new">Natural Language Processing with Deep Learning in Python</a><img src="https://ad.linksynergy.com/fs-bin/show?id=Jbc0N5ZkDzk&amp;bids=323058.918390&amp;type=2&amp;subid=0" width="1" height="1" border="0" /></p>
<hr />
<h1>Why do we need Word2Vec?</h1>
<p>If we want to feed words into machine learning models, unless we are using tree based methods, we need to convert the words into some set of numeric vectors.  A straight-forward way of doing this would be to use a &#8220;one-hot&#8221; method of converting the word into a sparse representation with only one element of the vector set to 1, the rest being zero.  This is the same method we use for classification tasks &#8211; see <a href="http://adventuresinmachinelearning.com/neural-networks-tutorial/#setting-up-output" target="_blank" rel="noopener">this tutorial</a>.</p>
<p>So, for the sentence &#8220;the cat sat on the mat&#8221; we would have the following vector representation:</p>
<p>\begin{equation}<br />
\begin{pmatrix}<br />
the \\<br />
cat \\<br />
sat \\<br />
on \\<br />
the \\<br />
mat \\<br />
\end{pmatrix}<br />
=<br />
\begin{pmatrix}<br />
1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\<br />
0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\<br />
0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\<br />
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\<br />
1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\<br />
0 &amp; 0 &amp; 0 &amp; 0 &amp; 1<br />
\end{pmatrix}<br />
\end{equation}</p>
<p>Here we have transformed a six word sentence into a 6&#215;5 matrix, with the 5 being the size of the <em>vocabulary </em>(&#8220;the&#8221; is repeated).  In practical applications, however, we will want machine and deep learning models to learn from gigantic vocabularies i.e. 10,000 words plus.  You can begin to see the efficiency issue of using &#8220;one hot&#8221; representations of the words &#8211; the input layer into any neural network attempting to model such a vocabulary would have to be at least 10,000 nodes.  Not only that, this method strips away any local context of the words &#8211; in other words, it strips away information about words which commonly appear close together in sentences (or between sentences).</p>
<p>For instance, we might expect to see &#8220;United&#8221; and &#8220;States&#8221; to appear close together, or &#8220;Soviet&#8221; and &#8220;Union&#8221;.  Or &#8220;food&#8221; and &#8220;eat&#8221;, and so on.  This method loses all such information, which, if we are trying to model natural language, is a large omission.  Therefore, we need an efficient representation of the text data which also conserves information about local word context.  This is where the Word2Vec methodology comes in.</p>
<h1>The Word2Vec methodology</h1>
<p>As mentioned previously, there is two components to the Word2Vec methodology.  The first is the mapping of a high dimensional one-hot style representation of words to a lower dimensional vector. This might involve transforming a 10,000 columned matrix into a 300 columned matrix, for instance. This process is called word embedding.  The second goal is to do this while still maintaining word context and therefore, to some extent, meaning. One approach to achieving these two goals in the Word2Vec methodology is by taking an input word and then attempting to estimate the probability of other words appearing close to that word.  This is called the skip-gram approach.  The alternative method, called Continuous Bag Of Words (CBOW), does the opposite &#8211; it takes some context words as input and tries to find the single word that has the highest probability of fitting that context.  In this tutorial, we will concentrate on the skip-gram method.</p>
<p>What&#8217;s a gram?  A gram is a group of <em>n </em>words, where <em>n</em> is the gram window size.  So for the sentence &#8220;The cat sat on the mat&#8221;, a 3-gram representation of this sentence would be &#8220;The cat sat&#8221;, &#8220;cat sat on&#8221;, &#8220;sat on the&#8221;, &#8220;on the mat&#8221;.  The &#8220;skip&#8221; part refers to the number of times an input word is repeated in the data-set with different context words (more on this later).  These grams are fed into the Word2Vec context prediction system. For instance, assume the input word is &#8220;cat&#8221; &#8211; the Word2Vec tries to predict the context (&#8220;the&#8221;, &#8220;sat&#8221;) from this supplied input word.  The Word2Vec system will move through all the supplied grams and input words and attempt to learn appropriate mapping vectors (embeddings) which produce high probabilities for the right context given the input words.</p>
<p>What is this Word2Vec prediction system?  Nothing other than a neural network.</p>
<h2>The softmax Word2Vec method</h2>
<p>Consider the diagram below &#8211; in this case we&#8217;ll assume the sentence &#8220;The cat sat on the mat&#8221; is part of a much larger text database, with a very large vocabulary &#8211; say 10,000 words in length.  We want to reduce this to a 300 length embedding.</p>
<figure id="attachment_395" style="width: 501px" class="wp-caption aligncenter"><img class=" wp-image-395" src="http://adventuresinmachinelearning.com/wp-content/uploads/2017/07/Word2Vec-softmax.jpg" alt="Word2Vec softmax trainer" width="501" height="315" srcset="http://adventuresinmachinelearning.com/wp-content/uploads/2017/07/Word2Vec-softmax.jpg 676w, http://adventuresinmachinelearning.com/wp-content/uploads/2017/07/Word2Vec-softmax-300x189.jpg 300w" sizes="(max-width: 501px) 100vw, 501px" /><figcaption class="wp-caption-text">A Word2Vec softmax trainer</figcaption></figure>
<p>With respect to the diagram above, if we take the word &#8220;cat&#8221; it will be one of the words in the 10,000 word vocabulary.  Therefore we can represent it as a 10,000 length one-hot vector.  We then interface this input vector to a 300 node hidden layer (if you need to scrub up on neural networks, see <a href="http://adventuresinmachinelearning.com/neural-networks-tutorial/" target="_blank" rel="noopener">this tutorial</a>).  The weights connecting this layer will be our new word vectors &#8211; more on this soon.  The activations of the nodes in this hidden layer are simply linear summations of the weighted inputs (i.e. no non-linear activation, like a sigmoid or tanh, is applied).  These nodes are then fed into a softmax output layer.  During training, we want to change the weights of this neural network so that words surrounding &#8220;cat&#8221; have a higher probability in the softmax output layer.  So, for instance, if our text data set has a lot of Dr Seuss books, we would want our network to assign large probabilities to words like &#8220;the&#8221;, &#8220;sat&#8221; and &#8220;on&#8221; (given lots of sentences like &#8220;the cat sat on the mat&#8221;).</p>
<p>By training this network, we would be creating a 10,000 x 300 weight matrix connecting the 10,000 length input with the 300 node hidden layer.  Each row in this matrix corresponds to a word in our 10,000 word vocabulary &#8211; so we have effectively reduced 10,000 length one-hot vector representations of our words to 300 length vectors.  The weight matrix essentially becomes a look-up or encoding table of our words.  Not only that, but these weight values contain context information due to the way we&#8217;ve trained our network.  Once we&#8217;ve trained the network, we abandon the softmax layer and just use the 10,000 x 300 weight matrix as our word embedding lookup table.</p>
<p>What does this look like in code?</p>
<h2>The softmax Word2Vec method in TensorFlow</h2>
<p>As with any machine learning problem, there are two components &#8211; the first is getting all the data into a usable format, and the next is actually performing the training, validation and testing.  First I&#8217;ll go through how the data can be gathered into a usable format, then we&#8217;ll talk about the TensorFlow graph of the model.  Note that the code that I will be going through can be found in its entirety at this site&#8217;s <a href="https://github.com/adventuresinML/adventures-in-ml-code" target="_blank" rel="noopener">Github repository</a>.  In this case, the code is mostly based on the TensorFlow Word2Vec tutorial <a href="https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/examples/tutorials/word2vec/word2vec_basic.py" target="_blank" rel="noopener">here</a> with some personal changes.</p>
<h3>Preparing the text data</h3>
<p>The previously mentioned TensorFlow tutorial has a few functions that take a text database and transform it so that we can extract input words and their associated grams in mini-batches for training the Word2Vec system / embeddings (if you&#8217;re not sure what &#8220;mini-batch&#8221; means, check out <a href="http://adventuresinmachinelearning.com/stochastic-gradient-descent/" target="_blank" rel="noopener">this tutorial</a>).  I&#8217;ll briefly talk about each of these functions in turn:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">def maybe_download(filename, url, expected_bytes):
    &quot;&quot;&quot;Download a file if not present, and make sure it&#039;s the right size.&quot;&quot;&quot;
    if not os.path.exists(filename):
        filename, _ = urllib.request.urlretrieve(url + filename, filename)
    statinfo = os.stat(filename)
    if statinfo.st_size == expected_bytes:
        print(&#039;Found and verified&#039;, filename)
    else:
        print(statinfo.st_size)
        raise Exception(
            &#039;Failed to verify &#039; + filename + &#039;. Can you get to it with a browser?&#039;)
    return filename</code></pre> <div class="code-embed-infos"> </div> </div>
<p>This function checks to see if the <em>filename</em> already has been downloaded from the supplied <em>url</em>.  If not, it uses the urllib.request Python module which retrieves a file from the given <em>url</em> argument, and downloads the file into the local code directory.  If the file already exists (i.e. <em>os.path.exists(filename)</em> returns true), then the function does not try to download the file again.  Next, the function checks the size of the file and makes sure it lines up with the expected file size, <em>expected_bytes</em>.  If all is well, it returns the <em>filename </em>object which can be used to extract the data from.  To call the function with the data-set we are using in this example, we execute the following code:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">url = &#039;http://mattmahoney.net/dc/&#039;
filename = maybe_download(&#039;text8.zip&#039;, url, 31344016)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>The next thing we have to do is take the <em>filename</em> object, which points to the downloaded file, and extract the data using the Python <em>zipfile</em> module.</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># Read the data into a list of strings.
def read_data(filename):
    &quot;&quot;&quot;Extract the first file enclosed in a zip file as a list of words.&quot;&quot;&quot;
    with zipfile.ZipFile(filename) as f:
        data = tf.compat.as_str(f.read(f.namelist()[0])).split()
    return data</code></pre> <div class="code-embed-infos"> </div> </div>
<p>Using <em>zipfile.ZipFile()</em> to extract the zipped file, we can then use the reader functionality found in this <em>zipfile</em> module.  First, the <em>namelist()</em> function retrieves all the members of the archive &#8211; in this case there is only one member, so we access this using the zero index.  Then we use the <em>read()</em> function which reads all the text in the file and pass this through the TensorFlow function <em>as_str</em> which ensures that the text is created as a string data-type.  Finally, we use <em>split()</em> function to create a list with all the words in the text file, separated by white-space characters.  We can see some of the output here:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">vocabulary = read_data(filename)
print(vocabulary[:7])
[&#039;anarchism&#039;, &#039;originated&#039;, &#039;as&#039;, &#039;a&#039;, &#039;term&#039;, &#039;of&#039;, &#039;abuse&#039;]</code></pre> <div class="code-embed-infos"> </div> </div>
<p>As you can observe, the returned vocabulary data contains a list of plain English words, ordered as they are in the sentences of the original extracted text file.  Now that we have all the words extracted in a list, we have to do some further processing to enable us to create our skip-gram batch data.  These further steps are:</p>
<ol>
<li>Extract the top 10,000 most common words to include in our embedding vector</li>
<li>Gather together all the unique words and index them with a unique integer value &#8211; this is what is required to create an equivalent one-hot type input for the word.  We&#8217;ll use a dictionary to do this</li>
<li>Loop through every word in the dataset (<em>vocabulary</em> variable) and assign it to the unique integer word identified, created in Step 2 above.  This will allow easy lookup / processing of the word data stream</li>
</ol>
<p>The function which performs all this magic is shown below:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">def build_dataset(words, n_words):
    &quot;&quot;&quot;Process raw inputs into a dataset.&quot;&quot;&quot;
    count = [[&#039;UNK&#039;, -1]]
    count.extend(collections.Counter(words).most_common(n_words - 1))
    dictionary = dict()
    for word, _ in count:
        dictionary[word] = len(dictionary)
    data = list()
    unk_count = 0
    for word in words:
        if word in dictionary:
            index = dictionary[word]
        else:
            index = 0  # dictionary[&#039;UNK&#039;]
            unk_count += 1
        data.append(index)
    count[0][1] = unk_count
    reversed_dictionary = dict(zip(dictionary.values(), dictionary.keys()))
    return data, count, dictionary, reversed_dictionary</code></pre> <div class="code-embed-infos"> </div> </div>
<p>The first step is setting up a &#8220;counter&#8221; list, which will store the number of times a word is found within the data-set.  Because we are restricting our vocabulary to only 10,000 words, any words not within the top 10,000 most common words will be marked with an &#8220;UNK&#8221; designation, standing for &#8220;unknown&#8221;.  The initialized <em>count</em> list is then extended, using the Python collections module and the <em>Counter() </em>class and the associated <em>most_common()</em> function.  These count the number of words in the given argument (<em>words</em>) and then returns the <em>n </em>most common words in a list format.</p>
<p>The next part of this function creates a dictionary, called <em>dictionary</em> which is populated by keys corresponding to each unique word.  The value assigned to each unique word key is simply an increasing integer count of the size of the dictionary.  So, for instance, the most common word will receive the value 1, the second most common the value 2, the third most common word the value 3, and so on (the integer 0 is assigned to the &#8216;UNK&#8217; words).   This step creates a unique integer value for each word within the vocabulary &#8211; accomplishing the second step of the process which was defined above.</p>
<p>Next, the function loops through each <em>word</em> in our full <em>words </em>data set &#8211; the data set which was output from the read_data() function.  A list called <em>data</em> is created, which will be the same length as <em>words</em> but instead of being a list of individual words, it will instead be a list of integers &#8211; with each word now being represented by the unique integer that was assigned to this word in <em>dictionary.  </em>So, for the first sentence of our data-set [&#8216;anarchism&#8217;, &#8216;originated&#8217;, &#8216;as&#8217;, &#8216;a&#8217;, &#8216;term&#8217;, &#8216;of&#8217;, &#8216;abuse&#8217;], now looks like this in the <em>data</em> variable: [5242, 3083, 12, 6, 195, 2, 3136].  This part of the function addresses step 3 in the list above.</p>
<p>Finally, the function creates a dictionary called <em>reverse_dictionary</em> that allows us to look up a word based on its unique integer identifier, rather than looking up the identifier based on the word i.e. the original <em>dictionary.  </em></p>
<p>The final aspect of setting up our data is now to create a data set comprising of our input words and associated grams, which can be used to train our Word2Vec embedding system.  The code to do this is:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">data_index = 0
# generate batch data
def generate_batch(data, batch_size, num_skips, skip_window):
    global data_index
    assert batch_size % num_skips == 0
    assert num_skips &lt;= 2 * skip_window
    batch = np.ndarray(shape=(batch_size), dtype=np.int32)
    context = np.ndarray(shape=(batch_size, 1), dtype=np.int32)
    span = 2 * skip_window + 1  # [ skip_window input_word skip_window ]
    buffer = collections.deque(maxlen=span)
    for _ in range(span):
        buffer.append(data[data_index])
        data_index = (data_index + 1) % len(data)
    for i in range(batch_size // num_skips):
        target = skip_window  # input word at the center of the buffer
        targets_to_avoid = [skip_window]
        for j in range(num_skips):
            while target in targets_to_avoid:
                target = random.randint(0, span - 1)
            targets_to_avoid.append(target)
            batch[i * num_skips + j] = buffer[skip_window]  # this is the input word
            context[i * num_skips + j, 0] = buffer[target]  # these are the context words
        buffer.append(data[data_index])
        data_index = (data_index + 1) % len(data)
    # Backtrack a little bit to avoid skipping words in the end of a batch
    data_index = (data_index + len(data) - span) % len(data)
    return batch, context</code></pre> <div class="code-embed-infos"> </div> </div>
<p>This function will generate mini-batches to use during our training (again, see <a href="http://adventuresinmachinelearning.com/stochastic-gradient-descent/" target="_blank" rel="noopener">here</a> for information on mini-batch training).  These batches will consist of input words (stored in <em>batch</em>) and random associated context words within the gram as the labels to predict (stored in <i>context</i>).  For instance, in the 5-gram &#8220;the cat sat on the&#8221;, the input word will be center word i.e. &#8220;sat&#8221; and the context words that will be predicted will be drawn randomly from the remaining words of the gram: [&#8216;the&#8217;, &#8216;cat&#8217;, &#8216;on&#8217;, &#8216;the&#8217;].  In this function, the number of words drawn randomly from the surrounding context is defined by the argument <em>num_skips</em>.  The size of the window of context words to draw from around the input word is defined in the argument <em>skip_window &#8211; </em>in the example above (&#8220;the cat sat on the&#8221;), we have a skip window width of 2 around the input word &#8220;sat&#8221;.</p>
<p>In the function above, first the batch and label outputs are defined as variables of size <em>batch_size</em>.  Then the span size is defined, which is basically the size of the word list that the input word and context samples will be drawn from.  In the example sub-sentence above &#8220;the cat sat on the&#8221;, the span is 5 = 2 x skip window + 1.  After this a buffer is created:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">buffer = collections.deque(maxlen=span)
for _ in range(span):
    buffer.append(data[data_index])
    data_index = (data_index + 1) % len(data)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>This buffer will hold a maximum of <em>span</em> elements and will be a kind of moving window of words that samples are drawn from.  Whenever a new word index is added to the buffer, the left most element will drop out of the buffer to allow room for the new word index being added.  The position of the buffer in the input text stream is stored in a global variable <em>data_index</em> which is incremented each time a new word is added to the buffer.  If it gets to the end of the text stream, the &#8220;% len(data)&#8221; component of the index update will basically reset the count back to zero.</p>
<p>The code below fills out the batch and context variables: <!--?prettify linenums=true?--></p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">for i in range(batch_size // num_skips):
    target = skip_window  # input word at the center of the buffer
    targets_to_avoid = [skip_window]
    for j in range(num_skips):
        while target in targets_to_avoid:
            target = random.randint(0, span - 1)
        targets_to_avoid.append(target)
        batch[i * num_skips + j] = buffer[skip_window]  # this is the input word
        context[i * num_skips + j, 0] = buffer[target]  # these are the context words
    buffer.append(data[data_index])
    data_index = (data_index + 1) % len(data)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>The first &#8220;target&#8221; word selected is the word at the center of the span of words and is therefore the input word.  Then other words are randomly selected from the span of words, making sure that the input word is not selected as part of the context, and each context word is unique.  The <em>batch</em> variable will feature repeated input words (<em>buffer[skip_window]</em>) which are matched with each context word in <em>context</em>.</p>
<p>The <em>batch </em>and <em>context</em> variables are then returned &#8211; and now we have a means of drawing batches of data from the data set.  We are now in a position to create our Word2Vec training code in TensorFlow.  However, before we get to that, we&#8217;ll first create a validation data-set that we can use to test how our model is doing.  We do that by measuring the vectors closest together in vector-space, and make sure these words indeed are similar using our knowledge of English.  This will be discussed more in the next section.  However, for now, the code below shows how to grab some random validation words from the most common words in our vocabulary:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># We pick a random validation set to sample nearest neighbors. Here we limit the
# validation samples to the words that have a low numeric ID, which by
# construction are also the most frequent.
valid_size = 16     # Random set of words to evaluate similarity on.
valid_window = 100  # Only pick dev samples in the head of the distribution.
valid_examples = np.random.choice(valid_window, valid_size, replace=False)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>The code above randomly chooses 16 integers from 0-100 &#8211; this corresponds to the integer indexes of the most common 100 words in our text data.  These will be the words we examine to assess how our learning is progressing in associating related words together in the vector-space.  Now, onto creating the TensorFlow model.</p>
<h3>Creating the TensorFlow model</h3>
<p>For a refresher on TensorFlow, check out <a href="http://adventuresinmachinelearning.com/python-tensorflow-tutorial/" target="_blank" rel="noopener">this tutorial</a>.  Below I will step through the process of creating our Word2Vec word embeddings in TensorFlow.  What does this involve?  Simply, we need to setup the neural network which I previously presented, with a word embedding matrix acting as the hidden layer and an output softmax layer in TensorFlow.  By training this model, we&#8217;ll be learning the best word embedding matrix and therefore we&#8217;ll be learning a reduced, context maintaining, mapping of words to vectors.</p>
<p>The first thing to do is set-up some variables which we&#8217;ll use later on in the code &#8211; the purposes of these variables will become clear as we progress:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">batch_size = 128
embedding_size = 128  # Dimension of the embedding vector.
skip_window = 1       # How many words to consider left and right.
num_skips = 2         # How many times to reuse an input to generate a context.</code></pre> <div class="code-embed-infos"> </div> </div>
<p>Next we setup some TensorFlow placeholders that will hold our input words (their integer indexes) and context words which we are trying to predict.  We also need to create a constant to hold our validation set indexes in TensorFlow:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">train_inputs = tf.placeholder(tf.int32, shape=[batch_size])
train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])
valid_dataset = tf.constant(valid_examples, dtype=tf.int32)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>Next, we need to setup the embedding matrix variable / tensor &#8211; this is straight-forward using the TensorFlow <em>embedding_lookup() </em>function, which I&#8217;ll explain shortly:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># Look up embeddings for inputs.
embeddings = tf.Variable(
    tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))
embed = tf.nn.embedding_lookup(embeddings, train_inputs)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>The first step in the code above is to create the embeddings variable, which is effectively the weights of the connections to the linear hidden layer.  We initialize the variable with a random uniform distribution between -1.0 to 1.0.  The size of this variable is (<em>vocabulary_size, </em><em>embedding_size</em>) &#8211; the <em>vocabulary_size </em>is the 10,000 words that we have used to setup our data in the previous section.  This is basically our one-hot vector input, where the only element with a value of &#8220;1&#8221; is the current input word, all the other values are set to &#8220;0&#8221;.  The second dimension, <em>embedding_size,</em> is our hidden layer size, and is the length of our new, smaller, representation of our words.  We can also think of this tensor as a big lookup table &#8211; the rows are each word in our vocabulary, and the columns are our new vector representation of each of these words.  Here&#8217;s a simplified example (using dummy values), where <em>vocabulary_size=7 </em>and <em>embedding_size=3</em>:</p>
<p>\begin{equation}<br />
\begin{array}{c|c c c}<br />
anarchism &amp; 0.5 &amp; 0.1 &amp; -0.1\\<br />
originated &amp; -0.5 &amp; 0.3 &amp; 0.9 \\<br />
as &amp; 0.3 &amp; -0.5 &amp; -0.3 \\<br />
a &amp; 0.7 &amp; 0.2 &amp; -0.3\\<br />
term &amp; 0.8 &amp; 0.1 &amp; -0.1 \\<br />
of &amp; 0.4 &amp; -0.6 &amp; -0.1 \\<br />
abuse &amp; 0.7 &amp; 0.1 &amp; -0.4<br />
\end{array}<br />
\end{equation}</p>
<p>As can be observed, &#8220;anarchism&#8221; (which would actually be represented by a unique integer or one-hot vector) is now expressed as [0.5, 0.1, -0.1].  We can &#8220;look up&#8221; anarchism by finding its integer index and searching the rows of <em>embeddings</em> to find the embedding vector: [0.5, 0.1, -0.1].</p>
<p>The next line in the code involves the <em>tf.nn.embedding_lookup() </em>function, which is a useful helper function in TensorFlow for this type of task.  Here&#8217;s how it works &#8211; it takes an input vector of integer indexes &#8211; in this case our <em>train_input</em> tensor of training input words, and &#8220;looks up&#8221; these indexes in the supplied embeddings tensor.  Therefore, this command will return the current embedding vector for each of the supplied input words in the training batch.  The full embedding tensor will be optimized during the training process.</p>
<p>Next we have to create some weights and bias values to connect the output softmax layer, and perform the appropriate multiplication and addition.  This looks like:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># Construct the variables for the softmax
weights = tf.Variable(tf.truncated_normal([vocabulary_size, embedding_size],
                          stddev=1.0 / math.sqrt(embedding_size)))
biases = tf.Variable(tf.zeros([vocabulary_size]))
hidden_out = tf.matmul(embed, tf.transpose(weights)) + biases</code></pre> <div class="code-embed-infos"> </div> </div>
<p>The weight variable, as it is connecting the hidden layer and the output layer, is of size (<em>out_layer_size, hidden_layer_size) = (vocabulary_size, embedding_size)</em>.  The biases, as usual, will only be single dimensional and the size of the output layer.  We then multiply the embedded variable (<em>embed</em>) by the weights and add the bias.  Now we are ready to create a softmax operation and we will use cross entropy loss to optimize the weights, biases and embeddings of the model.  To do this easily, we will use the TensorFlow function <em>softmax_cross_entropy_with_logits()</em>.  However, to use this function we first have to convert the context words / integer indices into one-hot vectors.  The code below performs both of these steps, and also adds a gradient descent optimization operation:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># convert train_context to a one-hot format
train_one_hot = tf.one_hot(train_context, vocabulary_size)
cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hidden_out, 
    labels=train_one_hot))
# Construct the SGD optimizer using a learning rate of 1.0.
optimizer = tf.train.GradientDescentOptimizer(1.0).minimize(cross_entropy)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>Next, we need to perform our similarity assessments to check on how the model is performing as it trains.  To determine which words are similar to each other, we need to perform some sort of operation that measures the &#8220;distances&#8221; between the various word embedding vectors for the different words.  In this case, we will use the <a href="https://en.wikipedia.org/wiki/Cosine_similarity" target="_blank" rel="noopener">cosine similarity</a> measure of distance between vectors.  It is defined as:</p>
<p>$$similarity = cos(\theta) = \frac{\textbf{A}\cdot\textbf{B}}{\parallel\textbf{A}\parallel_2 \parallel \textbf{B} \parallel_2}$$</p>
<p>Here the bolded <strong><em>A</em></strong> and <strong><em>B</em></strong> are the two vectors that we are measuring the similarity between.  The double parallel lines with the <em>2</em> subscript ($\parallel\textbf{A}\parallel_2$) refers to the L2 norm of the vector.  To get the L2 norm of a vector, you square every dimension of the vector (in this case <em>n</em><em>=300, </em>the width of our embedding vector), sum up the squared elements then take the square root of the product i.e.:</p>
<p>$$\sqrt{\sum_{i=1}^n A_{i}^2}$$</p>
<p>The best way to calculate the cosine similarity in TensorFlow is to normalize each vector like so:</p>
<p>$$\frac{\textbf{A}}{\parallel\textbf{A}\parallel_2}$$</p>
<p>Then we can simply multiply these normalized vectors together to get the cosine similarity.  We will multiply the validation vectors/words that were discussed earlier with all of the words in our embedding vector, then we can sort in descending order to get those words most similar to our validation words.</p>
<p>First, we calculate the L2 norm of each vector using the <em>tf.square()</em>, <em>tf.reduce_sum()</em> and <em>tf.sqrt()</em> functions to calculate the square, summation and square root of the norm, respectively:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># Compute the cosine similarity between minibatch examples and all embeddings.
norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims=True))
normalized_embeddings = embeddings / norm</code></pre> <div class="code-embed-infos"> </div> </div>
<p>Now we can look up our validation words / vectors using the <em>tf.nn.embedding_lookup() </em>that we discussed earlier:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">valid_embeddings = tf.nn.embedding_lookup(
      normalized_embeddings, valid_dataset)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>As before, we are supplying a list of integers (that correspond to our validation vocabulary words) to the <em>embedding_lookup() </em>function, which looks up these rows in the <em>normalized_embeddings </em>tensor, and returns the subset of <em>validation</em> normalized embeddings.  Now that we have the normalized validation tensor, <em>valid_embeddings</em>, we can multiply this by the full normalized vocabulary (<em>normalized_embedding</em>) to finalize our similarity calculation:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">similarity = tf.matmul(
      valid_embeddings, normalized_embeddings, transpose_b=True)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>This operation will return a (<em>validation_size, vocabulary_size</em>) sized tensor, where each row refers to one of our validation words and the columns refer to the similarity between the validation word and all the other words in the vocabulary.</p>
<h3>Running the TensorFlow model</h3>
<p>The code below initializes the variables and feeds in each data batch to the training loop, printing the average loss every 2000 iterations.  If this code doesn&#8217;t make sense to you, check out my <a href="http://adventuresinmachinelearning.com/python-tensorflow-tutorial/" target="_blank" rel="noopener">TensorFlow tutorial</a>.</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">with tf.Session(graph=graph) as session:
  # We must initialize all variables before we use them.
  init.run()
  print(&#039;Initialized&#039;)

  average_loss = 0
  for step in range(num_steps):
    batch_inputs, batch_context = generate_batch(data,
        batch_size, num_skips, skip_window)
    feed_dict = {train_inputs: batch_inputs, train_context: batch_context}

    # We perform one update step by evaluating the optimizer op (including it
    # in the list of returned values for session.run()
    _, loss_val = session.run([optimizer, cross_entropy], feed_dict=feed_dict)
    average_loss += loss_val

    if step % 2000 == 0:
      if step &gt; 0:
        average_loss /= 2000
      # The average loss is an estimate of the loss over the last 2000 batches.
      print(&#039;Average loss at step &#039;, step, &#039;: &#039;, average_loss)
      average_loss = 0</code></pre> <div class="code-embed-infos"> </div> </div>
<p>Next, we want to print out the words which are most similar to our validation words &#8211; we do this by calling the similarity operation we defined above and sorting the results (note, this is only performed every 10,000 iterations as it is computationally expensive):</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># Note that this is expensive (~20% slowdown if computed every 500 steps)
if step % 10000 == 0:
    sim = similarity.eval()
    for i in range(valid_size):
        valid_word = reverse_dictionary[valid_examples[i]]
        top_k = 8  # number of nearest neighbors
        nearest = (-sim[i, :]).argsort()[1:top_k + 1]
        log_str = &#039;Nearest to %s:&#039; % valid_word
        for k in range(top_k):
            close_word = reverse_dictionary[nearest[k]]
            log_str = &#039;%s %s,&#039; % (log_str, close_word)
        print(log_str)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>This function first evaluates the similarity operation, which returns an array of cosine similarity values for each of the validation words.  Then we iterate through each of the validation words, taking the top 8 closest words by using argsort() on the negative of the similarity to arrange the values in descending order.  The code then prints out these 8 closest words so we can monitor how the embedding process is performing.</p>
<p>Finally, after all the training iterations are finished, we can assign the final embeddings to a separate tensor for use later (most likely in some sort of other deep learning or machine learning process):</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code">final_embeddings = normalized_embeddings.eval()</code></pre> <div class="code-embed-infos"> </div> </div>
<p>So now we&#8217;re done &#8211; or are we?  The code for this softmax method of Word2Vec is on this site&#8217;s Github repository &#8211; you could try running it, but I wouldn&#8217;t recommend it.  Why?  Because it is seriously slow.</p>
<h2>Speeding things up &#8211; the &#8220;true&#8221; Word2Vec method</h2>
<p>The fact is, performing softmax evaluations and updating the weights over a 10,000 word output/vocabulary is really slow.  Why&#8217;s that?  Consider the softmax definition:</p>
<p>$$P(y = j \mid x) = \frac{e^{x^T w_j}}{\sum_{k=1}^K e^{x^T w_k}}$$</p>
<p>In the context of what we are working on, the softmax function will predict what words have the highest probability of being in the context of the input word.  To determine that probability however, the denominator of the softmax function has to evaluate <em>all </em>the possible context words in the vocabulary.  Therefore, we need 300 x 10,000 = 3M weights, all of which need to be trained for the softmax output.  This slows things down.</p>
<p>There is an alternative, faster scheme called <a href="http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf" target="_blank" rel="noopener">Noise Contrastive Estimation (NCE)</a>.  Instead of taking the probability of the context word compared to <em>all </em>of the possible context words in the vocabulary, this method randomly samples 2-20 possible context words and evaluates the probability only from these.  I won&#8217;t go into the nitty gritty details here, but suffice to say that this method has been shown to perform well and drastically speeds up the training process.</p>
<p>TensorFlow has helped us out here, and has supplied an NCE loss function that we can use called <em>tf.nn.nce_loss()</em> which we can supply weight and bias variables to.  Using this function, the time to perform 100 training iterations reduced from 25 seconds with the softmax method to less than 1 second using the NCE method.  An awesome improvement!  We replace the softmax lines with the following in our code:</p>
<div class="code-embed-wrapper"> <pre class="language-python code-embed-pre line-numbers"  data-start="1" data-line-offset="0"><code class="language-python code-embed-code"># Construct the variables for the NCE loss
nce_weights = tf.Variable(
        tf.truncated_normal([vocabulary_size, embedding_size],
                            stddev=1.0 / math.sqrt(embedding_size)))
nce_biases = tf.Variable(tf.zeros([vocabulary_size]))

nce_loss = tf.reduce_mean(
        tf.nn.nce_loss(weights=nce_weights,
                       biases=nce_biases,
                       labels=train_context,
                       inputs=embed,
                       num_sampled=num_sampled,
                       num_classes=vocabulary_size))

optimizer = tf.train.GradientDescentOptimizer(1.0).minimize(nce_loss)</code></pre> <div class="code-embed-infos"> </div> </div>
<p>Now we are good to run the code.  You can get the full code <a href="https://github.com/adventuresinML/adventures-in-ml-code" target="_blank" rel="noopener">here</a>.  As discussed, every 10,000 iterations the code outputs the validation words and the words that the Word2Vec system deems are similar.  Below, you can see the improvement for some selected validation words between the random initialization and at the 50,000 iteration mark:</p>
<p>At the beginning:</p>
<blockquote><p>Nearest to nine: heterosexual, scholarly, scandal, serves, humor, realized, cave, himself</p>
<p>Nearest to this: contains, alter, numerous, harmonica, nickname, ghana, bogart, marxist</p></blockquote>
<p>After 10,000 iterations:</p>
<blockquote><p>Nearest to nine: zero, one, and, coke, in, UNK, the, jpg</p>
<p>Nearest to this: the, a, UNK, killing, meter, afghanistan, ada, indiana</p></blockquote>
<p>Finally after 50,000 iterations:</p>
<blockquote><p>Nearest to nine: eight, one, zero, seven, six, two, five, three</p>
<p>Nearest to this: that, the, a, UNK, one, it, he, an</p></blockquote>
<p>By examining the outputs above, we can first see that the word &#8220;nine&#8221; becomes increasingly associated with other number words (&#8220;eight&#8221;, &#8220;one&#8221;, &#8220;seven&#8221; etc.).  This makes sense. The word &#8220;this&#8221;, which acts as a pronoun and definite article in sentences, becomes associated with other pronouns (&#8220;he&#8221;, &#8220;it&#8221;) and other definite articles (&#8220;the&#8221;, &#8220;that&#8221;, etc.) the more iterations we run.</p>
<p>In summary then, we have learnt how to use the Word2Vec methodology to reduce large one-hot word vectors to much reduced word embedding vectors which preserve the context and meaning of the original words.  These word embedding vectors can then be used as a more efficient and effective input to deep learning techniques which aim to model natural language.  These techniques, such as recurrent neural networks, will be the subject of future posts.</p>
<hr />
<p><strong>Recommended online course: </strong>If you would like to learn more in a video format, check out this well rated and inexpensive Udemy course: <a href="https://click.linksynergy.com/link?id=Jbc0N5ZkDzk&amp;offerid=323058.918390&amp;type=2&amp;murl=https%3A%2F%2Fwww.udemy.com%2Fnatural-language-processing-with-deep-learning-in-python%2F" target="new">Natural Language Processing with Deep Learning in Python</a><img src="https://ad.linksynergy.com/fs-bin/show?id=Jbc0N5ZkDzk&amp;bids=323058.918390&amp;type=2&amp;subid=0" width="1" height="1" border="0" /></p>
<hr />
<p>&nbsp;</p>
<p>The post <a rel="nofollow" href="http://adventuresinmachinelearning.com/word2vec-tutorial-tensorflow/">Word2Vec word embedding tutorial in Python and TensorFlow</a> appeared first on <a rel="nofollow" href="http://adventuresinmachinelearning.com">Adventures in Machine Learning</a>.</p>
]]></content:encoded>
			<wfw:commentRss>http://adventuresinmachinelearning.com/word2vec-tutorial-tensorflow/feed/</wfw:commentRss>
		<slash:comments>18</slash:comments>
		</item>
	</channel>
</rss>
